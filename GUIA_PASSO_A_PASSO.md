# Guia Passo a Passo - Prova CBR para Classifica√ß√£o de DRC

## üìã Vis√£o Geral da Prova

**Objetivo**: Implementar algoritmos CBR (Case-Based Reasoning) para classificar Doen√ßa Renal Cr√¥nica em dois problemas:

-   **Problema 1**: Classifica√ß√£o multiclasse (`CKD_Stage` - est√°gios 1-5)
-   **Problema 2**: Classifica√ß√£o bin√°ria (`CKD_Progression` - sim/n√£o)

**Dataset**: 1140 amostras com 23 features cl√≠nicas + 2 targets

---

## üéØ Checklist de Entreg√°veis

-   [ ] C√≥digo Python bem comentado (main.ipynb)
-   [ ] Relat√≥rio PDF com an√°lises e conclus√µes
-   [ ] Implementa√ß√£o CBR baseline (pesos iguais)
-   [ ] Implementa√ß√£o de otimiza√ß√£o de pesos (Grid Search/Gradiente/Gen√©tico)
-   [ ] Avalia√ß√£o completa com m√©tricas cl√≠nicas
-   [ ] Compara√ß√£o entre abordagens e problemas

---

## üìù PASSO 1: Configura√ß√£o do Ambiente

### 1.1 Verificar Depend√™ncias

```bash
# J√° instalado: cbrkit[all]>=0.28.5
uv add pandas numpy scikit-learn matplotlib seaborn
uv add jupyter plotly scipy
```

### 1.2 Estrutura do Projeto

```
‚úì main.ipynb          # Notebook principal
‚úì dataset/ckd.csv     # Dataset com 1140 amostras
‚úì README.md           # Especifica√ß√µes
‚úì Prova.pdf          # Documento original
```

---

## üìä PASSO 2: An√°lise Explorat√≥ria (EDA)

### 2.1 Carregamento e Inspe√ß√£o Inicial

-   [ ] Carregar `dataset/ckd.csv`
-   [ ] Verificar shape: (1140, 25) - 23 features + 2 targets
-   [ ] Identificar tipos de dados (numerical, categorical)
-   [ ] Mapear features por categoria cl√≠nica

### 2.2 An√°lise de Qualidade dos Dados

-   [ ] **Valores faltantes**: Focar em BMI (tem nulls mencionados)
-   [ ] **Distribui√ß√µes**: Histogramas para num√©ricas, contagens para categ√≥ricas
-   [ ] **Outliers**: Boxplots para detectar valores extremos
-   [ ] **Balance das classes**: Para ambos os targets

### 2.3 An√°lise de Correla√ß√£o

-   [ ] **Matriz de correla√ß√£o** entre features
-   [ ] **Correla√ß√£o features-target** (CKD_Stage e CKD_Progression)
-   [ ] **Identificar features com >90% correla√ß√£o** com targets (CR√çTICO!)

**‚ö†Ô∏è ATEN√á√ÉO**: Features com correla√ß√£o >90% devem ser removidas obrigatoriamente!

---

## üîß PASSO 3: Pr√©-processamento (OBRIGAT√ìRIO)

### 3.1 Limpeza de Dados

-   [ ] **Tratar valores faltantes** (imputa√ß√£o ou remo√ß√£o)
-   [ ] **Remover features com correla√ß√£o >90%** com targets
-   [ ] **Verificar consist√™ncia** dos dados cl√≠nicos

### 3.2 Transforma√ß√£o de Features

-   [ ] **Encoding categ√≥ricas**: Label encoding ou One-hot
-   [ ] **Normaliza√ß√£o/Padroniza√ß√£o**: MinMaxScaler ou StandardScaler
-   [ ] **Feature engineering** se necess√°rio

### 3.3 Divisi√≥n dos Dados

-   [ ] **Train/Test split** (ex: 80/20)
-   [ ] **Separar por problema**:
    -   Dataset para CKD_Stage (multiclass)
    -   Dataset para CKD_Progression (binary)
-   [ ] **Diferentes features** podem ser usadas para cada problema

**üìç CHECKPOINT**: Dois datasets limpos e preparados

---

## üß† PASSO 4: Implementa√ß√£o CBR Baseline

### 4.1 Fun√ß√£o de Similaridade

-   [ ] **Design modular** para diferentes tipos:
    -   Num√©rica: Dist√¢ncia Euclidiana normalizada
    -   Categ√≥rica: Match/mismatch ou Jaccard
    -   Textual: Similaridade de strings
-   [ ] **Fun√ß√£o combinada** com pesos ajust√°veis
-   [ ] **Valida√ß√£o** com casos de teste

### 4.2 Algoritmo CBR Base

-   [ ] **Recupera√ß√£o de casos**: k-NN baseado em similaridade
-   [ ] **Classifica√ß√£o**: Vota√ß√£o majorit√°ria
-   [ ] **Pesos iniciais**: Todos iguais (w = 1)
-   [ ] **Implementa√ß√£o modular** para reutiliza√ß√£o

### 4.3 Avalia√ß√£o Baseline

-   [ ] **Teste para CKD_Stage** (multiclass)
-   [ ] **Teste para CKD_Progression** (binary)
-   [ ] **M√©tricas iniciais**: Accuracy, Precision, Recall, F1
-   [ ] **Documentar performance** baseline

**üìç CHECKPOINT**: CBR funcionando com pesos iguais

---

## ‚ö° PASSO 5: Otimiza√ß√£o de Pesos

### 5.1 Escolha do M√©todo (implementar 1 dos 3)

#### Op√ß√£o A: Grid Search

-   [ ] **Definir espa√ßo de busca** para pesos
-   [ ] **Cross-validation** no conjunto de treino
-   [ ] **Busca exaustiva** em grid de par√¢metros

#### Op√ß√£o B: Gradiente Descendente

-   [ ] **Fun√ß√£o objetivo**: Minimizar erro de classifica√ß√£o
-   [ ] **Gradiente num√©rico** ou anal√≠tico
-   [ ] **Learning rate** e crit√©rios de parada

#### Op√ß√£o C: Algoritmo Gen√©tico

-   [ ] **Popula√ß√£o de solu√ß√µes** (conjuntos de pesos)
-   [ ] **Fun√ß√£o fitness**: Accuracy ou F1-Score
-   [ ] **Operadores**: Sele√ß√£o, crossover, muta√ß√£o

### 5.2 Implementa√ß√£o e Tuning

-   [ ] **Justificar escolha** do m√©todo
-   [ ] **Documentar par√¢metros**: itera√ß√µes, popula√ß√£o, thresholds
-   [ ] **Experimentos controlados**: Testar varia√ß√µes
-   [ ] **Converg√™ncia**: Monitorar otimiza√ß√£o

### 5.3 Valida√ß√£o da Otimiza√ß√£o

-   [ ] **Aplicar pesos otimizados** ao CBR
-   [ ] **Teste nos dois problemas**
-   [ ] **Comparar com baseline**

**üìç CHECKPOINT**: Pesos otimizados funcionando

---

## üìà PASSO 6: Avalia√ß√£o Completa

### 6.1 M√©tricas Quantitativas

-   [ ] **Para ambos problemas** (CKD_Stage e CKD_Progression):
    -   Accuracy, Precision, Recall, F1-Score
    -   Matriz de Confus√£o
    -   AUC-ROC (quando aplic√°vel)
-   [ ] **Compara√ß√£o**: Baseline vs Otimizado

### 6.2 An√°lise Cl√≠nica

-   [ ] **Interpreta√ß√£o m√©dica**:
    -   Falsos positivos: Pacientes sem DRC classificados como tendo
    -   Falsos negativos: Pacientes com DRC n√£o detectados
-   [ ] **Implica√ß√µes cl√≠nicas** de cada tipo de erro
-   [ ] **Relev√¢ncia das features** mais importantes

### 6.3 An√°lise Comparativa

-   [ ] **CBR Baseline vs CBR Otimizado**
-   [ ] **CKD_Stage vs CKD_Progression**: Qual problema √© mais dif√≠cil?
-   [ ] **Impacto da otimiza√ß√£o** por tipo de problema

**üìç CHECKPOINT**: Avalia√ß√£o completa documentada

---

## üìã PASSO 7: Experimenta√ß√£o e Refinamento

### 7.1 Experimentos Controlados

-   [ ] **Varia√ß√£o de par√¢metros**:
    -   N√∫mero de casos recuperados (k)
    -   Thresholds de similaridade
    -   Par√¢metros do otimizador
-   [ ] **An√°lise de sensibilidade**
-   [ ] **Documentar comportamento** observado

### 7.2 Visualiza√ß√µes

-   [ ] **Gr√°ficos de otimiza√ß√£o**: Converg√™ncia dos pesos
-   [ ] **Heatmaps**: Import√¢ncia das features
-   [ ] **Curvas ROC**: Para an√°lise de performance
-   [ ] **Compara√ß√µes visuais**: Baseline vs Otimizado

---

## üìÑ PASSO 8: Documenta√ß√£o e Relat√≥rio

### 8.1 C√≥digo (main.ipynb)

-   [ ] **C√≥digo bem comentado** em portugu√™s
-   [ ] **Instru√ß√µes de reprodu√ß√£o** claras
-   [ ] **C√©lulas organizadas** por se√ß√£o
-   [ ] **Outputs preservados** para demonstra√ß√£o

### 8.2 Relat√≥rio PDF

-   [ ] **Introdu√ß√£o**: Problema e objetivos
-   [ ] **Metodologia**: CBR e otimiza√ß√£o escolhida
-   [ ] **Experimentos**: Configura√ß√µes e resultados
-   [ ] **Resultados**: Tabelas e gr√°ficos de performance
-   [ ] **An√°lise cr√≠tica**: Interpreta√ß√£o dos resultados
-   [ ] **Conclus√µes**: Limita√ß√µes e trabalhos futuros
-   [ ] **Refer√™ncias**: Bibliografia utilizada

### 8.3 Estrutura Sugerida do Relat√≥rio

1. **Resumo Executivo** (1 p√°gina)
2. **An√°lise Explorat√≥ria** (2-3 p√°ginas)
3. **Metodologia CBR** (2-3 p√°ginas)
4. **Experimentos e Resultados** (3-4 p√°ginas)
5. **Discuss√£o Cl√≠nica** (2 p√°ginas)
6. **Conclus√µes** (1 p√°gina)

---

## ‚ö†Ô∏è Pontos Cr√≠ticos para Sucesso

### ‚ùó Obrigat√≥rios (Pode reprovar se n√£o fizer)

-   Remo√ß√£o de features com correla√ß√£o >90% com target
-   Implementa√ß√£o CBR com fun√ß√£o de similaridade apropriada
-   Otimiza√ß√£o de pesos com pelo menos um m√©todo
-   Avalia√ß√£o completa nos dois problemas
-   C√≥digo Python bem documentado

### üéØ Diferenciais (Nota m√°xima)

-   Justificativa s√≥lida da escolha de otimiza√ß√£o
-   An√°lise cl√≠nica aprofundada dos erros
-   Experimentos bem controlados e documentados
-   Visualiza√ß√µes claras e informativas
-   Discuss√£o cr√≠tica das limita√ß√µes

### üö® Armadilhas Comuns

-   N√£o remover features altamente correlacionadas
-   Usar dados de teste para otimiza√ß√£o de pesos
-   N√£o justificar escolhas metodol√≥gicas
-   Ignorar aspectos cl√≠nicos dos resultados
-   C√≥digo mal documentado ou irreprodu√≠vel

**üèÅ Meta**: Prova completa e bem documentada!
