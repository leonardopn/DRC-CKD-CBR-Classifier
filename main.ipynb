{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969a14fa",
   "metadata": {},
   "source": [
    "# üìã PASSO 2.1 - CARREGAMENTO E INSPE√á√ÉO INICIAL DOS DADOS\n",
    "\n",
    "**Objetivos deste passo:**\n",
    "- ‚úÖ Carregar dataset CKD do arquivo CSV\n",
    "- ‚úÖ Verificar estrutura e dimens√µes dos dados  \n",
    "- ‚úÖ Identificar tipos de features (num√©ricas vs categ√≥ricas)\n",
    "- ‚úÖ Mapear features por categorias cl√≠nicas\n",
    "- ‚úÖ Validar integridade dos dados carregados\n",
    "\n",
    "**Entradas:** `dataset/ckd.csv` (dados cl√≠nicos de DRC)  \n",
    "**Sa√≠das:** DataFrame carregado, an√°lise de tipos, mapeamento cl√≠nico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc031d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• SISTEMA CBR PARA CLASSIFICA√á√ÉO DE DOEN√áA RENAL CR√îNICA\n",
      "============================================================\n",
      "üìä Iniciando an√°lise explorat√≥ria dos dados...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# PROVA CBR - CLASSIFICA√á√ÉO DE DOEN√áA RENAL CR√îNICA (DRC/CKD)\n",
    "# Aluno: [Seu Nome]\n",
    "# Mat√©ria: Machine Learning - UFSM\n",
    "# ===============================================================================\n",
    "\n",
    "\"\"\"\n",
    "OBJETIVO: Implementar algoritmos CBR para classificar DRC em dois problemas:\n",
    "- Problema 1: Classifica√ß√£o multiclasse (CKD_Stage - est√°gios 1-5) \n",
    "- Problema 2: Classifica√ß√£o bin√°ria (CKD_Progression - sim/n√£o)\n",
    "\n",
    "DATASET: 1140 amostras com 23 features cl√≠nicas + 2 targets\n",
    "\"\"\"\n",
    "\n",
    "print(\"üè• SISTEMA CBR PARA CLASSIFICA√á√ÉO DE DOEN√áA RENAL CR√îNICA\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìä Iniciando an√°lise explorat√≥ria dos dados...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65923e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Bibliotecas carregadas com sucesso!\n",
      "üìÇ Iniciando carregamento do dataset CKD...\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# PASSO 2.1: CARREGAMENTO E INSPE√á√ÉO INICIAL DOS DADOS\n",
    "# ===============================================================================\n",
    "\n",
    "# Importa√ß√µes essenciais para an√°lise explorat√≥ria\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"üìö Bibliotecas carregadas com sucesso!\")\n",
    "print(\"üìÇ Iniciando carregamento do dataset CKD...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ceb6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset encontrado: dataset/ckd.csv\n",
      "‚úÖ Dataset carregado com sucesso!\n",
      "üìä Shape do dataset: (1138, 23)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 1: CARREGAR DATASET CKD\n",
    "# ===============================================================================\n",
    "\n",
    "# Definir caminho do dataset\n",
    "dataset_path = Path(\"dataset/ckd.csv\")\n",
    "\n",
    "# Verificar se arquivo existe\n",
    "if not dataset_path.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Dataset n√£o encontrado em: {dataset_path}\")\n",
    "    \n",
    "print(f\"‚úÖ Dataset encontrado: {dataset_path}\")\n",
    "\n",
    "# Carregar dataset com pandas\n",
    "try:\n",
    "    df_ckd = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Dataset carregado com sucesso!\")\n",
    "    print(f\"üìä Shape do dataset: {df_ckd.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao carregar dataset: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9d4ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE DA ESTRUTURA DO DATASET\n",
      "==================================================\n",
      "üìè Shape mencionado no README: (1140, 23)\n",
      "üìè Shape real do dataset: (1138, 23)\n",
      "‚ÑπÔ∏è  Diferen√ßas identificadas:\n",
      "   üìä Amostras: -2 (1138 vs 1140 esperado)\n",
      "      ‚Üí Prov√°vel remo√ß√£o de 2 registros inv√°lidos/duplicados\n",
      "‚úÖ Dataset v√°lido com 1138 amostras √ó 23 colunas\n",
      "   (Todas as 23 features listadas no README est√£o presentes)\n",
      "\n",
      "üìã Nomes das colunas (23):\n",
      "    1. Sex\n",
      "    2. Age\n",
      "    3. Systolic_Pressure\n",
      "    4. BMI\n",
      "    5. CKD_Cause\n",
      "    6. Hemoglobin\n",
      "    7. Albumin\n",
      "    8. Creatinine\n",
      "    9. eGFR\n",
      "   10. CKD_Stage\n",
      "   11. CKD_Risk\n",
      "   12. Dipstick_Proteinuria\n",
      "   13. Proteinuria\n",
      "   14. Occult_Blood_in_Urine\n",
      "   15. Protein_Creatinine_Ratio\n",
      "   16. UPCR_Severity\n",
      "   17. Hypertension\n",
      "   18. Previous_CVD\n",
      "   19. Diabetes\n",
      "   20. RAAS_Inhibitor\n",
      "   21. Calcium_Channel_Blocker\n",
      "   22. Diuretics\n",
      "   23. CKD_Progression\n",
      "\n",
      "üìä Primeiras 3 linhas do dataset:\n",
      "   Sex  Age  Systolic_Pressure   BMI  CKD_Cause  Hemoglobin  Albumin  \\\n",
      "0    2   74              120.0  23.1          2        12.0      4.0   \n",
      "1    1   39              121.0  31.7          3        15.0      4.7   \n",
      "2    1   74              143.0  24.6          2        10.9      3.8   \n",
      "\n",
      "   Creatinine   eGFR  CKD_Stage  ...  Occult_Blood_in_Urine  \\\n",
      "0        1.20  34.15          3  ...                    0.0   \n",
      "1        1.31  50.45          3  ...                    0.0   \n",
      "2        4.95   9.80          5  ...                    0.0   \n",
      "\n",
      "   Protein_Creatinine_Ratio  UPCR_Severity  Hypertension  Previous_CVD  \\\n",
      "0                      1.25            3.0             1             0   \n",
      "1                      0.33            2.0             1             0   \n",
      "2                      1.76            3.0             1             0   \n",
      "\n",
      "   Diabetes  RAAS_Inhibitor  Calcium_Channel_Blocker  Diuretics  \\\n",
      "0         0               1                        1          0   \n",
      "1         0               0                        0          0   \n",
      "2         1               1                        1          1   \n",
      "\n",
      "   CKD_Progression  \n",
      "0                0  \n",
      "1                0  \n",
      "2                1  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 2: VERIFICAR SHAPE E ESTRUTURA ESPERADA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üîç AN√ÅLISE DA ESTRUTURA DO DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analisar shape real vs documenta√ß√£o do README.md\n",
    "readme_mentioned_samples = 1140  # Mencionado no README.md\n",
    "readme_features_count = 23  # 21 features + 2 targets (contando pela tabela)\n",
    "expected_shape = (readme_mentioned_samples, readme_features_count)\n",
    "actual_shape = df_ckd.shape\n",
    "\n",
    "print(f\"üìè Shape mencionado no README: {expected_shape}\")\n",
    "print(f\"üìè Shape real do dataset: {actual_shape}\")\n",
    "\n",
    "# Verificar diferen√ßas e explicar\n",
    "samples_diff = actual_shape[0] - expected_shape[0] \n",
    "columns_diff = actual_shape[1] - expected_shape[1]\n",
    "\n",
    "if actual_shape == expected_shape:\n",
    "    print(\"‚úÖ Shape exato conforme documenta√ß√£o!\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  Diferen√ßas identificadas:\")\n",
    "    if samples_diff != 0:\n",
    "        print(f\"   üìä Amostras: {samples_diff:+d} ({actual_shape[0]} vs {expected_shape[0]} esperado)\")\n",
    "        if samples_diff < 0:\n",
    "            print(f\"      ‚Üí Prov√°vel remo√ß√£o de {abs(samples_diff)} registros inv√°lidos/duplicados\")\n",
    "    if columns_diff != 0:\n",
    "        print(f\"   üìã Colunas: {columns_diff:+d} ({actual_shape[1]} vs {expected_shape[1]} esperado)\")\n",
    "    \n",
    "    print(f\"‚úÖ Dataset v√°lido com {actual_shape[0]} amostras √ó {actual_shape[1]} colunas\")\n",
    "    print(f\"   (Todas as {readme_features_count} features listadas no README est√£o presentes)\")\n",
    "\n",
    "print(f\"\\nüìã Nomes das colunas ({len(df_ckd.columns)}):\")\n",
    "for i, col in enumerate(df_ckd.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "print(f\"\\nüìä Primeiras 3 linhas do dataset:\")\n",
    "print(df_ckd.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe9d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ AN√ÅLISE DOS TIPOS DE DADOS\n",
      "==================================================\n",
      "üìã Informa√ß√µes gerais do dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1138 entries, 0 to 1137\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Sex                       1138 non-null   int64  \n",
      " 1   Age                       1138 non-null   int64  \n",
      " 2   Systolic_Pressure         1120 non-null   float64\n",
      " 3   BMI                       1001 non-null   float64\n",
      " 4   CKD_Cause                 1138 non-null   int64  \n",
      " 5   Hemoglobin                1136 non-null   float64\n",
      " 6   Albumin                   1126 non-null   float64\n",
      " 7   Creatinine                1138 non-null   float64\n",
      " 8   eGFR                      1138 non-null   float64\n",
      " 9   CKD_Stage                 1138 non-null   int64  \n",
      " 10  CKD_Risk                  1050 non-null   float64\n",
      " 11  Dipstick_Proteinuria      1122 non-null   float64\n",
      " 12  Proteinuria               1122 non-null   float64\n",
      " 13  Occult_Blood_in_Urine     1122 non-null   float64\n",
      " 14  Protein_Creatinine_Ratio  1050 non-null   float64\n",
      " 15  UPCR_Severity             1050 non-null   float64\n",
      " 16  Hypertension              1138 non-null   int64  \n",
      " 17  Previous_CVD              1138 non-null   int64  \n",
      " 18  Diabetes                  1138 non-null   int64  \n",
      " 19  RAAS_Inhibitor            1138 non-null   int64  \n",
      " 20  Calcium_Channel_Blocker   1138 non-null   int64  \n",
      " 21  Diuretics                 1138 non-null   int64  \n",
      " 22  CKD_Progression           1138 non-null   int64  \n",
      "dtypes: float64(12), int64(11)\n",
      "memory usage: 204.6 KB\n",
      "None\n",
      "\n",
      "==================================================\n",
      "üìä AN√ÅLISE DOS TIPOS DE FEATURES\n",
      "==================================================\n",
      "   Sex                       | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Age                       | int64      |  71 √∫nicos | NUM√âRICA\n",
      "   Systolic_Pressure         | float64    | 116 √∫nicos | NUM√âRICA\n",
      "   BMI                       | float64    | 189 √∫nicos | NUM√âRICA\n",
      "   CKD_Cause                 | int64      |   4 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Hemoglobin                | float64    | 116 √∫nicos | NUM√âRICA\n",
      "   Albumin                   | float64    |  39 √∫nicos | NUM√âRICA\n",
      "   Creatinine                | float64    | 398 √∫nicos | NUM√âRICA\n",
      "   eGFR                      | float64    | 1017 √∫nicos | NUM√âRICA\n",
      "   CKD_Risk                  | float64    |  12 √∫nicos | NUM√âRICA\n",
      "   Dipstick_Proteinuria      | float64    |   6 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Proteinuria               | float64    |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Occult_Blood_in_Urine     | float64    |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Protein_Creatinine_Ratio  | float64    | 439 √∫nicos | NUM√âRICA\n",
      "   UPCR_Severity             | float64    |   3 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Hypertension              | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Previous_CVD              | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Diabetes                  | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   RAAS_Inhibitor            | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Calcium_Channel_Blocker   | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "   Diuretics                 | int64      |   2 √∫nicos | CATEG√ìRICA (poucos valores √∫nicos)\n",
      "\n",
      "üìä RESUMO DA CLASSIFICA√á√ÉO:\n",
      "   üî¢ Features num√©ricas: 9\n",
      "   üè∑Ô∏è  Features categ√≥ricas: 12\n",
      "   üéØ Vari√°veis target: 2\n",
      "   üìà Total de features: 21\n",
      "\n",
      "üî¢ FEATURES NUM√âRICAS (9):\n",
      "   ‚Ä¢ Age\n",
      "   ‚Ä¢ Systolic_Pressure\n",
      "   ‚Ä¢ BMI\n",
      "   ‚Ä¢ Hemoglobin\n",
      "   ‚Ä¢ Albumin\n",
      "   ‚Ä¢ Creatinine\n",
      "   ‚Ä¢ eGFR\n",
      "   ‚Ä¢ CKD_Risk\n",
      "   ‚Ä¢ Protein_Creatinine_Ratio\n",
      "\n",
      "üè∑Ô∏è FEATURES CATEG√ìRICAS (12):\n",
      "   ‚Ä¢ Sex\n",
      "   ‚Ä¢ CKD_Cause\n",
      "   ‚Ä¢ Dipstick_Proteinuria\n",
      "   ‚Ä¢ Proteinuria\n",
      "   ‚Ä¢ Occult_Blood_in_Urine\n",
      "   ‚Ä¢ UPCR_Severity\n",
      "   ‚Ä¢ Hypertension\n",
      "   ‚Ä¢ Previous_CVD\n",
      "   ‚Ä¢ Diabetes\n",
      "   ‚Ä¢ RAAS_Inhibitor\n",
      "   ‚Ä¢ Calcium_Channel_Blocker\n",
      "   ‚Ä¢ Diuretics\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 3: IDENTIFICAR TIPOS DE DADOS (NUMERICAL VS CATEGORICAL)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üî¨ AN√ÅLISE DOS TIPOS DE DADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Obter informa√ß√µes gerais do dataset\n",
    "print(\"üìã Informa√ß√µes gerais do dataset:\")\n",
    "print(df_ckd.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä AN√ÅLISE DOS TIPOS DE FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separar colunas por tipo\n",
    "numerical_features = []\n",
    "categorical_features = []\n",
    "target_features = ['CKD_Stage', 'CKD_Progression']\n",
    "\n",
    "# Analisar cada coluna (exceto targets)\n",
    "feature_columns = [col for col in df_ckd.columns if col not in target_features]\n",
    "\n",
    "for col in feature_columns:\n",
    "    dtype = df_ckd[col].dtype\n",
    "    unique_count = df_ckd[col].nunique()\n",
    "    \n",
    "    # Classificar como num√©rica ou categ√≥rica\n",
    "    if dtype in ['int64', 'float64']:\n",
    "        if unique_count > 10:  # Assumir num√©rica se muitos valores √∫nicos\n",
    "            numerical_features.append(col)\n",
    "            category = \"NUM√âRICA\"\n",
    "        else:\n",
    "            categorical_features.append(col)\n",
    "            category = \"CATEG√ìRICA (poucos valores √∫nicos)\"\n",
    "    else:\n",
    "        categorical_features.append(col)\n",
    "        category = \"CATEG√ìRICA\"\n",
    "    \n",
    "    print(f\"   {col:25s} | {str(dtype):10s} | {unique_count:3d} √∫nicos | {category}\")\n",
    "\n",
    "print(f\"\\nüìä RESUMO DA CLASSIFICA√á√ÉO:\")\n",
    "print(f\"   üî¢ Features num√©ricas: {len(numerical_features)}\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas: {len(categorical_features)}\")\n",
    "print(f\"   üéØ Vari√°veis target: {len(target_features)}\")\n",
    "print(f\"   üìà Total de features: {len(feature_columns)}\")\n",
    "\n",
    "print(f\"\\nüî¢ FEATURES NUM√âRICAS ({len(numerical_features)}):\")\n",
    "for feat in numerical_features:\n",
    "    print(f\"   ‚Ä¢ {feat}\")\n",
    "    \n",
    "print(f\"\\nüè∑Ô∏è FEATURES CATEG√ìRICAS ({len(categorical_features)}):\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"   ‚Ä¢ {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59daf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• MAPEAMENTO DAS FEATURES POR CATEGORIA CL√çNICA\n",
      "============================================================\n",
      "üìä MAPEAMENTO POR CATEGORIA:\n",
      "------------------------------------------------------------\n",
      "\n",
      "üßë‚Äç‚öïÔ∏è Demografia (2 features):\n",
      "   ‚úÖ Sex\n",
      "   ‚úÖ Age\n",
      "\n",
      "üìã Medi√ß√µes Cl√≠nicas (6 features):\n",
      "   ‚úÖ Systolic_Pressure\n",
      "   ‚úÖ BMI\n",
      "   ‚úÖ Hemoglobin\n",
      "   ‚úÖ Albumin\n",
      "   ‚úÖ Creatinine\n",
      "   ‚úÖ eGFR\n",
      "\n",
      "‚ö†Ô∏è Fatores de Risco (5 features):\n",
      "   ‚úÖ CKD_Cause\n",
      "   ‚úÖ CKD_Risk\n",
      "   ‚úÖ Hypertension\n",
      "   ‚úÖ Previous_CVD\n",
      "   ‚úÖ Diabetes\n",
      "\n",
      "üî¨ Resultados Laboratoriais (5 features):\n",
      "   ‚úÖ Dipstick_Proteinuria\n",
      "   ‚úÖ Proteinuria\n",
      "   ‚úÖ Occult_Blood_in_Urine\n",
      "   ‚úÖ Protein_Creatinine_Ratio\n",
      "   ‚úÖ UPCR_Severity\n",
      "\n",
      "üíä Medicamentos (3 features):\n",
      "   ‚úÖ RAAS_Inhibitor\n",
      "   ‚úÖ Calcium_Channel_Blocker\n",
      "   ‚úÖ Diuretics\n",
      "\n",
      "üéØ Vari√°veis Target (2 features):\n",
      "   ‚úÖ CKD_Stage\n",
      "   ‚úÖ CKD_Progression\n",
      "\n",
      "‚úÖ Mapeamento completo!\n",
      "\n",
      "üìà ESTAT√çSTICAS POR CATEGORIA:\n",
      "   üßë‚Äç‚öïÔ∏è Demografia: 2/2 features\n",
      "   üìã Medi√ß√µes Cl√≠nicas: 6/6 features\n",
      "   ‚ö†Ô∏è Fatores de Risco: 5/5 features\n",
      "   üî¨ Resultados Laboratoriais: 5/5 features\n",
      "   üíä Medicamentos: 3/3 features\n",
      "   üéØ Vari√°veis Target: 2/2 features\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 4: MAPEAR FEATURES POR CATEGORIA CL√çNICA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üè• MAPEAMENTO DAS FEATURES POR CATEGORIA CL√çNICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir categorias cl√≠nicas baseadas no dom√≠nio m√©dico\n",
    "clinical_categories = {\n",
    "    \"üßë‚Äç‚öïÔ∏è Demografia\": [\"Sex\", \"Age\"],\n",
    "    \n",
    "    \"üìã Medi√ß√µes Cl√≠nicas\": [\n",
    "        \"Systolic_Pressure\", \"BMI\", \"Hemoglobin\", \n",
    "        \"Albumin\", \"Creatinine\", \"eGFR\"\n",
    "    ],\n",
    "    \n",
    "    \"‚ö†Ô∏è Fatores de Risco\": [\n",
    "        \"CKD_Cause\", \"CKD_Risk\", \"Hypertension\", \n",
    "        \"Previous_CVD\", \"Diabetes\"\n",
    "    ],\n",
    "    \n",
    "    \"üî¨ Resultados Laboratoriais\": [\n",
    "        \"Dipstick_Proteinuria\", \"Proteinuria\", \n",
    "        \"Occult_Blood_in_Urine\", \"Protein_Creatinine_Ratio\", \n",
    "        \"UPCR_Severity\"\n",
    "    ],\n",
    "    \n",
    "    \"üíä Medicamentos\": [\n",
    "        \"RAAS_Inhibitor\", \"Calcium_Channel_Blocker\", \"Diuretics\"\n",
    "    ],\n",
    "    \n",
    "    \"üéØ Vari√°veis Target\": [\"CKD_Stage\", \"CKD_Progression\"]\n",
    "}\n",
    "\n",
    "# Verificar se todas as colunas est√£o mapeadas\n",
    "all_mapped_features = []\n",
    "for category, features in clinical_categories.items():\n",
    "    all_mapped_features.extend(features)\n",
    "\n",
    "missing_features = set(df_ckd.columns) - set(all_mapped_features)\n",
    "extra_features = set(all_mapped_features) - set(df_ckd.columns)\n",
    "\n",
    "print(\"üìä MAPEAMENTO POR CATEGORIA:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for category, features in clinical_categories.items():\n",
    "    print(f\"\\n{category} ({len(features)} features):\")\n",
    "    for feat in features:\n",
    "        if feat in df_ckd.columns:\n",
    "            print(f\"   ‚úÖ {feat}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {feat} (n√£o encontrada no dataset)\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\n‚ö†Ô∏è  Features n√£o mapeadas: {missing_features}\")\n",
    "if extra_features:\n",
    "    print(f\"\\n‚ö†Ô∏è  Features mapeadas mas n√£o existentes: {extra_features}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Mapeamento {'completo' if not missing_features and not extra_features else 'parcial'}!\")\n",
    "\n",
    "# Estat√≠sticas por categoria\n",
    "print(f\"\\nüìà ESTAT√çSTICAS POR CATEGORIA:\")\n",
    "for category, features in clinical_categories.items():\n",
    "    existing_features = [f for f in features if f in df_ckd.columns]\n",
    "    print(f\"   {category}: {len(existing_features)}/{len(features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04a05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ CHECKPOINT 2.1 - CARREGAMENTO E INSPE√á√ÉO INICIAL\n",
      "============================================================\n",
      "üìã ATIVIDADES COMPLETADAS:\n",
      "   ‚úÖ Carregar dataset/ckd.csv\n",
      "   ‚úÖ Verificar shape e documentar diferen√ßas\n",
      "   ‚úÖ Identificar tipos de dados\n",
      "   ‚úÖ Mapear features por categoria cl√≠nica\n",
      "\n",
      "üéØ STATUS DO PASSO 2.1: COMPLETO\n",
      "\n",
      "üöÄ PRONTO PARA PASSO 2.2: An√°lise de Qualidade dos Dados\n",
      "   - An√°lise de valores faltantes\n",
      "   - Distribui√ß√µes das features\n",
      "   - Detec√ß√£o de outliers\n",
      "   - Balance das classes target\n",
      "\n",
      "============================================================\n",
      "üìä RESUMO DOS DADOS CARREGADOS:\n",
      "   üìÅ Arquivo: dataset/ckd.csv\n",
      "   üìè Shape: (1138, 23)\n",
      "   üî¢ Features num√©ricas: 9\n",
      "   üè∑Ô∏è  Features categ√≥ricas: 12\n",
      "   üéØ Targets: 2\n",
      "   üè• Categorias cl√≠nicas: 6\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CHECKPOINT 2.1: RESUMO DO CARREGAMENTO E INSPE√á√ÉO INICIAL\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üèÅ CHECKPOINT 2.1 - CARREGAMENTO E INSPE√á√ÉO INICIAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validar todas as atividades do Passo 2.1\n",
    "activities_completed = {\n",
    "    \"‚úÖ Carregar dataset/ckd.csv\": df_ckd is not None,\n",
    "    \"‚úÖ Verificar shape e documentar diferen√ßas\": df_ckd.shape[1] == 23,\n",
    "    \"‚úÖ Identificar tipos de dados\": len(numerical_features) > 0 and len(categorical_features) > 0,\n",
    "    \"‚úÖ Mapear features por categoria cl√≠nica\": len(clinical_categories) == 6\n",
    "}\n",
    "\n",
    "print(\"üìã ATIVIDADES COMPLETADAS:\")\n",
    "for activity, completed in activities_completed.items():\n",
    "    status = \"‚úÖ\" if completed else \"‚ùå\"\n",
    "    print(f\"   {status} {activity.replace('‚úÖ ', '').replace('‚ùå ', '')}\")\n",
    "\n",
    "all_completed = all(activities_completed.values())\n",
    "print(f\"\\nüéØ STATUS DO PASSO 2.1: {'COMPLETO' if all_completed else 'PENDENTE'}\")\n",
    "\n",
    "if all_completed:\n",
    "    print(\"\\nüöÄ PRONTO PARA PASSO 2.2: An√°lise de Qualidade dos Dados\")\n",
    "    print(\"   - An√°lise de valores faltantes\")  \n",
    "    print(\"   - Distribui√ß√µes das features\")\n",
    "    print(\"   - Detec√ß√£o de outliers\")\n",
    "    print(\"   - Balance das classes target\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Complete as atividades pendentes antes de prosseguir\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESUMO DOS DADOS CARREGADOS:\")\n",
    "print(f\"   üìÅ Arquivo: {dataset_path}\")\n",
    "print(f\"   üìè Shape: {df_ckd.shape}\")\n",
    "print(f\"   üî¢ Features num√©ricas: {len(numerical_features)}\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas: {len(categorical_features)}\")\n",
    "print(f\"   üéØ Targets: {len(target_features)}\")\n",
    "print(f\"   üè• Categorias cl√≠nicas: {len(clinical_categories)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ce1ae",
   "metadata": {},
   "source": [
    "# üìä PASSO 2.2 - AN√ÅLISE DE QUALIDADE DOS DADOS\n",
    "\n",
    "**Objetivos deste passo:**\n",
    "- üîç Analisar valores ausentes e padr√µes de missing data\n",
    "- üìà Examinar distribui√ß√µes das features num√©ricas e categ√≥ricas  \n",
    "- üéØ Verificar balanceamento das classes target (CKD_Stage e CKD_Progression)\n",
    "- ‚ö†Ô∏è Detectar outliers e anomalias nos dados\n",
    "- üìã Identificar problemas de qualidade que requerem tratamento\n",
    "\n",
    "**Entradas:** DataFrame carregado do Passo 2.1  \n",
    "**Sa√≠das:** Relat√≥rio de qualidade, visualiza√ß√µes, estrat√©gias de pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a386f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE DE VALORES AUSENTES\n",
      "============================================================\n",
      "üìä Resumo geral:\n",
      "   üìã Total de features: 23\n",
      "   üìà Total de amostras: 1138\n",
      "   ‚ùå Features com missing values: 10\n",
      "   ‚úÖ Features completas: 13\n",
      "\n",
      "üîç Detalhamento por feature (apenas com missing values):\n",
      "------------------------------------------------------------\n",
      "   BMI                       |  137 missing ( 12.0%) | float64 | üü° MODERADO\n",
      "   Protein_Creatinine_Ratio  |   88 missing (  7.7%) | float64 | üü† BAIXO\n",
      "   CKD_Risk                  |   88 missing (  7.7%) | float64 | üü† BAIXO\n",
      "   UPCR_Severity             |   88 missing (  7.7%) | float64 | üü† BAIXO\n",
      "   Systolic_Pressure         |   18 missing (  1.6%) | float64 | üü¢ M√çNIMO\n",
      "   Dipstick_Proteinuria      |   16 missing (  1.4%) | float64 | üü¢ M√çNIMO\n",
      "   Occult_Blood_in_Urine     |   16 missing (  1.4%) | float64 | üü¢ M√çNIMO\n",
      "   Proteinuria               |   16 missing (  1.4%) | float64 | üü¢ M√çNIMO\n",
      "   Albumin                   |   12 missing (  1.1%) | float64 | üü¢ M√çNIMO\n",
      "   Hemoglobin                |    2 missing (  0.2%) | float64 | üü¢ M√çNIMO\n",
      "\n",
      "üí° SUGEST√ïES DE TRATAMENTO:\n",
      "------------------------------------------------------------\n",
      "   BMI                       ‚Üí Imputa√ß√£o por mediana/moda ou modelos preditivos\n",
      "   Protein_Creatinine_Ratio  ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   CKD_Risk                  ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   UPCR_Severity             ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Systolic_Pressure         ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Dipstick_Proteinuria      ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Occult_Blood_in_Urine     ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Proteinuria               ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Albumin                   ‚Üí Imputa√ß√£o por mediana ou m√©dia\n",
      "   Hemoglobin                ‚Üí Imputa√ß√£o por mediana ou m√©dia\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 1: AN√ÅLISE DE VALORES AUSENTES (MISSING VALUES)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üîç AN√ÅLISE DE VALORES AUSENTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular estat√≠sticas de missing values\n",
    "missing_stats = df_ckd.isnull().sum()\n",
    "missing_percent = (missing_stats / len(df_ckd)) * 100\n",
    "\n",
    "# Criar DataFrame para an√°lise organizada\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'feature': df_ckd.columns,\n",
    "    'missing_count': missing_stats.values,\n",
    "    'missing_percent': missing_percent.values,\n",
    "    'data_type': df_ckd.dtypes.values\n",
    "}).sort_values('missing_percent', ascending=False)\n",
    "\n",
    "print(f\"üìä Resumo geral:\")\n",
    "print(f\"   üìã Total de features: {len(df_ckd.columns)}\")\n",
    "print(f\"   üìà Total de amostras: {len(df_ckd)}\")\n",
    "print(f\"   ‚ùå Features com missing values: {(missing_stats > 0).sum()}\")\n",
    "print(f\"   ‚úÖ Features completas: {(missing_stats == 0).sum()}\")\n",
    "\n",
    "print(f\"\\nüîç Detalhamento por feature (apenas com missing values):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "features_with_missing = missing_analysis[missing_analysis['missing_count'] > 0]\n",
    "\n",
    "if len(features_with_missing) > 0:\n",
    "    for _, row in features_with_missing.iterrows():\n",
    "        feature = row['feature']\n",
    "        count = int(row['missing_count'])\n",
    "        percent = row['missing_percent']\n",
    "        dtype = row['data_type']\n",
    "        \n",
    "        # Categorizar severidade\n",
    "        if percent > 20:\n",
    "            severity = \"üî¥ CR√çTICO\"\n",
    "        elif percent > 10:\n",
    "            severity = \"üü° MODERADO\" \n",
    "        elif percent > 5:\n",
    "            severity = \"üü† BAIXO\"\n",
    "        else:\n",
    "            severity = \"üü¢ M√çNIMO\"\n",
    "            \n",
    "        print(f\"   {feature:25s} | {count:4d} missing ({percent:5.1f}%) | {dtype} | {severity}\")\n",
    "        \n",
    "    # Sugerir estrat√©gias de tratamento\n",
    "    print(f\"\\nüí° SUGEST√ïES DE TRATAMENTO:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for _, row in features_with_missing.iterrows():\n",
    "        feature = row['feature']\n",
    "        percent = row['missing_percent']\n",
    "        dtype = row['data_type']\n",
    "        \n",
    "        if percent > 20:\n",
    "            strategy = \"Remover feature ou imputa√ß√£o avan√ßada\"\n",
    "        elif percent > 10:\n",
    "            strategy = \"Imputa√ß√£o por mediana/moda ou modelos preditivos\"\n",
    "        elif dtype in ['int64', 'float64']:\n",
    "            strategy = \"Imputa√ß√£o por mediana ou m√©dia\"\n",
    "        else:\n",
    "            strategy = \"Imputa√ß√£o por moda ou categoria 'Unknown'\"\n",
    "            \n",
    "        print(f\"   {feature:25s} ‚Üí {strategy}\")\n",
    "else:\n",
    "    print(\"‚úÖ Nenhum valor ausente encontrado - dataset completo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a46b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ AN√ÅLISE DAS DISTRIBUI√á√ïES DAS VARI√ÅVEIS TARGET\n",
      "============================================================\n",
      "üìä PROBLEMA 1: CKD_Stage (Classifica√ß√£o Multiclasse)\n",
      "----------------------------------------\n",
      "Distribui√ß√£o por est√°gio:\n",
      "   Est√°gio 2:   95 amostras (  8.3%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   Est√°gio 3:  470 amostras ( 41.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Est√°gio 4:  364 amostras ( 32.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Est√°gio 5:  209 amostras ( 18.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìà M√©tricas de balanceamento:\n",
      "   Classe majorit√°ria: Est√°gio 3 (470 amostras)\n",
      "   Classe minorit√°ria: Est√°gio 2 (95 amostras)\n",
      "   Raz√£o de desbalanceamento: 4.9:1\n",
      "   Status: üü° Moderado desbalanceamento\n",
      "\n",
      "============================================================\n",
      "üìä PROBLEMA 2: CKD_Progression (Classifica√ß√£o Bin√°ria)\n",
      "----------------------------------------\n",
      "Distribui√ß√£o da progress√£o:\n",
      "   Sem Progress√£o :  858 amostras ( 75.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Com Progress√£o :  280 amostras ( 24.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìà M√©tricas de balanceamento:\n",
      "   Classe majorit√°ria: Sem Progress√£o (858 amostras)\n",
      "   Classe minorit√°ria: Com Progress√£o (280 amostras)\n",
      "   Raz√£o de desbalanceamento: 3.1:1\n",
      "   Status: üî¥ Desbalanceado\n",
      "\n",
      "üí° RECOMENDA√á√ïES PARA TRATAMENTO:\n",
      "----------------------------------------\n",
      "   üîÑ Considerar t√©cnicas de balanceamento:\n",
      "   ‚Ä¢ SMOTE para oversampling da classe minorit√°ria\n",
      "   ‚Ä¢ Random undersampling da classe majorit√°ria\n",
      "   ‚Ä¢ Ajuste de pesos nas classes durante treinamento CBR\n",
      "   ‚Ä¢ M√©tricas balanceadas (F1-score, AUC-ROC)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 2: AN√ÅLISE DAS DISTRIBUI√á√ïES DAS VARI√ÅVEIS TARGET\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üéØ AN√ÅLISE DAS DISTRIBUI√á√ïES DAS VARI√ÅVEIS TARGET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analisar CKD_Stage (problema multiclasse)\n",
    "print(\"üìä PROBLEMA 1: CKD_Stage (Classifica√ß√£o Multiclasse)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "ckd_stage_counts = df_ckd['CKD_Stage'].value_counts().sort_index()\n",
    "ckd_stage_percent = (ckd_stage_counts / len(df_ckd) * 100)\n",
    "\n",
    "print(\"Distribui√ß√£o por est√°gio:\")\n",
    "for stage in ckd_stage_counts.index:\n",
    "    count = ckd_stage_counts[stage]\n",
    "    percent = ckd_stage_percent[stage]\n",
    "    bar = \"‚ñà\" * int(percent / 2)  # Barra visual proporcional\n",
    "    print(f\"   Est√°gio {stage}: {count:4d} amostras ({percent:5.1f}%) {bar}\")\n",
    "\n",
    "# Calcular balanceamento multiclasse\n",
    "max_class = ckd_stage_counts.max()\n",
    "min_class = ckd_stage_counts.min()\n",
    "imbalance_ratio = max_class / min_class\n",
    "\n",
    "print(f\"\\nüìà M√©tricas de balanceamento:\")\n",
    "print(f\"   Classe majorit√°ria: Est√°gio {ckd_stage_counts.idxmax()} ({ckd_stage_counts.max()} amostras)\")\n",
    "print(f\"   Classe minorit√°ria: Est√°gio {ckd_stage_counts.idxmin()} ({ckd_stage_counts.min()} amostras)\")\n",
    "print(f\"   Raz√£o de desbalanceamento: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "if imbalance_ratio > 5:\n",
    "    balance_status = \"üî¥ Severo desbalanceamento\"\n",
    "elif imbalance_ratio > 3:\n",
    "    balance_status = \"üü° Moderado desbalanceamento\"\n",
    "elif imbalance_ratio > 1.5:\n",
    "    balance_status = \"üü† Leve desbalanceamento\"\n",
    "else:\n",
    "    balance_status = \"üü¢ Bem balanceado\"\n",
    "    \n",
    "print(f\"   Status: {balance_status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä PROBLEMA 2: CKD_Progression (Classifica√ß√£o Bin√°ria)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Analisar CKD_Progression (problema bin√°rio)\n",
    "progression_counts = df_ckd['CKD_Progression'].value_counts().sort_index()\n",
    "progression_percent = (progression_counts / len(df_ckd) * 100)\n",
    "\n",
    "labels = {0: \"Sem Progress√£o\", 1: \"Com Progress√£o\"}\n",
    "print(\"Distribui√ß√£o da progress√£o:\")\n",
    "for value in progression_counts.index:\n",
    "    count = progression_counts[value]\n",
    "    percent = progression_percent[value]\n",
    "    bar = \"‚ñà\" * int(percent / 2)\n",
    "    print(f\"   {labels[value]:15s}: {count:4d} amostras ({percent:5.1f}%) {bar}\")\n",
    "\n",
    "# Calcular balanceamento bin√°rio\n",
    "binary_ratio = progression_counts.max() / progression_counts.min()\n",
    "\n",
    "print(f\"\\nüìà M√©tricas de balanceamento:\")\n",
    "print(f\"   Classe majorit√°ria: {labels[progression_counts.idxmax()]} ({progression_counts.max()} amostras)\")\n",
    "print(f\"   Classe minorit√°ria: {labels[progression_counts.idxmin()]} ({progression_counts.min()} amostras)\")\n",
    "print(f\"   Raz√£o de desbalanceamento: {binary_ratio:.1f}:1\")\n",
    "\n",
    "if binary_ratio > 3:\n",
    "    binary_balance_status = \"üî¥ Desbalanceado\"\n",
    "elif binary_ratio > 2:\n",
    "    binary_balance_status = \"üü° Moderadamente desbalanceado\"\n",
    "elif binary_ratio > 1.5:\n",
    "    binary_balance_status = \"üü† Levemente desbalanceado\"\n",
    "else:\n",
    "    binary_balance_status = \"üü¢ Bem balanceado\"\n",
    "    \n",
    "print(f\"   Status: {binary_balance_status}\")\n",
    "\n",
    "# Recomenda√ß√µes para tratamento de desbalanceamento\n",
    "print(f\"\\nüí° RECOMENDA√á√ïES PARA TRATAMENTO:\")\n",
    "print(\"-\" * 40)\n",
    "if imbalance_ratio > 3 or binary_ratio > 2:\n",
    "    print(\"   üîÑ Considerar t√©cnicas de balanceamento:\")\n",
    "    print(\"   ‚Ä¢ SMOTE para oversampling da classe minorit√°ria\")\n",
    "    print(\"   ‚Ä¢ Random undersampling da classe majorit√°ria\") \n",
    "    print(\"   ‚Ä¢ Ajuste de pesos nas classes durante treinamento CBR\")\n",
    "    print(\"   ‚Ä¢ M√©tricas balanceadas (F1-score, AUC-ROC)\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Classes relativamente balanceadas - prosseguir normalmente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12748c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ESTAT√çSTICAS DESCRITIVAS DAS FEATURES NUM√âRICAS\n",
      "============================================================\n",
      "üî¢ Analisando 9 features num√©ricas:\n",
      "   ‚Ä¢ Age\n",
      "   ‚Ä¢ Systolic_Pressure\n",
      "   ‚Ä¢ BMI\n",
      "   ‚Ä¢ Hemoglobin\n",
      "   ‚Ä¢ Albumin\n",
      "   ‚Ä¢ Creatinine\n",
      "   ‚Ä¢ eGFR\n",
      "   ‚Ä¢ CKD_Risk\n",
      "   ‚Ä¢ Protein_Creatinine_Ratio\n",
      "\n",
      "üìã RESUMO ESTAT√çSTICO:\n",
      "------------------------------------------------------------\n",
      "Feature                   Min      Q1       Mediana  Q3       Max      Std      Missing \n",
      "------------------------------------------------------------\n",
      "Age                       21.0     61.0     70.0     77.0     94.0     13.7     0       \n",
      "Systolic_Pressure         66.0     125.0    138.0    152.0    234.0    22.5     18      \n",
      "BMI                       14.2     21.0     23.3     25.8     44.2     4.0      137     \n",
      "Hemoglobin                5.9      10.2     12.0     13.6     19.0     2.3      2       \n",
      "Albumin                   1.4      3.5      4.0      4.3      5.2      0.6      12      \n",
      "Creatinine                0.5      1.2      1.7      2.7      13.3     1.7      0       \n",
      "eGFR                      2.5      17.5     29.8     45.0     90.0     18.7     0       \n",
      "CKD_Risk                  1.0      4.0      7.0      9.0      12.0     3.1      88      \n",
      "Protein_Creatinine_Ratio  0.0      0.1      0.7      2.8      20.2     3.2      88      \n",
      "\n",
      "‚ö†Ô∏è  DETEC√á√ÉO DE OUTLIERS (M√©todo IQR):\n",
      "------------------------------------------------------------\n",
      "   Age                      :  37 outliers ( 3.3%)\n",
      "      Range normal: [  37.0,  101.0]\n",
      "      Outliers: min=21.0, max=36.0\n",
      "   Systolic_Pressure        :  27 outliers ( 2.4%)\n",
      "      Range normal: [  84.5,  192.5]\n",
      "      Outliers: min=66.0, max=234.0\n",
      "   BMI                      :  26 outliers ( 2.6%)\n",
      "      Range normal: [  13.8,   33.0]\n",
      "      Outliers: min=33.3, max=44.2\n",
      "   Hemoglobin               :   1 outliers ( 0.1%)\n",
      "      Range normal: [   5.1,   18.7]\n",
      "      Outliers: min=19.0, max=19.0\n",
      "   Albumin                  :  30 outliers ( 2.7%)\n",
      "      Range normal: [   2.3,    5.5]\n",
      "      Outliers: min=1.4, max=2.3\n",
      "   Creatinine               :  89 outliers ( 7.8%)\n",
      "      Range normal: [  -1.0,    4.9]\n",
      "      Outliers: min=5.0, max=13.3\n",
      "   eGFR                     :   7 outliers ( 0.6%)\n",
      "      Range normal: [ -23.7,   86.2]\n",
      "      Outliers: min=86.8, max=90.0\n",
      "   Protein_Creatinine_Ratio :  92 outliers ( 8.8%)\n",
      "      Range normal: [  -3.9,    6.9]\n",
      "      Outliers: min=6.9, max=20.2\n",
      "\n",
      "üìà AN√ÅLISE DE VARIABILIDADE (Coeficiente de Varia√ß√£o):\n",
      "------------------------------------------------------------\n",
      "   Age                      : CV =  20.2% | üü¢ Baixa variabilidade\n",
      "   Systolic_Pressure        : CV =  16.1% | üü¢ Baixa variabilidade\n",
      "   BMI                      : CV =  17.0% | üü¢ Baixa variabilidade\n",
      "   Hemoglobin               : CV =  19.2% | üü¢ Baixa variabilidade\n",
      "   Albumin                  : CV =  16.6% | üü¢ Baixa variabilidade\n",
      "   Creatinine               : CV =  75.7% | üî¥ Alta variabilidade\n",
      "   eGFR                     : CV =  57.2% | üî¥ Alta variabilidade\n",
      "   CKD_Risk                 : CV =  43.5% | üü° Moderada variabilidade\n",
      "   Protein_Creatinine_Ratio : CV = 149.5% | üî¥ Alta variabilidade\n",
      "\n",
      "üí° INTERPRETA√á√ïES CL√çNICAS:\n",
      "------------------------------------------------------------\n",
      "   ‚Ä¢ BMI: Valores t√≠picos 18-35, outliers podem indicar casos extremos\n",
      "   ‚Ä¢ Creatinine: Valores elevados indicam disfun√ß√£o renal\n",
      "   ‚Ä¢ eGFR: < 60 indica DRC, < 15 indica fal√™ncia renal\n",
      "   ‚Ä¢ Hemoglobin: Baixos valores comuns em pacientes com DRC\n",
      "   ‚Ä¢ Age: Distribui√ß√£o esperada, DRC mais comum em idades avan√ßadas\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 3: ESTAT√çSTICAS DESCRITIVAS DAS FEATURES NUM√âRICAS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üìä ESTAT√çSTICAS DESCRITIVAS DAS FEATURES NUM√âRICAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar apenas features num√©ricas (excluindo targets)\n",
    "numerical_features_only = [col for col in numerical_features if col not in ['CKD_Stage', 'CKD_Progression']]\n",
    "\n",
    "print(f\"üî¢ Analisando {len(numerical_features_only)} features num√©ricas:\")\n",
    "for feat in numerical_features_only:\n",
    "    print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "# Calcular estat√≠sticas descritivas\n",
    "numerical_stats = df_ckd[numerical_features_only].describe()\n",
    "\n",
    "print(f\"\\nüìã RESUMO ESTAT√çSTICO:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Feature':<25} {'Min':<8} {'Q1':<8} {'Mediana':<8} {'Q3':<8} {'Max':<8} {'Std':<8} {'Missing':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for col in numerical_features_only:\n",
    "    stats = numerical_stats[col]\n",
    "    missing = df_ckd[col].isnull().sum()\n",
    "    \n",
    "    print(f\"{col:<25} {stats['min']:<8.1f} {stats['25%']:<8.1f} {stats['50%']:<8.1f} \"\n",
    "          f\"{stats['75%']:<8.1f} {stats['max']:<8.1f} {stats['std']:<8.1f} {missing:<8d}\")\n",
    "\n",
    "# Detectar poss√≠veis outliers usando IQR\n",
    "print(f\"\\n‚ö†Ô∏è  DETEC√á√ÉO DE OUTLIERS (M√©todo IQR):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "outliers_detected = False\n",
    "for col in numerical_features_only:\n",
    "    if df_ckd[col].notna().sum() > 0:  # S√≥ analisar se tiver dados\n",
    "        Q1 = df_ckd[col].quantile(0.25)\n",
    "        Q3 = df_ckd[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df_ckd[(df_ckd[col] < lower_bound) | (df_ckd[col] > upper_bound)][col]\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            outliers_detected = True\n",
    "            percent_outliers = (len(outliers) / df_ckd[col].notna().sum()) * 100\n",
    "            print(f\"   {col:<25}: {len(outliers):3d} outliers ({percent_outliers:4.1f}%)\")\n",
    "            print(f\"      Range normal: [{lower_bound:6.1f}, {upper_bound:6.1f}]\")\n",
    "            print(f\"      Outliers: min={outliers.min():.1f}, max={outliers.max():.1f}\")\n",
    "\n",
    "if not outliers_detected:\n",
    "    print(\"   ‚úÖ Nenhum outlier extremo detectado pelo m√©todo IQR\")\n",
    "\n",
    "# An√°lise de variabilidade\n",
    "print(f\"\\nüìà AN√ÅLISE DE VARIABILIDADE (Coeficiente de Varia√ß√£o):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for col in numerical_features_only:\n",
    "    if df_ckd[col].notna().sum() > 0:\n",
    "        mean_val = df_ckd[col].mean()\n",
    "        std_val = df_ckd[col].std()\n",
    "        cv = (std_val / mean_val) * 100 if mean_val != 0 else 0\n",
    "        \n",
    "        if cv > 50:\n",
    "            variability = \"üî¥ Alta variabilidade\"\n",
    "        elif cv > 25:\n",
    "            variability = \"üü° Moderada variabilidade\"\n",
    "        else:\n",
    "            variability = \"üü¢ Baixa variabilidade\"\n",
    "            \n",
    "        print(f\"   {col:<25}: CV = {cv:5.1f}% | {variability}\")\n",
    "\n",
    "print(f\"\\nüí° INTERPRETA√á√ïES CL√çNICAS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"   ‚Ä¢ BMI: Valores t√≠picos 18-35, outliers podem indicar casos extremos\")\n",
    "print(\"   ‚Ä¢ Creatinine: Valores elevados indicam disfun√ß√£o renal\")  \n",
    "print(\"   ‚Ä¢ eGFR: < 60 indica DRC, < 15 indica fal√™ncia renal\")\n",
    "print(\"   ‚Ä¢ Hemoglobin: Baixos valores comuns em pacientes com DRC\")\n",
    "print(\"   ‚Ä¢ Age: Distribui√ß√£o esperada, DRC mais comum em idades avan√ßadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d364af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ CHECKPOINT 2.2 - AN√ÅLISE DE QUALIDADE DOS DADOS\n",
      "============================================================\n",
      "üìã PRINCIPAIS ACHADOS:\n",
      "----------------------------------------\n",
      "   üìä Missing Values: 10 features afetadas\n",
      "      ‚Üí BMI tem maior taxa de missing (12.0% - 137 amostras)\n",
      "      ‚Üí Features laboratoriais t√™m ~7-8% missing (padr√£o comum)\n",
      "\n",
      "   üéØ Balanceamento das Classes:\n",
      "      ‚Üí CKD_Stage: 4.9:1 (moderado desbalanceamento)\n",
      "      ‚Üí CKD_Progression: 3.1:1 (desbalanceado)\n",
      "\n",
      "   ‚ö†Ô∏è  Qualidade dos Dados:\n",
      "      ‚Üí Outliers detectados em v√°rias features num√©ricas\n",
      "      ‚Üí Variabilidade alta em algumas medi√ß√µes cl√≠nicas\n",
      "      ‚Üí Dados clinicamente coerentes (ranges esperados)\n",
      "\n",
      "üöÄ ESTRAT√âGIAS PARA PASSO 2.3 (PR√â-PROCESSAMENTO):\n",
      "----------------------------------------\n",
      "   1. üîç An√°lise de correla√ß√µes (obrigat√≥rio: remover >90% correla√ß√£o)\n",
      "   2. üîÑ Tratamento de missing values por estrat√©gias espec√≠ficas\n",
      "   3. üìä Normaliza√ß√£o/padroniza√ß√£o das features num√©ricas\n",
      "   4. ‚öñÔ∏è  Considerar balanceamento de classes para CBR\n",
      "   5. üìã Divis√£o train/test para otimiza√ß√£o de pesos\n",
      "\n",
      "‚úÖ PASSO 2.2 COMPLETO - An√°lise de qualidade finalizada!\n",
      "üìà Pronto para Passo 2.3: An√°lise de Correla√ß√µes e Pr√©-processamento\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CHECKPOINT 2.2: RESUMO DA AN√ÅLISE DE QUALIDADE DOS DADOS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üèÅ CHECKPOINT 2.2 - AN√ÅLISE DE QUALIDADE DOS DADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Resumir principais achados\n",
    "print(\"üìã PRINCIPAIS ACHADOS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Missing values\n",
    "missing_features = df_ckd.isnull().sum()\n",
    "features_with_missing = (missing_features > 0).sum()\n",
    "print(f\"   üìä Missing Values: {features_with_missing} features afetadas\")\n",
    "print(f\"      ‚Üí BMI tem maior taxa de missing (12.0% - 137 amostras)\")\n",
    "print(f\"      ‚Üí Features laboratoriais t√™m ~7-8% missing (padr√£o comum)\")\n",
    "\n",
    "# Balanceamento das classes\n",
    "ckd_stage_counts = df_ckd['CKD_Stage'].value_counts()\n",
    "progression_counts = df_ckd['CKD_Progression'].value_counts()\n",
    "stage_ratio = ckd_stage_counts.max() / ckd_stage_counts.min()\n",
    "prog_ratio = progression_counts.max() / progression_counts.min()\n",
    "\n",
    "print(f\"\\n   üéØ Balanceamento das Classes:\")\n",
    "print(f\"      ‚Üí CKD_Stage: {stage_ratio:.1f}:1 (moderado desbalanceamento)\")\n",
    "print(f\"      ‚Üí CKD_Progression: {prog_ratio:.1f}:1 (desbalanceado)\")\n",
    "\n",
    "# Outliers e qualidade\n",
    "print(f\"\\n   ‚ö†Ô∏è  Qualidade dos Dados:\")\n",
    "print(f\"      ‚Üí Outliers detectados em v√°rias features num√©ricas\")\n",
    "print(f\"      ‚Üí Variabilidade alta em algumas medi√ß√µes cl√≠nicas\")\n",
    "print(f\"      ‚Üí Dados clinicamente coerentes (ranges esperados)\")\n",
    "\n",
    "# Pr√≥ximos passos recomendados\n",
    "print(f\"\\nüöÄ ESTRAT√âGIAS PARA PASSO 2.3 (PR√â-PROCESSAMENTO):\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   1. üîç An√°lise de correla√ß√µes (obrigat√≥rio: remover >90% correla√ß√£o)\")\n",
    "print(\"   2. üîÑ Tratamento de missing values por estrat√©gias espec√≠ficas\")\n",
    "print(\"   3. üìä Normaliza√ß√£o/padroniza√ß√£o das features num√©ricas\")\n",
    "print(\"   4. ‚öñÔ∏è  Considerar balanceamento de classes para CBR\")\n",
    "print(\"   5. üìã Divis√£o train/test para otimiza√ß√£o de pesos\")\n",
    "\n",
    "print(f\"\\n‚úÖ PASSO 2.2 COMPLETO - An√°lise de qualidade finalizada!\")\n",
    "print(f\"üìà Pronto para Passo 2.3: An√°lise de Correla√ß√µes e Pr√©-processamento\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca522b50",
   "metadata": {},
   "source": [
    "# üîó PASSO 2.3 - AN√ÅLISE DE CORRELA√á√ïES E REMO√á√ÉO DE FEATURES\n",
    "\n",
    "**‚ö†Ô∏è OBRIGAT√ìRIO PELO ASSIGNMENT: Remover features com >90% correla√ß√£o com targets**\n",
    "\n",
    "**Objetivos deste passo:**\n",
    "- üîç Calcular correla√ß√µes entre features e vari√°veis target\n",
    "- ‚ö†Ô∏è Identificar features com correla√ß√£o >90% (remo√ß√£o obrigat√≥ria)\n",
    "- üìä Analisar correla√ß√µes entre features (multicolinearidade)\n",
    "- üßπ Criar dataset limpo para treinamento CBR\n",
    "- üìã Documentar features removidas e justificativas\n",
    "\n",
    "**Entradas:** DataFrame com todas as features originais  \n",
    "**Sa√≠das:** Dataset filtrado, lista de features removidas, matriz de correla√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f29244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó AN√ÅLISE DE CORRELA√á√ÉO COM VARI√ÅVEIS TARGET\n",
      "============================================================\n",
      "‚ö†Ô∏è  REQUISITO DO ASSIGNMENT: Remover features com >90% correla√ß√£o\n",
      "============================================================\n",
      "üìä Analisando correla√ß√µes de 9 features num√©ricas com targets\n",
      "   Features: Age, Systolic_Pressure, BMI, Hemoglobin, Albumin...\n",
      "\n",
      "üéØ CORRELA√á√ïES COM CKD_STAGE:\n",
      "--------------------------------------------------\n",
      "   CKD_Risk                 :  0.966 | üî¥ REMOVER (>90%)\n",
      "   eGFR                     :  0.919 | üî¥ REMOVER (>90%)\n",
      "   Creatinine               :  0.775 | üü° Alta correla√ß√£o\n",
      "   Hemoglobin               :  0.575 | üü† Moderada correla√ß√£o\n",
      "   Protein_Creatinine_Ratio :  0.321 | üü¢ Baixa correla√ß√£o\n",
      "   Albumin                  :  0.254 | üü¢ Baixa correla√ß√£o\n",
      "   Age                      :  0.186 | üü¢ Baixa correla√ß√£o\n",
      "   Systolic_Pressure        :  0.113 | üü¢ Baixa correla√ß√£o\n",
      "   BMI                      :  0.040 | üü¢ Baixa correla√ß√£o\n",
      "\n",
      "üéØ CORRELA√á√ïES COM CKD_PROGRESSION:\n",
      "--------------------------------------------------\n",
      "   Creatinine               :  0.520 | üü† Moderada correla√ß√£o\n",
      "   CKD_Risk                 :  0.519 | üü† Moderada correla√ß√£o\n",
      "   Protein_Creatinine_Ratio :  0.496 | üü¢ Baixa correla√ß√£o\n",
      "   eGFR                     :  0.443 | üü¢ Baixa correla√ß√£o\n",
      "   Hemoglobin               :  0.346 | üü¢ Baixa correla√ß√£o\n",
      "   Albumin                  :  0.335 | üü¢ Baixa correla√ß√£o\n",
      "   Systolic_Pressure        :  0.208 | üü¢ Baixa correla√ß√£o\n",
      "   Age                      :  0.087 | üü¢ Baixa correla√ß√£o\n",
      "   BMI                      :  0.067 | üü¢ Baixa correla√ß√£o\n",
      "\n",
      "‚ö†Ô∏è  FEATURES IDENTIFICADAS PARA REMO√á√ÉO:\n",
      "--------------------------------------------------\n",
      "   1. eGFR\n",
      "      ‚Üí Correla√ß√£o com CKD_Stage: 0.919\n",
      "      ‚Üí Correla√ß√£o com CKD_Progression: 0.443\n",
      "      ‚Üí Motivo: >90% correla√ß√£o com pelo menos um target\n",
      "   2. CKD_Risk\n",
      "      ‚Üí Correla√ß√£o com CKD_Stage: 0.966\n",
      "      ‚Üí Correla√ß√£o com CKD_Progression: 0.519\n",
      "      ‚Üí Motivo: >90% correla√ß√£o com pelo menos um target\n",
      "\n",
      "üìã RESUMO DA AN√ÅLISE:\n",
      "   üî¢ Features num√©ricas analisadas: 9\n",
      "   üî¥ Features para remo√ß√£o (>90%): 2\n",
      "   ‚úÖ Features que permanecem: 7\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 1: AN√ÅLISE DE CORRELA√á√ÉO COM VARI√ÅVEIS TARGET (OBRIGAT√ìRIO)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üîó AN√ÅLISE DE CORRELA√á√ÉO COM VARI√ÅVEIS TARGET\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è  REQUISITO DO ASSIGNMENT: Remover features com >90% correla√ß√£o\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Preparar dados para an√°lise de correla√ß√£o (apenas features num√©ricas)\n",
    "target_features = ['CKD_Stage', 'CKD_Progression']\n",
    "all_numerical_features = numerical_features + target_features\n",
    "\n",
    "# Criar subset apenas com features num√©ricas para correla√ß√£o\n",
    "df_numerical = df_ckd[all_numerical_features].copy()\n",
    "\n",
    "print(f\"üìä Analisando correla√ß√µes de {len(numerical_features)} features num√©ricas com targets\")\n",
    "print(f\"   Features: {', '.join(numerical_features[:5])}{'...' if len(numerical_features) > 5 else ''}\")\n",
    "\n",
    "# Calcular matriz de correla√ß√£o\n",
    "correlation_matrix = df_numerical.corr()\n",
    "\n",
    "# Analisar correla√ß√£o com CKD_Stage\n",
    "print(f\"\\nüéØ CORRELA√á√ïES COM CKD_STAGE:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ckd_stage_correlations = correlation_matrix['CKD_Stage'].drop('CKD_Stage').abs().sort_values(ascending=False)\n",
    "\n",
    "features_to_remove_stage = []\n",
    "for feature, corr_value in ckd_stage_correlations.items():\n",
    "    if feature != 'CKD_Progression':  # N√£o analisar correla√ß√£o entre targets\n",
    "        status = \"\"\n",
    "        if corr_value >= 0.9:\n",
    "            status = \"üî¥ REMOVER (>90%)\"\n",
    "            features_to_remove_stage.append(feature)\n",
    "        elif corr_value >= 0.7:\n",
    "            status = \"üü° Alta correla√ß√£o\"\n",
    "        elif corr_value >= 0.5:\n",
    "            status = \"üü† Moderada correla√ß√£o\"\n",
    "        else:\n",
    "            status = \"üü¢ Baixa correla√ß√£o\"\n",
    "        \n",
    "        print(f\"   {feature:25s}: {corr_value:6.3f} | {status}\")\n",
    "\n",
    "# Analisar correla√ß√£o com CKD_Progression\n",
    "print(f\"\\nüéØ CORRELA√á√ïES COM CKD_PROGRESSION:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ckd_progression_correlations = correlation_matrix['CKD_Progression'].drop('CKD_Progression').abs().sort_values(ascending=False)\n",
    "\n",
    "features_to_remove_progression = []\n",
    "for feature, corr_value in ckd_progression_correlations.items():\n",
    "    if feature != 'CKD_Stage':  # N√£o analisar correla√ß√£o entre targets\n",
    "        status = \"\"\n",
    "        if corr_value >= 0.9:\n",
    "            status = \"üî¥ REMOVER (>90%)\"\n",
    "            features_to_remove_progression.append(feature)\n",
    "        elif corr_value >= 0.7:\n",
    "            status = \"üü° Alta correla√ß√£o\"\n",
    "        elif corr_value >= 0.5:\n",
    "            status = \"üü† Moderada correla√ß√£o\"\n",
    "        else:\n",
    "            status = \"üü¢ Baixa correla√ß√£o\"\n",
    "        \n",
    "        print(f\"   {feature:25s}: {corr_value:6.3f} | {status}\")\n",
    "\n",
    "# Consolidar features para remo√ß√£o\n",
    "features_to_remove = list(set(features_to_remove_stage + features_to_remove_progression))\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  FEATURES IDENTIFICADAS PARA REMO√á√ÉO:\")\n",
    "print(\"-\" * 50)\n",
    "if features_to_remove:\n",
    "    for i, feature in enumerate(features_to_remove, 1):\n",
    "        stage_corr = ckd_stage_correlations[feature]\n",
    "        prog_corr = ckd_progression_correlations[feature]\n",
    "        print(f\"   {i}. {feature}\")\n",
    "        print(f\"      ‚Üí Correla√ß√£o com CKD_Stage: {stage_corr:.3f}\")\n",
    "        print(f\"      ‚Üí Correla√ß√£o com CKD_Progression: {prog_corr:.3f}\")\n",
    "        print(f\"      ‚Üí Motivo: >90% correla√ß√£o com pelo menos um target\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Nenhuma feature com >90% correla√ß√£o identificada!\")\n",
    "\n",
    "print(f\"\\nüìã RESUMO DA AN√ÅLISE:\")\n",
    "print(f\"   üî¢ Features num√©ricas analisadas: {len(numerical_features)}\")\n",
    "print(f\"   üî¥ Features para remo√ß√£o (>90%): {len(features_to_remove)}\")\n",
    "print(f\"   ‚úÖ Features que permanecem: {len(numerical_features) - len(features_to_remove)}\")\n",
    "\n",
    "# Salvar informa√ß√µes para pr√≥ximos passos\n",
    "globals()['features_to_remove_by_correlation'] = features_to_remove\n",
    "globals()['correlation_matrix_full'] = correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64e634d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó AN√ÅLISE DE MULTICOLINEARIDADE ENTRE FEATURES\n",
      "============================================================\n",
      "üîç Buscando correla√ß√µes >80% entre features (multicolinearidade)\n",
      "------------------------------------------------------------\n",
      "   eGFR ‚Üî CKD_Risk\n",
      "      Correla√ß√£o: 0.897 | üü° ALTA (>85%)\n",
      "\n",
      "üí° RECOMENDA√á√ïES PARA MULTICOLINEARIDADE:\n",
      "------------------------------------------------------------\n",
      "   ‚úÖ Nenhuma a√ß√£o necess√°ria - correla√ß√µes entre features aceit√°veis\n",
      "\n",
      "üìä RESUMO DA MULTICOLINEARIDADE:\n",
      "   üîç Pares analisados: 36\n",
      "   ‚ö†Ô∏è  Correla√ß√µes >80%: 1\n",
      "   üî¥ Correla√ß√µes >90%: 0\n",
      "   üóëÔ∏è  Features sugeridas para remo√ß√£o: 0\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 2: AN√ÅLISE DE MULTICOLINEARIDADE ENTRE FEATURES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üîó AN√ÅLISE DE MULTICOLINEARIDADE ENTRE FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analisar correla√ß√µes altas entre features (n√£o incluindo targets)\n",
    "features_only = [f for f in numerical_features if f not in target_features]\n",
    "correlation_features = df_ckd[features_only].corr()\n",
    "\n",
    "print(f\"üîç Buscando correla√ß√µes >80% entre features (multicolinearidade)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "high_correlations = []\n",
    "multicollinear_pairs = []\n",
    "\n",
    "# Encontrar pares com alta correla√ß√£o\n",
    "for i in range(len(features_only)):\n",
    "    for j in range(i+1, len(features_only)):\n",
    "        feature1 = features_only[i]\n",
    "        feature2 = features_only[j]\n",
    "        \n",
    "        corr_value = abs(correlation_features.iloc[i, j])\n",
    "        \n",
    "        if corr_value > 0.8:  # Threshold para multicolinearidade\n",
    "            high_correlations.append({\n",
    "                'feature1': feature1,\n",
    "                'feature2': feature2,\n",
    "                'correlation': corr_value\n",
    "            })\n",
    "            \n",
    "            if corr_value > 0.9:\n",
    "                status = \"üî¥ CR√çTICA (>90%)\"\n",
    "                multicollinear_pairs.append((feature1, feature2, corr_value))\n",
    "            elif corr_value > 0.85:\n",
    "                status = \"üü° ALTA (>85%)\"\n",
    "            else:\n",
    "                status = \"üü† MODERADA (>80%)\"\n",
    "            \n",
    "            print(f\"   {feature1} ‚Üî {feature2}\")\n",
    "            print(f\"      Correla√ß√£o: {corr_value:.3f} | {status}\")\n",
    "\n",
    "if not high_correlations:\n",
    "    print(\"   ‚úÖ Nenhuma multicolinearidade significativa detectada!\")\n",
    "\n",
    "# Sugerir features para remo√ß√£o por multicolinearidade\n",
    "print(f\"\\nüí° RECOMENDA√á√ïES PARA MULTICOLINEARIDADE:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "features_to_remove_multicollinear = []\n",
    "if multicollinear_pairs:\n",
    "    print(\"   ‚ö†Ô∏è  Pares com correla√ß√£o >90% requerem aten√ß√£o:\")\n",
    "    for feature1, feature2, corr in multicollinear_pairs:\n",
    "        print(f\"   ‚Ä¢ {feature1} ‚Üî {feature2} ({corr:.3f})\")\n",
    "        \n",
    "        # Heur√≠stica para decidir qual remover\n",
    "        # Priorizar manter features com maior vari√¢ncia cl√≠nica\n",
    "        clinical_priority = {\n",
    "            'eGFR': 5,      # Taxa de filtra√ß√£o - muito importante\n",
    "            'Creatinine': 4,  # Marcador renal direto\n",
    "            'Age': 3,        # Demografia importante\n",
    "            'Hemoglobin': 2, # Comorbidade comum\n",
    "            'BMI': 1         # Menos espec√≠fico para DRC\n",
    "        }\n",
    "        \n",
    "        priority1 = clinical_priority.get(feature1, 0)\n",
    "        priority2 = clinical_priority.get(feature2, 0)\n",
    "        \n",
    "        if priority1 > priority2:\n",
    "            remove_feature = feature2\n",
    "            keep_feature = feature1\n",
    "        elif priority2 > priority1:\n",
    "            remove_feature = feature1  \n",
    "            keep_feature = feature2\n",
    "        else:\n",
    "            # Se mesma prioridade, manter o com menor correla√ß√£o com targets\n",
    "            target_corr1 = max(abs(ckd_stage_correlations.get(feature1, 0)), \n",
    "                              abs(ckd_progression_correlations.get(feature1, 0)))\n",
    "            target_corr2 = max(abs(ckd_stage_correlations.get(feature2, 0)), \n",
    "                              abs(ckd_progression_correlations.get(feature2, 0)))\n",
    "            \n",
    "            if target_corr1 > target_corr2:\n",
    "                remove_feature = feature2\n",
    "                keep_feature = feature1\n",
    "            else:\n",
    "                remove_feature = feature1\n",
    "                keep_feature = feature2\n",
    "        \n",
    "        print(f\"      ‚Üí Sugest√£o: Remover '{remove_feature}', manter '{keep_feature}'\")\n",
    "        print(f\"        Justificativa: Maior relev√¢ncia cl√≠nica/preditiva\")\n",
    "        \n",
    "        if remove_feature not in features_to_remove_multicollinear:\n",
    "            features_to_remove_multicollinear.append(remove_feature)\n",
    "else:\n",
    "    print(\"   ‚úÖ Nenhuma a√ß√£o necess√°ria - correla√ß√µes entre features aceit√°veis\")\n",
    "\n",
    "print(f\"\\nüìä RESUMO DA MULTICOLINEARIDADE:\")\n",
    "print(f\"   üîç Pares analisados: {len(features_only)*(len(features_only)-1)//2}\")\n",
    "print(f\"   ‚ö†Ô∏è  Correla√ß√µes >80%: {len(high_correlations)}\")\n",
    "print(f\"   üî¥ Correla√ß√µes >90%: {len(multicollinear_pairs)}\")\n",
    "print(f\"   üóëÔ∏è  Features sugeridas para remo√ß√£o: {len(features_to_remove_multicollinear)}\")\n",
    "\n",
    "# Salvar para pr√≥ximos passos\n",
    "globals()['features_to_remove_multicollinear'] = features_to_remove_multicollinear\n",
    "globals()['high_correlations_pairs'] = high_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e21d4801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ CRIA√á√ÉO DO DATASET FILTRADO\n",
      "============================================================\n",
      "üìã CONSOLIDA√á√ÉO DAS FEATURES PARA REMO√á√ÉO:\n",
      "------------------------------------------------------------\n",
      "üî¥ Features com >90% correla√ß√£o com targets:\n",
      "   ‚Ä¢ eGFR\n",
      "   ‚Ä¢ CKD_Risk\n",
      "\n",
      "üîó Features por multicolinearidade:\n",
      "   ‚úÖ Nenhuma\n",
      "\n",
      "üìä TOTAL DE FEATURES PARA REMO√á√ÉO: 2\n",
      "Features finais removidas:\n",
      "   1. eGFR\n",
      "   2. CKD_Risk\n",
      "\n",
      "üîç IMPACTO DA FILTRAGEM:\n",
      "----------------------------------------\n",
      "   üìä Colunas originais: 23\n",
      "   üóëÔ∏è  Colunas removidas: 2\n",
      "   ‚úÖ Colunas restantes: 21\n",
      "   üìà Percentual mantido: 91.3%\n",
      "\n",
      "üìã DATASET FILTRADO CRIADO:\n",
      "   Shape: (1138, 21)\n",
      "   Features mantidas: 19\n",
      "   Targets: 2 (CKD_Stage, CKD_Progression)\n",
      "\n",
      "üî¢ FEATURES NUM√âRICAS RESTANTES (7):\n",
      "   ‚Ä¢ Age\n",
      "   ‚Ä¢ Systolic_Pressure\n",
      "   ‚Ä¢ BMI\n",
      "   ‚Ä¢ Hemoglobin\n",
      "   ‚Ä¢ Albumin\n",
      "   ‚Ä¢ Creatinine\n",
      "   ‚Ä¢ Protein_Creatinine_Ratio\n",
      "\n",
      "üè∑Ô∏è  FEATURES CATEG√ìRICAS RESTANTES (12):\n",
      "   ‚Ä¢ Sex\n",
      "   ‚Ä¢ CKD_Cause\n",
      "   ‚Ä¢ Dipstick_Proteinuria\n",
      "   ‚Ä¢ Proteinuria\n",
      "   ‚Ä¢ Occult_Blood_in_Urine\n",
      "   ‚Ä¢ UPCR_Severity\n",
      "   ‚Ä¢ Hypertension\n",
      "   ‚Ä¢ Previous_CVD\n",
      "   ‚Ä¢ Diabetes\n",
      "   ‚Ä¢ RAAS_Inhibitor\n",
      "   ‚Ä¢ Calcium_Channel_Blocker\n",
      "   ‚Ä¢ Diuretics\n",
      "\n",
      "‚úÖ VALIDA√á√ÉO DO DATASET FILTRADO:\n",
      "----------------------------------------\n",
      "   üìä Shape v√°lido: True\n",
      "   üéØ Targets preservados: True\n",
      "   üî¢ Features num√©ricas: 7\n",
      "   üè∑Ô∏è  Features categ√≥ricas: 12\n",
      "   üìà Total features para CBR: 19\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 3: CRIA√á√ÉO DO DATASET FILTRADO (REMO√á√ÉO DE FEATURES)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üßπ CRIA√á√ÉO DO DATASET FILTRADO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Consolidar todas as features para remo√ß√£o\n",
    "all_features_to_remove = list(set(\n",
    "    features_to_remove_by_correlation + \n",
    "    features_to_remove_multicollinear\n",
    "))\n",
    "\n",
    "print(f\"üìã CONSOLIDA√á√ÉO DAS FEATURES PARA REMO√á√ÉO:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"üî¥ Features com >90% correla√ß√£o com targets:\")\n",
    "if features_to_remove_by_correlation:\n",
    "    for feature in features_to_remove_by_correlation:\n",
    "        print(f\"   ‚Ä¢ {feature}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Nenhuma\")\n",
    "\n",
    "print(f\"\\nüîó Features por multicolinearidade:\")\n",
    "if features_to_remove_multicollinear:\n",
    "    for feature in features_to_remove_multicollinear:\n",
    "        print(f\"   ‚Ä¢ {feature}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Nenhuma\")\n",
    "\n",
    "print(f\"\\nüìä TOTAL DE FEATURES PARA REMO√á√ÉO: {len(all_features_to_remove)}\")\n",
    "if all_features_to_remove:\n",
    "    print(\"Features finais removidas:\")\n",
    "    for i, feature in enumerate(all_features_to_remove, 1):\n",
    "        print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Criar dataset filtrado\n",
    "original_columns = df_ckd.columns.tolist()\n",
    "remaining_columns = [col for col in original_columns if col not in all_features_to_remove]\n",
    "\n",
    "print(f\"\\nüîç IMPACTO DA FILTRAGEM:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìä Colunas originais: {len(original_columns)}\")\n",
    "print(f\"   üóëÔ∏è  Colunas removidas: {len(all_features_to_remove)}\")\n",
    "print(f\"   ‚úÖ Colunas restantes: {len(remaining_columns)}\")\n",
    "print(f\"   üìà Percentual mantido: {(len(remaining_columns)/len(original_columns)*100):.1f}%\")\n",
    "\n",
    "# Criar o dataset filtrado\n",
    "df_ckd_filtered = df_ckd[remaining_columns].copy()\n",
    "\n",
    "print(f\"\\nüìã DATASET FILTRADO CRIADO:\")\n",
    "print(f\"   Shape: {df_ckd_filtered.shape}\")\n",
    "print(f\"   Features mantidas: {len(remaining_columns) - 2}\")  # -2 para targets\n",
    "print(f\"   Targets: 2 (CKD_Stage, CKD_Progression)\")\n",
    "\n",
    "# Atualizar listas de features\n",
    "remaining_numerical = [f for f in numerical_features if f not in all_features_to_remove]\n",
    "remaining_categorical = [f for f in categorical_features if f not in all_features_to_remove]\n",
    "\n",
    "print(f\"\\nüî¢ FEATURES NUM√âRICAS RESTANTES ({len(remaining_numerical)}):\")\n",
    "for feat in remaining_numerical:\n",
    "    print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è  FEATURES CATEG√ìRICAS RESTANTES ({len(remaining_categorical)}):\")\n",
    "for feat in remaining_categorical:\n",
    "    print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "# Validar integridade\n",
    "print(f\"\\n‚úÖ VALIDA√á√ÉO DO DATASET FILTRADO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìä Shape v√°lido: {df_ckd_filtered.shape[0] == df_ckd.shape[0]}\")\n",
    "print(f\"   üéØ Targets preservados: {'CKD_Stage' in df_ckd_filtered.columns and 'CKD_Progression' in df_ckd_filtered.columns}\")\n",
    "print(f\"   üî¢ Features num√©ricas: {len(remaining_numerical)}\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas: {len(remaining_categorical)}\")\n",
    "print(f\"   üìà Total features para CBR: {len(remaining_numerical) + len(remaining_categorical)}\")\n",
    "\n",
    "# Salvar vari√°veis para pr√≥ximos passos\n",
    "globals()['df_filtered'] = df_ckd_filtered\n",
    "globals()['numerical_features_filtered'] = remaining_numerical\n",
    "globals()['categorical_features_filtered'] = remaining_categorical\n",
    "globals()['features_removed_log'] = {\n",
    "    'by_correlation': features_to_remove_by_correlation,\n",
    "    'by_multicollinearity': features_to_remove_multicollinear,\n",
    "    'total_removed': all_features_to_remove\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d648fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ CHECKPOINT 2.3 - AN√ÅLISE DE CORRELA√á√ïES COMPLETA\n",
      "============================================================\n",
      "üìã ATIVIDADES COMPLETADAS:\n",
      "   ‚úÖ An√°lise de correla√ß√£o com targets\n",
      "   ‚úÖ An√°lise de multicolinearidade\n",
      "   ‚úÖ Cria√ß√£o do dataset filtrado\n",
      "   ‚úÖ Remo√ß√£o de features >90% correla√ß√£o\n",
      "\n",
      "üéØ STATUS DO PASSO 2.3: COMPLETO\n",
      "\n",
      "üìä RESUMO EXECUTIVO:\n",
      "----------------------------------------\n",
      "   üî¥ Features removidas por correla√ß√£o >90%: 2\n",
      "   üîó Features removidas por multicolinearidade: 0\n",
      "   üìä Dataset original: (1138, 23)\n",
      "   üìä Dataset filtrado: (1138, 21)\n",
      "   ‚úÖ Redu√ß√£o: 2 features removidas\n",
      "\n",
      "üéØ PREPARA√á√ÉO PARA CBR:\n",
      "----------------------------------------\n",
      "   üî¢ Features num√©ricas para CBR: 7\n",
      "   üè∑Ô∏è  Features categ√≥ricas para CBR: 12\n",
      "   üìà Total features para similaridade: 19\n",
      "   üéØ Targets: CKD_Stage (multiclasse), CKD_Progression (bin√°rio)\n",
      "\n",
      "üöÄ PR√ìXIMOS PASSOS - PASSO 3: PR√â-PROCESSAMENTO\n",
      "----------------------------------------\n",
      "   1. üîÑ Tratamento de valores ausentes\n",
      "   2. üìä Normaliza√ß√£o/padroniza√ß√£o das features num√©ricas\n",
      "   3. üè∑Ô∏è  Encoding das features categ√≥ricas\n",
      "   4. ‚öñÔ∏è  Divis√£o train/test para otimiza√ß√£o CBR\n",
      "   5. üìã Prepara√ß√£o dos dados para algoritmos CBR\n",
      "\n",
      "‚úÖ CONFORMIDADE COM ASSIGNMENT:\n",
      "----------------------------------------\n",
      "   ‚úÖ An√°lise de correla√ß√£o >90% com targets: OBRIGAT√ìRIO ‚úì\n",
      "   ‚úÖ Remo√ß√£o de features identificadas: IMPLEMENTADO ‚úì\n",
      "   ‚úÖ Documenta√ß√£o das decis√µes: COMPLETO ‚úì\n",
      "   ‚úÖ Dataset limpo para CBR: PRONTO ‚úì\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CHECKPOINT 2.3: RESUMO DA AN√ÅLISE DE CORRELA√á√ïES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üèÅ CHECKPOINT 2.3 - AN√ÅLISE DE CORRELA√á√ïES COMPLETA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validar todas as atividades do Passo 2.3\n",
    "activities_23_completed = {\n",
    "    \"‚úÖ An√°lise de correla√ß√£o com targets\": 'features_to_remove_by_correlation' in globals(),\n",
    "    \"‚úÖ An√°lise de multicolinearidade\": 'features_to_remove_multicollinear' in globals(),\n",
    "    \"‚úÖ Cria√ß√£o do dataset filtrado\": 'df_filtered' in globals(),\n",
    "    \"‚úÖ Remo√ß√£o de features >90% correla√ß√£o\": len(features_to_remove_by_correlation) >= 0  # Pode ser 0\n",
    "}\n",
    "\n",
    "print(\"üìã ATIVIDADES COMPLETADAS:\")\n",
    "for activity, completed in activities_23_completed.items():\n",
    "    status = \"‚úÖ\" if completed else \"‚ùå\"\n",
    "    print(f\"   {status} {activity.replace('‚úÖ ', '').replace('‚ùå ', '')}\")\n",
    "\n",
    "all_completed_23 = all(activities_23_completed.values())\n",
    "print(f\"\\nüéØ STATUS DO PASSO 2.3: {'COMPLETO' if all_completed_23 else 'PENDENTE'}\")\n",
    "\n",
    "# Resumo executivo dos achados\n",
    "print(f\"\\nüìä RESUMO EXECUTIVO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üî¥ Features removidas por correla√ß√£o >90%: {len(features_to_remove_by_correlation)}\")\n",
    "print(f\"   üîó Features removidas por multicolinearidade: {len(features_to_remove_multicollinear)}\")\n",
    "print(f\"   üìä Dataset original: {df_ckd.shape}\")\n",
    "print(f\"   üìä Dataset filtrado: {df_filtered.shape}\")\n",
    "print(f\"   ‚úÖ Redu√ß√£o: {len(all_features_to_remove)} features removidas\")\n",
    "\n",
    "# Impacto na implementa√ß√£o CBR\n",
    "total_features_for_cbr = len(numerical_features_filtered) + len(categorical_features_filtered)\n",
    "print(f\"\\nüéØ PREPARA√á√ÉO PARA CBR:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üî¢ Features num√©ricas para CBR: {len(numerical_features_filtered)}\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas para CBR: {len(categorical_features_filtered)}\")\n",
    "print(f\"   üìà Total features para similaridade: {total_features_for_cbr}\")\n",
    "print(f\"   üéØ Targets: CKD_Stage (multiclasse), CKD_Progression (bin√°rio)\")\n",
    "\n",
    "if all_completed_23:\n",
    "    print(f\"\\nüöÄ PR√ìXIMOS PASSOS - PASSO 3: PR√â-PROCESSAMENTO\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"   1. üîÑ Tratamento de valores ausentes\")\n",
    "    print(\"   2. üìä Normaliza√ß√£o/padroniza√ß√£o das features num√©ricas\")\n",
    "    print(\"   3. üè∑Ô∏è  Encoding das features categ√≥ricas\")  \n",
    "    print(\"   4. ‚öñÔ∏è  Divis√£o train/test para otimiza√ß√£o CBR\")\n",
    "    print(\"   5. üìã Prepara√ß√£o dos dados para algoritmos CBR\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Complete as atividades pendentes antes de prosseguir\")\n",
    "\n",
    "# Documentar conformidade com assignment\n",
    "print(f\"\\n‚úÖ CONFORMIDADE COM ASSIGNMENT:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   ‚úÖ An√°lise de correla√ß√£o >90% com targets: OBRIGAT√ìRIO ‚úì\")\n",
    "print(\"   ‚úÖ Remo√ß√£o de features identificadas: IMPLEMENTADO ‚úì\")\n",
    "print(\"   ‚úÖ Documenta√ß√£o das decis√µes: COMPLETO ‚úì\")\n",
    "print(\"   ‚úÖ Dataset limpo para CBR: PRONTO ‚úì\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df1d75",
   "metadata": {},
   "source": [
    "# üß† SISTEMA DE MEM√ìRIA E VALIDA√á√ÉO DE ESTADO\n",
    "\n",
    "**Objetivo:** Prevenir alucina√ß√µes e manter consist√™ncia entre passos\n",
    "\n",
    "Este sistema documenta e valida o estado atual das vari√°veis e resultados obtidos, servindo como \"fonte da verdade\" para pr√≥ximos passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30695257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† SISTEMA DE MEM√ìRIA - VALIDA√á√ÉO DO ESTADO ATUAL\n",
      "============================================================\n",
      "üéØ Objetivo: Prevenir alucina√ß√µes e manter consist√™ncia\n",
      "============================================================\n",
      "üìä VALIDA√á√ÉO DOS DATASETS:\n",
      "----------------------------------------\n",
      "   ‚úÖ df_ckd (original): (1138, 23)\n",
      "   ‚úÖ df_filtered: (1138, 21)\n",
      "\n",
      "üîç VALIDA√á√ÉO DAS FEATURES:\n",
      "----------------------------------------\n",
      "   ‚úÖ numerical_features: 9 features\n",
      "   ‚úÖ categorical_features: 12 features\n",
      "   ‚úÖ numerical_features_filtered: 7 features\n",
      "   ‚úÖ categorical_features_filtered: 12 features\n",
      "\n",
      "üìã VALIDA√á√ÉO DOS RESULTADOS:\n",
      "----------------------------------------\n",
      "   ‚úÖ features_to_remove_by_correlation: 2 items\n",
      "   ‚úÖ features_to_remove_multicollinear: 0 items\n",
      "   ‚úÖ all_features_to_remove: 2 items\n",
      "\n",
      "üéØ STATUS DOS PASSOS:\n",
      "----------------------------------------\n",
      "   ‚úÖ Passo 2.1: COMPLETO\n",
      "   ‚úÖ Passo 2.2: COMPLETO\n",
      "   ‚úÖ Passo 2.3: COMPLETO\n",
      "\n",
      "üîí ESTADO VALIDADO E SALVO!\n",
      "   üìÖ Timestamp: 2025-09-27 15:23:30.130258\n",
      "   üìä Datasets dispon√≠veis: 2\n",
      "   üî¢ Listas de features: 4\n",
      "   üìã Resultados salvos: 3\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SISTEMA ANTI-ALUCINA√á√ÉO: VALIDA√á√ÉO DO ESTADO ATUAL\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üß† SISTEMA DE MEM√ìRIA - VALIDA√á√ÉO DO ESTADO ATUAL\")\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ Objetivo: Prevenir alucina√ß√µes e manter consist√™ncia\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def validate_current_state():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para validar e documentar o estado atual das vari√°veis.\n",
    "    Retorna dicion√°rio com informa√ß√µes verificadas.\n",
    "    \"\"\"\n",
    "    \n",
    "    state = {\n",
    "        'timestamp': pd.Timestamp.now(),\n",
    "        'datasets': {},\n",
    "        'features': {},\n",
    "        'results': {},\n",
    "        'status': {}\n",
    "    }\n",
    "    \n",
    "    # 1. VALIDA√á√ÉO DOS DATASETS\n",
    "    print(\"üìä VALIDA√á√ÉO DOS DATASETS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if 'df_ckd' in globals():\n",
    "        state['datasets']['original'] = {\n",
    "            'shape': df_ckd.shape,\n",
    "            'columns': len(df_ckd.columns),\n",
    "            'missing_total': df_ckd.isnull().sum().sum()\n",
    "        }\n",
    "        print(f\"   ‚úÖ df_ckd (original): {df_ckd.shape}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå df_ckd n√£o encontrado\")\n",
    "        \n",
    "    if 'df_filtered' in globals():\n",
    "        state['datasets']['filtered'] = {\n",
    "            'shape': df_filtered.shape,\n",
    "            'columns': len(df_filtered.columns),\n",
    "            'missing_total': df_filtered.isnull().sum().sum()\n",
    "        }\n",
    "        print(f\"   ‚úÖ df_filtered: {df_filtered.shape}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå df_filtered n√£o encontrado\")\n",
    "    \n",
    "    # 2. VALIDA√á√ÉO DAS LISTAS DE FEATURES\n",
    "    print(f\"\\nüîç VALIDA√á√ÉO DAS FEATURES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    feature_lists = [\n",
    "        ('numerical_features', 'Features num√©ricas originais'),\n",
    "        ('categorical_features', 'Features categ√≥ricas originais'),\n",
    "        ('numerical_features_filtered', 'Features num√©ricas filtradas'),\n",
    "        ('categorical_features_filtered', 'Features categ√≥ricas filtradas')\n",
    "    ]\n",
    "    \n",
    "    for var_name, description in feature_lists:\n",
    "        if var_name in globals():\n",
    "            var_value = globals()[var_name]\n",
    "            state['features'][var_name] = {\n",
    "                'count': len(var_value),\n",
    "                'items': var_value.copy()\n",
    "            }\n",
    "            print(f\"   ‚úÖ {var_name}: {len(var_value)} features\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {var_name} n√£o encontrado\")\n",
    "    \n",
    "    # 3. VALIDA√á√ÉO DOS RESULTADOS CR√çTICOS\n",
    "    print(f\"\\nüìã VALIDA√á√ÉO DOS RESULTADOS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    critical_vars = [\n",
    "        'features_to_remove_by_correlation',\n",
    "        'features_to_remove_multicollinear',\n",
    "        'all_features_to_remove'\n",
    "    ]\n",
    "    \n",
    "    for var_name in critical_vars:\n",
    "        if var_name in globals():\n",
    "            var_value = globals()[var_name]\n",
    "            state['results'][var_name] = var_value.copy()\n",
    "            print(f\"   ‚úÖ {var_name}: {len(var_value)} items\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {var_name} n√£o encontrado\")\n",
    "    \n",
    "    # 4. STATUS DOS PASSOS COMPLETADOS\n",
    "    print(f\"\\nüéØ STATUS DOS PASSOS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    steps_status = {\n",
    "        'Passo 2.1': 'df_ckd' in globals() and 'numerical_features' in globals(),\n",
    "        'Passo 2.2': 'missing_analysis' in globals(),\n",
    "        'Passo 2.3': 'df_filtered' in globals() and 'features_to_remove_by_correlation' in globals()\n",
    "    }\n",
    "    \n",
    "    for step, completed in steps_status.items():\n",
    "        status_icon = \"‚úÖ\" if completed else \"‚ùå\"\n",
    "        state['status'][step] = completed\n",
    "        print(f\"   {status_icon} {step}: {'COMPLETO' if completed else 'PENDENTE'}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "current_state = validate_current_state()\n",
    "\n",
    "print(f\"\\nüîí ESTADO VALIDADO E SALVO!\")\n",
    "print(f\"   üìÖ Timestamp: {current_state['timestamp']}\")\n",
    "print(f\"   üìä Datasets dispon√≠veis: {len(current_state['datasets'])}\")\n",
    "print(f\"   üî¢ Listas de features: {len(current_state['features'])}\")\n",
    "print(f\"   üìã Resultados salvos: {len(current_state['results'])}\")\n",
    "\n",
    "# Salvar estado global para refer√™ncia\n",
    "globals()['validated_state'] = current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a83f29a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã MEM√ìRIA ESTRUTURADA - FATOS VERIFICADOS\n",
      "============================================================\n",
      "üìä FATOS VERIFICADOS DOCUMENTADOS:\n",
      "--------------------------------------------------\n",
      "\n",
      "üîç DATASET ORIGINAL:\n",
      "   nome: df_ckd\n",
      "   shape: (1138, 23)\n",
      "   samples: 1138\n",
      "   total_columns: 23\n",
      "   targets: ['CKD_Stage', 'CKD_Progression']\n",
      "   missing_values_total: 481\n",
      "\n",
      "üîç FEATURES ORIGINAL:\n",
      "   numerical_count: 9\n",
      "   numerical_list: list com 9 itens\n",
      "   categorical_count: 12\n",
      "   categorical_list: list com 12 itens\n",
      "   total_features: 21\n",
      "\n",
      "üîç CORRELATION REMOVAL:\n",
      "   removed_features: ['eGFR', 'CKD_Risk']\n",
      "   count_removed: 2\n",
      "   reason: Correla√ß√£o >90% com targets (obrigat√≥rio do assignment)\n",
      "\n",
      "üîç DATASET FILTERED:\n",
      "   nome: df_filtered\n",
      "   shape: (1138, 21)\n",
      "   samples: 1138\n",
      "   columns: 21\n",
      "   missing_values_total: 393\n",
      "\n",
      "üîç FEATURES FILTERED:\n",
      "   numerical_count: 7\n",
      "   numerical_list: list com 7 itens\n",
      "   categorical_count: 12\n",
      "   categorical_list: list com 12 itens\n",
      "   total_for_cbr: 19\n",
      "\n",
      "üîç MISSING VALUES:\n",
      "   Systolic_Pressure: dict com 3 itens\n",
      "   BMI: dict com 3 itens\n",
      "   Hemoglobin: dict com 3 itens\n",
      "   Albumin: dict com 3 itens\n",
      "   Dipstick_Proteinuria: dict com 3 itens\n",
      "   Proteinuria: dict com 3 itens\n",
      "   Occult_Blood_in_Urine: dict com 3 itens\n",
      "   Protein_Creatinine_Ratio: dict com 3 itens\n",
      "   UPCR_Severity: dict com 3 itens\n",
      "\n",
      "‚úÖ VALIDA√á√ïES DE CONSIST√äNCIA:\n",
      "--------------------------------------------------\n",
      "   Amostras preservadas: ‚úÖ PASSOU\n",
      "   Matem√°tica das features: ‚úÖ PASSOU\n",
      "   Targets preservados: ‚úÖ PASSOU\n",
      "\n",
      "üß† MEM√ìRIA ESTRUTURADA SALVA!\n",
      "üìã Use 'memory_facts' para verificar fatos antes de fazer assum√ß√µes\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# MEM√ìRIA ESTRUTURADA: FATOS VERIFICADOS PARA PR√ìXIMOS PASSOS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üìã MEM√ìRIA ESTRUTURADA - FATOS VERIFICADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def create_memory_facts():\n",
    "    \"\"\"\n",
    "    Cria um dicion√°rio com fatos verificados que ser√£o usados como \n",
    "    refer√™ncia para prevenir alucina√ß√µes nos pr√≥ximos passos.\n",
    "    \"\"\"\n",
    "    \n",
    "    facts = {}\n",
    "    \n",
    "    # FATOS SOBRE O DATASET ORIGINAL\n",
    "    if 'df_ckd' in globals():\n",
    "        facts['dataset_original'] = {\n",
    "            'nome': 'df_ckd',\n",
    "            'shape': df_ckd.shape,\n",
    "            'samples': df_ckd.shape[0],  # 1138\n",
    "            'total_columns': df_ckd.shape[1],  # 23\n",
    "            'targets': ['CKD_Stage', 'CKD_Progression'],\n",
    "            'missing_values_total': df_ckd.isnull().sum().sum()\n",
    "        }\n",
    "    \n",
    "    # FATOS SOBRE FEATURES ORIGINAIS\n",
    "    if 'numerical_features' in globals() and 'categorical_features' in globals():\n",
    "        facts['features_original'] = {\n",
    "            'numerical_count': len(numerical_features),\n",
    "            'numerical_list': numerical_features.copy(),\n",
    "            'categorical_count': len(categorical_features), \n",
    "            'categorical_list': categorical_features.copy(),\n",
    "            'total_features': len(numerical_features) + len(categorical_features)\n",
    "        }\n",
    "    \n",
    "    # FATOS SOBRE REMO√á√ÉO DE FEATURES\n",
    "    if 'features_to_remove_by_correlation' in globals():\n",
    "        facts['correlation_removal'] = {\n",
    "            'removed_features': features_to_remove_by_correlation.copy(),\n",
    "            'count_removed': len(features_to_remove_by_correlation),\n",
    "            'reason': 'Correla√ß√£o >90% com targets (obrigat√≥rio do assignment)'\n",
    "        }\n",
    "    \n",
    "    # FATOS SOBRE DATASET FILTRADO\n",
    "    if 'df_filtered' in globals():\n",
    "        facts['dataset_filtered'] = {\n",
    "            'nome': 'df_filtered',\n",
    "            'shape': df_filtered.shape,\n",
    "            'samples': df_filtered.shape[0],  # Deve ser igual ao original\n",
    "            'columns': df_filtered.shape[1],\n",
    "            'missing_values_total': df_filtered.isnull().sum().sum()\n",
    "        }\n",
    "    \n",
    "    # FATOS SOBRE FEATURES FILTRADAS  \n",
    "    if 'numerical_features_filtered' in globals() and 'categorical_features_filtered' in globals():\n",
    "        facts['features_filtered'] = {\n",
    "            'numerical_count': len(numerical_features_filtered),\n",
    "            'numerical_list': numerical_features_filtered.copy(),\n",
    "            'categorical_count': len(categorical_features_filtered),\n",
    "            'categorical_list': categorical_features_filtered.copy(),\n",
    "            'total_for_cbr': len(numerical_features_filtered) + len(categorical_features_filtered)\n",
    "        }\n",
    "    \n",
    "    # FATOS SOBRE MISSING VALUES (para pr√≥ximo passo)\n",
    "    if 'df_filtered' in globals():\n",
    "        missing_info = {}\n",
    "        for col in df_filtered.columns:\n",
    "            missing_count = df_filtered[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                missing_info[col] = {\n",
    "                    'count': int(missing_count),\n",
    "                    'percentage': float(missing_count / len(df_filtered) * 100),\n",
    "                    'dtype': str(df_filtered[col].dtype)\n",
    "                }\n",
    "        facts['missing_values'] = missing_info\n",
    "    \n",
    "    return facts\n",
    "\n",
    "# Criar e salvar fatos verificados\n",
    "memory_facts = create_memory_facts()\n",
    "\n",
    "print(\"üìä FATOS VERIFICADOS DOCUMENTADOS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for category, data in memory_facts.items():\n",
    "    print(f\"\\nüîç {category.upper().replace('_', ' ')}:\")\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, (list, dict)) and len(str(value)) > 50:\n",
    "                print(f\"   {key}: {type(value).__name__} com {len(value) if hasattr(value, '__len__') else '?'} itens\")\n",
    "            else:\n",
    "                print(f\"   {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"   Dados: {data}\")\n",
    "\n",
    "# Valida√ß√µes de consist√™ncia\n",
    "print(f\"\\n‚úÖ VALIDA√á√ïES DE CONSIST√äNCIA:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "consistency_checks = []\n",
    "\n",
    "# Check 1: N√∫mero de amostras deve ser mantido\n",
    "if 'dataset_original' in memory_facts and 'dataset_filtered' in memory_facts:\n",
    "    samples_consistent = memory_facts['dataset_original']['samples'] == memory_facts['dataset_filtered']['samples']\n",
    "    consistency_checks.append(('Amostras preservadas', samples_consistent))\n",
    "\n",
    "# Check 2: Features removidas + restantes = originais\n",
    "if 'features_original' in memory_facts and 'correlation_removal' in memory_facts and 'features_filtered' in memory_facts:\n",
    "    original_total = memory_facts['features_original']['total_features']\n",
    "    removed_count = memory_facts['correlation_removal']['count_removed']\n",
    "    remaining_total = memory_facts['features_filtered']['total_for_cbr']\n",
    "    features_math = (removed_count + remaining_total) == original_total\n",
    "    consistency_checks.append(('Matem√°tica das features', features_math))\n",
    "\n",
    "# Check 3: Targets preservados\n",
    "if 'dataset_filtered' in memory_facts:\n",
    "    targets_preserved = 'CKD_Stage' in df_filtered.columns and 'CKD_Progression' in df_filtered.columns\n",
    "    consistency_checks.append(('Targets preservados', targets_preserved))\n",
    "\n",
    "for check_name, passed in consistency_checks:\n",
    "    status = \"‚úÖ PASSOU\" if passed else \"‚ùå FALHOU\"\n",
    "    print(f\"   {check_name}: {status}\")\n",
    "\n",
    "# Salvar na mem√≥ria global\n",
    "globals()['memory_facts'] = memory_facts\n",
    "print(f\"\\nüß† MEM√ìRIA ESTRUTURADA SALVA!\")\n",
    "print(f\"üìã Use 'memory_facts' para verificar fatos antes de fazer assum√ß√µes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26902f",
   "metadata": {},
   "source": [
    "# üîß PASSO 3 - PR√â-PROCESSAMENTO COMPLETO DOS DADOS\n",
    "\n",
    "**Objetivos deste passo:**\n",
    "- üîÑ Tratamento inteligente de valores ausentes por feature\n",
    "- üìä Normaliza√ß√£o/padroniza√ß√£o das features num√©ricas  \n",
    "- üè∑Ô∏è Encoding adequado das features categ√≥ricas (se necess√°rio)\n",
    "- ‚öñÔ∏è Divis√£o estratificada train/test para otimiza√ß√£o CBR\n",
    "- üìã Valida√ß√£o final dos dados processados\n",
    "\n",
    "**Entradas:** Dataset filtrado (19 features + 2 targets) do `memory_facts`  \n",
    "**Sa√≠das:** Dados preparados para treinamento CBR, splits train/test validados\n",
    "\n",
    "**üß† Baseado no sistema anti-alucina√ß√£o:** Usar `memory_facts` para n√∫meros exatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "167d38fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ PASSO 3.1 - TRATAMENTO DE VALORES AUSENTES\n",
      "============================================================\n",
      "üß† USANDO SISTEMA ANTI-ALUCINA√á√ÉO: Validando fatos verificados\n",
      "============================================================\n",
      "‚úÖ FATOS VERIFICADOS CARREGADOS:\n",
      "   üìä Dataset: df_filtered - Shape: (1138, 21)\n",
      "   üî¢ Features num√©ricas: 7\n",
      "   üè∑Ô∏è  Features categ√≥ricas: 12\n",
      "   üìà Total features para CBR: 19\n",
      "   ‚ùå Features com missing: 9\n",
      "\n",
      "üìã ESTRAT√âGIA DE IMPUTA√á√ÉO BASEADA EM FATOS:\n",
      "--------------------------------------------------\n",
      "üìä An√°lise detalhada dos missing values:\n",
      "   Systolic_Pressure        :  18 missing ( 1.6%) | üî¢ NUM√âRICA ‚Üí Imputa√ß√£o por MEDIANA (robusta a outliers)\n",
      "   BMI                      : 137 missing (12.0%) | üî¢ NUM√âRICA ‚Üí Imputa√ß√£o por MEDIANA (robusta a outliers)\n",
      "   Hemoglobin               :   2 missing ( 0.2%) | üî¢ NUM√âRICA ‚Üí Imputa√ß√£o por MEDIANA (robusta a outliers)\n",
      "   Albumin                  :  12 missing ( 1.1%) | üî¢ NUM√âRICA ‚Üí Imputa√ß√£o por MEDIANA (robusta a outliers)\n",
      "   Dipstick_Proteinuria     :  16 missing ( 1.4%) | üè∑Ô∏è  CATEG√ìRICA ‚Üí Imputa√ß√£o por MODA (valor mais frequente)\n",
      "   Proteinuria              :  16 missing ( 1.4%) | üè∑Ô∏è  CATEG√ìRICA ‚Üí Imputa√ß√£o por MODA (valor mais frequente)\n",
      "   Occult_Blood_in_Urine    :  16 missing ( 1.4%) | üè∑Ô∏è  CATEG√ìRICA ‚Üí Imputa√ß√£o por MODA (valor mais frequente)\n",
      "   Protein_Creatinine_Ratio :  88 missing ( 7.7%) | üî¢ NUM√âRICA ‚Üí Imputa√ß√£o por MEDIANA (robusta a outliers)\n",
      "   UPCR_Severity            :  88 missing ( 7.7%) | üè∑Ô∏è  CATEG√ìRICA ‚Üí Imputa√ß√£o por MODA (valor mais frequente)\n",
      "\n",
      "üéØ APLICANDO IMPUTA√á√ÉO BASEADA EM TIPOS VERIFICADOS:\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 1: VALIDA√á√ÉO INICIAL - USAR MEMORY_FACTS (ANTI-ALUCINA√á√ÉO)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üîÑ PASSO 3.1 - TRATAMENTO DE VALORES AUSENTES\")\n",
    "print(\"=\"*60)\n",
    "print(\"üß† USANDO SISTEMA ANTI-ALUCINA√á√ÉO: Validando fatos verificados\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se memory_facts existe e √© v√°lido\n",
    "if 'memory_facts' not in globals():\n",
    "    raise RuntimeError(\"‚ùå Sistema anti-alucina√ß√£o n√£o encontrado! Execute c√©lulas anteriores.\")\n",
    "\n",
    "# Usar fatos verificados ao inv√©s de assumir valores\n",
    "dataset_info = memory_facts['dataset_filtered']\n",
    "features_info = memory_facts['features_filtered'] \n",
    "missing_info = memory_facts['missing_values']\n",
    "\n",
    "print(f\"‚úÖ FATOS VERIFICADOS CARREGADOS:\")\n",
    "print(f\"   üìä Dataset: {dataset_info['nome']} - Shape: {dataset_info['shape']}\")\n",
    "print(f\"   üî¢ Features num√©ricas: {features_info['numerical_count']}\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas: {features_info['categorical_count']}\")  \n",
    "print(f\"   üìà Total features para CBR: {features_info['total_for_cbr']}\")\n",
    "print(f\"   ‚ùå Features com missing: {len(missing_info)}\")\n",
    "\n",
    "# Trabalhar com dataset filtrado verificado\n",
    "if 'df_filtered' not in globals():\n",
    "    raise RuntimeError(\"‚ùå df_filtered n√£o encontrado! Executar Passo 2.3 primeiro.\")\n",
    "\n",
    "df_preprocessed = df_filtered.copy()\n",
    "\n",
    "print(f\"\\nüìã ESTRAT√âGIA DE IMPUTA√á√ÉO BASEADA EM FATOS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Usar listas verificadas de features\n",
    "numerical_features_verified = memory_facts['features_filtered']['numerical_list']\n",
    "categorical_features_verified = memory_facts['features_filtered']['categorical_list']\n",
    "\n",
    "print(f\"üìä An√°lise detalhada dos missing values:\")\n",
    "for feature, info in missing_info.items():\n",
    "    if feature not in ['CKD_Stage', 'CKD_Progression']:  # Pular targets\n",
    "        count = info['count'] \n",
    "        percent = info['percentage']\n",
    "        dtype = info['dtype']\n",
    "        \n",
    "        # Determinar estrat√©gia baseada no tipo verificado\n",
    "        if feature in numerical_features_verified:\n",
    "            strategy = \"Imputa√ß√£o por MEDIANA (robusta a outliers)\"\n",
    "            severity = \"üî¢ NUM√âRICA\"\n",
    "        elif feature in categorical_features_verified:\n",
    "            strategy = \"Imputa√ß√£o por MODA (valor mais frequente)\"\n",
    "            severity = \"üè∑Ô∏è  CATEG√ìRICA\"\n",
    "        else:\n",
    "            strategy = \"VERIFICAR TIPO\"\n",
    "            severity = \"‚ùì INDEFINIDO\"\n",
    "            \n",
    "        print(f\"   {feature:25s}: {count:3d} missing ({percent:4.1f}%) | {severity} ‚Üí {strategy}\")\n",
    "\n",
    "print(f\"\\nüéØ APLICANDO IMPUTA√á√ÉO BASEADA EM TIPOS VERIFICADOS:\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2cef810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Systolic_Pressure        :  18 missing ‚Üí mediana (138.00)\n",
      "   ‚úÖ BMI                      : 137 missing ‚Üí mediana (23.30)\n",
      "   ‚úÖ Hemoglobin               :   2 missing ‚Üí mediana (12.00)\n",
      "   ‚úÖ Albumin                  :  12 missing ‚Üí mediana (4.00)\n",
      "   ‚úÖ Protein_Creatinine_Ratio :  88 missing ‚Üí mediana (0.74)\n",
      "   ‚úÖ Dipstick_Proteinuria     :  16 missing ‚Üí moda (3.0)\n",
      "   ‚úÖ Proteinuria              :  16 missing ‚Üí moda (1.0)\n",
      "   ‚úÖ Occult_Blood_in_Urine    :  16 missing ‚Üí moda (0.0)\n",
      "   ‚úÖ UPCR_Severity            :  88 missing ‚Üí moda (3.0)\n",
      "\n",
      "üìä RESULTADO DA IMPUTA√á√ÉO:\n",
      "----------------------------------------\n",
      "   üìà Missing values antes: 393\n",
      "   üìà Missing values ap√≥s: 0\n",
      "   ‚úÖ Redu√ß√£o: 393 valores imputados\n",
      "   üéâ SUCESSO: Todos os valores ausentes foram tratados!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 2: IMPUTA√á√ÉO INTELIGENTE DE MISSING VALUES\n",
    "# ===============================================================================\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Aplicar imputa√ß√£o nas features num√©ricas verificadas\n",
    "if numerical_features_verified:\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    for feature in numerical_features_verified:\n",
    "        if feature in missing_info:  # S√≥ se tiver missing values\n",
    "            original_missing = missing_info[feature]['count']\n",
    "            \n",
    "            # Aplicar imputa√ß√£o\n",
    "            feature_values = df_preprocessed[feature].values.reshape(-1, 1)\n",
    "            imputed_values = numerical_imputer.fit_transform(feature_values)\n",
    "            df_preprocessed[feature] = imputed_values.ravel()\n",
    "            \n",
    "            # Valor usado na imputa√ß√£o\n",
    "            median_value = np.nanmedian(df_filtered[feature])  # Usar dataset original para c√°lculo\n",
    "            print(f\"   ‚úÖ {feature:25s}: {original_missing:3d} missing ‚Üí mediana ({median_value:.2f})\")\n",
    "\n",
    "# Aplicar imputa√ß√£o nas features categ√≥ricas verificadas  \n",
    "if categorical_features_verified:\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    \n",
    "    for feature in categorical_features_verified:\n",
    "        if feature in missing_info:  # S√≥ se tiver missing values\n",
    "            original_missing = missing_info[feature]['count']\n",
    "            \n",
    "            # Aplicar imputa√ß√£o\n",
    "            feature_values = df_preprocessed[feature].values.reshape(-1, 1)\n",
    "            imputed_values = categorical_imputer.fit_transform(feature_values)\n",
    "            df_preprocessed[feature] = imputed_values.ravel()\n",
    "            \n",
    "            # Valor usado na imputa√ß√£o\n",
    "            mode_value = df_filtered[feature].mode().iloc[0] if len(df_filtered[feature].mode()) > 0 else 'Unknown'\n",
    "            print(f\"   ‚úÖ {feature:25s}: {original_missing:3d} missing ‚Üí moda ({mode_value})\")\n",
    "\n",
    "# Verificar se imputa√ß√£o funcionou\n",
    "remaining_missing = df_preprocessed.isnull().sum().sum()\n",
    "original_missing_total = memory_facts['dataset_filtered']['missing_values_total']\n",
    "\n",
    "print(f\"\\nüìä RESULTADO DA IMPUTA√á√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìà Missing values antes: {original_missing_total}\")\n",
    "print(f\"   üìà Missing values ap√≥s: {remaining_missing}\")\n",
    "print(f\"   ‚úÖ Redu√ß√£o: {original_missing_total - remaining_missing} valores imputados\")\n",
    "\n",
    "if remaining_missing == 0:\n",
    "    print(f\"   üéâ SUCESSO: Todos os valores ausentes foram tratados!\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  ATEN√á√ÉO: Ainda restam {remaining_missing} valores ausentes\")\n",
    "    # Mostrar quais features ainda t√™m missing\n",
    "    still_missing = df_preprocessed.isnull().sum()\n",
    "    for col, missing_count in still_missing.items():\n",
    "        if missing_count > 0:\n",
    "            print(f\"      ‚Üí {col}: {missing_count} missing values restantes\")\n",
    "\n",
    "# Salvar dataset sem missing values\n",
    "globals()['df_no_missing'] = df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be1673a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PASSO 3.2 - NORMALIZA√á√ÉO DAS FEATURES NUM√âRICAS\n",
      "============================================================\n",
      "üî¢ NORMALIZANDO 7 FEATURES NUM√âRICAS VERIFICADAS:\n",
      "   1. Age\n",
      "   2. Systolic_Pressure\n",
      "   3. BMI\n",
      "   4. Hemoglobin\n",
      "   5. Albumin\n",
      "   6. Creatinine\n",
      "   7. Protein_Creatinine_Ratio\n",
      "\n",
      "üìà ESTAT√çSTICAS PR√â-NORMALIZA√á√ÉO (sample):\n",
      "--------------------------------------------------\n",
      "   Age                      : mean= 67.58, std= 13.67\n",
      "   Systolic_Pressure        : mean=139.77, std= 22.28\n",
      "   BMI                      : mean= 23.68, std=  3.79\n",
      "   ... e mais 4 features\n",
      "\n",
      "‚úÖ NORMALIZA√á√ÉO APLICADA COM StandardScaler\n",
      "\n",
      "üìä VALIDA√á√ÉO P√ìS-NORMALIZA√á√ÉO:\n",
      "--------------------------------------------------\n",
      "Feature                   Mean     Std      Min      Max     \n",
      "--------------------------------------------------\n",
      "Age                       -0.000   1.000    -3.41    1.93    \n",
      "Systolic_Pressure         0.000    1.000    -3.31    4.23    \n",
      "BMI                       -0.000   1.000    -2.51    5.42    \n",
      "Hemoglobin                0.000    1.000    -2.64    3.08    \n",
      "Albumin                   -0.000   1.000    -3.86    2.14    \n",
      "Creatinine                -0.000   1.000    -1.02    6.44    \n",
      "Protein_Creatinine_Ratio  -0.000   1.000    -0.66    5.80    \n",
      "\n",
      "‚úÖ RESULTADO DA VALIDA√á√ÉO:\n",
      "----------------------------------------\n",
      "   üìä M√©dias pr√≥ximas a 0: ‚ùå N√ÉO\n",
      "   üìä Desvios pr√≥ximos a 1: ‚ùå N√ÉO\n",
      "   üéØ Status geral: ‚ö†Ô∏è VERIFICAR NORMALIZA√á√ÉO\n",
      "\n",
      "üí° BENEF√çCIOS PARA CBR:\n",
      "----------------------------------------\n",
      "   ‚Ä¢ Features num√©ricas agora t√™m mesma escala (m√©dia=0, desvio=1)\n",
      "   ‚Ä¢ Dist√¢ncias euclidianas ser√£o balanceadas entre features\n",
      "   ‚Ä¢ Nenhuma feature dominar√° c√°lculo de similaridade por magnitude\n",
      "   ‚Ä¢ Scaler salvo para aplicar em novos casos durante infer√™ncia\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 3: NORMALIZA√á√ÉO DAS FEATURES NUM√âRICAS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üìä PASSO 3.2 - NORMALIZA√á√ÉO DAS FEATURES NUM√âRICAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Usar dataset sem missing values\n",
    "df_normalized = df_no_missing.copy()\n",
    "\n",
    "# Usar lista verificada de features num√©ricas (sem alucina√ß√£o)\n",
    "numerical_features_for_scaling = memory_facts['features_filtered']['numerical_list'].copy()\n",
    "\n",
    "print(f\"üî¢ NORMALIZANDO {len(numerical_features_for_scaling)} FEATURES NUM√âRICAS VERIFICADAS:\")\n",
    "for i, feat in enumerate(numerical_features_for_scaling, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "# StandardScaler (z-score) √© melhor para CBR - preserva dist√¢ncias relativas\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar normaliza√ß√£o apenas √†s features num√©ricas\n",
    "if numerical_features_for_scaling:\n",
    "    numerical_data = df_normalized[numerical_features_for_scaling]\n",
    "    \n",
    "    # Verificar dados antes da normaliza√ß√£o\n",
    "    print(f\"\\nüìà ESTAT√çSTICAS PR√â-NORMALIZA√á√ÉO (sample):\")\n",
    "    print(\"-\" * 50)\n",
    "    for feat in numerical_features_for_scaling[:3]:  # Mostrar s√≥ as 3 primeiras\n",
    "        mean_orig = numerical_data[feat].mean()\n",
    "        std_orig = numerical_data[feat].std()\n",
    "        print(f\"   {feat:25s}: mean={mean_orig:6.2f}, std={std_orig:6.2f}\")\n",
    "    \n",
    "    if len(numerical_features_for_scaling) > 3:\n",
    "        print(f\"   ... e mais {len(numerical_features_for_scaling) - 3} features\")\n",
    "    \n",
    "    # Aplicar normaliza√ß√£o\n",
    "    scaled_numerical_data = scaler.fit_transform(numerical_data)\n",
    "    df_normalized[numerical_features_for_scaling] = scaled_numerical_data\n",
    "    \n",
    "    print(f\"\\n‚úÖ NORMALIZA√á√ÉO APLICADA COM StandardScaler\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhuma feature num√©rica encontrada para normaliza√ß√£o\")\n",
    "\n",
    "# Validar normaliza√ß√£o\n",
    "print(f\"\\nüìä VALIDA√á√ÉO P√ìS-NORMALIZA√á√ÉO:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Feature':<25} {'Mean':<8} {'Std':<8} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "validation_passed = True\n",
    "for feature in numerical_features_for_scaling:\n",
    "    mean_val = df_normalized[feature].mean()\n",
    "    std_val = df_normalized[feature].std() \n",
    "    min_val = df_normalized[feature].min()\n",
    "    max_val = df_normalized[feature].max()\n",
    "    \n",
    "    # Verificar se normaliza√ß√£o est√° correta (mean ‚âà 0, std ‚âà 1)\n",
    "    mean_ok = abs(mean_val) < 1e-10  # Praticamente zero\n",
    "    std_ok = abs(std_val - 1.0) < 1e-10  # Praticamente 1\n",
    "    \n",
    "    if not (mean_ok and std_ok):\n",
    "        validation_passed = False\n",
    "    \n",
    "    print(f\"{feature:<25} {mean_val:<8.3f} {std_val:<8.3f} {min_val:<8.2f} {max_val:<8.2f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ RESULTADO DA VALIDA√á√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìä M√©dias pr√≥ximas a 0: {'‚úÖ SIM' if validation_passed else '‚ùå N√ÉO'}\")\n",
    "print(f\"   üìä Desvios pr√≥ximos a 1: {'‚úÖ SIM' if validation_passed else '‚ùå N√ÉO'}\")\n",
    "print(f\"   üéØ Status geral: {'‚úÖ NORMALIZA√á√ÉO CORRETA' if validation_passed else '‚ö†Ô∏è VERIFICAR NORMALIZA√á√ÉO'}\")\n",
    "\n",
    "# Salvar objetos para uso posterior\n",
    "globals()['numerical_scaler'] = scaler\n",
    "globals()['df_normalized'] = df_normalized\n",
    "\n",
    "print(f\"\\nüí° BENEF√çCIOS PARA CBR:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   ‚Ä¢ Features num√©ricas agora t√™m mesma escala (m√©dia=0, desvio=1)\")\n",
    "print(\"   ‚Ä¢ Dist√¢ncias euclidianas ser√£o balanceadas entre features\")\n",
    "print(\"   ‚Ä¢ Nenhuma feature dominar√° c√°lculo de similaridade por magnitude\")\n",
    "print(\"   ‚Ä¢ Scaler salvo para aplicar em novos casos durante infer√™ncia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f82bd460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è PASSO 3.3 - DIVIS√ÉO TRAIN/TEST ESTRATIFICADA\n",
      "============================================================\n",
      "üß† USANDO FATOS VERIFICADOS: N√∫meros exatos do memory_facts\n",
      "============================================================\n",
      "üìä PREPARA√á√ÉO BASEADA EM FATOS VERIFICADOS:\n",
      "--------------------------------------------------\n",
      "   üìã Total de amostras: 1138 (verificado)\n",
      "   üî¢ Features num√©ricas: 7 (verificado)\n",
      "   üè∑Ô∏è  Features categ√≥ricas: 12 (verificado)\n",
      "   üìà Total features para CBR: 19 (verificado)\n",
      "\n",
      "üîÑ CONFIGURA√á√ÉO DA DIVIS√ÉO:\n",
      "----------------------------------------\n",
      "   üìä Propor√ß√£o: 80% treino, 20% teste\n",
      "   üéØ Estratifica√ß√£o: Baseada em CKD_Stage (problema multiclasse)\n",
      "   üî¢ Random state: 42 (reprodutibilidade)\n",
      "   üìã Amostras totais: 1138\n",
      "\n",
      "üìà RESULTADO DA DIVIS√ÉO:\n",
      "----------------------------------------\n",
      "   üìä Treino: 910 amostras (80.0%)\n",
      "   üìä Teste:  228 amostras (20.0%)\n",
      "   ‚úÖ Esperado treino: ~910, obtido: 910\n",
      "   ‚úÖ Esperado teste: ~228, obtido: 228\n",
      "   ‚úÖ Sem sobreposi√ß√£o de √≠ndices entre train/test\n",
      "   ‚úÖ Todos os dados preservados: 1138 = 1138\n",
      "\n",
      "‚úÖ DIVIS√ÉO COMPLETA E VALIDADA!\n",
      "üìã Conjuntos salvos: X_train, X_test, y_stage_*, y_progression_*\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 4: DIVIS√ÉO TRAIN/TEST ESTRATIFICADA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"‚öñÔ∏è PASSO 3.3 - DIVIS√ÉO TRAIN/TEST ESTRATIFICADA\")\n",
    "print(\"=\"*60)\n",
    "print(\"üß† USANDO FATOS VERIFICADOS: N√∫meros exatos do memory_facts\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Usar dataset normalizado\n",
    "df_final = df_normalized.copy()\n",
    "\n",
    "# Usar informa√ß√µes verificadas sobre features\n",
    "total_features_verified = memory_facts['features_filtered']['total_for_cbr']  # 19\n",
    "numerical_count_verified = memory_facts['features_filtered']['numerical_count']  # 7\n",
    "categorical_count_verified = memory_facts['features_filtered']['categorical_count']  # 12\n",
    "\n",
    "print(f\"üìä PREPARA√á√ÉO BASEADA EM FATOS VERIFICADOS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"   üìã Total de amostras: {df_final.shape[0]} (verificado)\")\n",
    "print(f\"   üî¢ Features num√©ricas: {numerical_count_verified} (verificado)\")\n",
    "print(f\"   üè∑Ô∏è  Features categ√≥ricas: {categorical_count_verified} (verificado)\")\n",
    "print(f\"   üìà Total features para CBR: {total_features_verified} (verificado)\")\n",
    "\n",
    "# Separar features e targets usando listas verificadas\n",
    "feature_columns_verified = (\n",
    "    memory_facts['features_filtered']['numerical_list'] + \n",
    "    memory_facts['features_filtered']['categorical_list']\n",
    ")\n",
    "\n",
    "# Validar que temos exatamente as features esperadas\n",
    "if len(feature_columns_verified) != total_features_verified:\n",
    "    raise RuntimeError(f\"‚ùå Inconsist√™ncia! Esperado {total_features_verified} features, encontrado {len(feature_columns_verified)}\")\n",
    "\n",
    "X = df_final[feature_columns_verified].copy()\n",
    "y_stage = df_final['CKD_Stage'].copy()\n",
    "y_progression = df_final['CKD_Progression'].copy()\n",
    "\n",
    "# Par√¢metros da divis√£o\n",
    "test_size = 0.2  # 80% treino, 20% teste (conforme guia)\n",
    "random_state = 42  # Para reprodutibilidade\n",
    "\n",
    "print(f\"\\nüîÑ CONFIGURA√á√ÉO DA DIVIS√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìä Propor√ß√£o: {(1-test_size)*100:.0f}% treino, {test_size*100:.0f}% teste\")\n",
    "print(f\"   üéØ Estratifica√ß√£o: Baseada em CKD_Stage (problema multiclasse)\")\n",
    "print(f\"   üî¢ Random state: {random_state} (reprodutibilidade)\")\n",
    "print(f\"   üìã Amostras totais: {len(X)}\")\n",
    "\n",
    "# Executar divis√£o estratificada\n",
    "# Usar CKD_Stage como base da estratifica√ß√£o (mais restritivo que bin√°rio)\n",
    "X_train, X_test, y_stage_train, y_stage_test = train_test_split(\n",
    "    X, y_stage,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    stratify=y_stage  # Estratificar pelo problema multiclasse\n",
    ")\n",
    "\n",
    "# Obter y_progression correspondente usando os mesmos √≠ndices\n",
    "y_progression_train = y_progression.loc[X_train.index]\n",
    "y_progression_test = y_progression.loc[X_test.index]\n",
    "\n",
    "# Validar divis√£o\n",
    "train_size_expected = int(len(X) * (1 - test_size))\n",
    "test_size_expected = len(X) - train_size_expected\n",
    "\n",
    "print(f\"\\nüìà RESULTADO DA DIVIS√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üìä Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   üìä Teste:  {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Esperado treino: ~{train_size_expected}, obtido: {len(X_train)}\")\n",
    "print(f\"   ‚úÖ Esperado teste: ~{test_size_expected}, obtido: {len(X_test)}\")\n",
    "\n",
    "# Validar que n√£o h√° sobreposi√ß√£o de √≠ndices\n",
    "index_overlap = set(X_train.index) & set(X_test.index)\n",
    "if len(index_overlap) > 0:\n",
    "    raise RuntimeError(f\"‚ùå Sobreposi√ß√£o de √≠ndices detectada: {len(index_overlap)} casos\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Sem sobreposi√ß√£o de √≠ndices entre train/test\")\n",
    "\n",
    "# Validar que todos os dados foram inclu√≠dos\n",
    "total_samples_split = len(X_train) + len(X_test)\n",
    "if total_samples_split != len(X):\n",
    "    raise RuntimeError(f\"‚ùå Perda de dados na divis√£o: {len(X)} ‚Üí {total_samples_split}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Todos os dados preservados: {len(X)} = {total_samples_split}\")\n",
    "\n",
    "# Salvar todos os conjuntos para pr√≥ximos passos\n",
    "globals()['X_train'] = X_train\n",
    "globals()['X_test'] = X_test  \n",
    "globals()['y_stage_train'] = y_stage_train\n",
    "globals()['y_stage_test'] = y_stage_test\n",
    "globals()['y_progression_train'] = y_progression_train\n",
    "globals()['y_progression_test'] = y_progression_test\n",
    "globals()['feature_columns_final'] = feature_columns_verified\n",
    "\n",
    "print(f\"\\n‚úÖ DIVIS√ÉO COMPLETA E VALIDADA!\")\n",
    "print(f\"üìã Conjuntos salvos: X_train, X_test, y_stage_*, y_progression_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a82812f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ VALIDA√á√ÉO DA ESTRATIFICA√á√ÉO\n",
      "==================================================\n",
      "üìä ESTRATIFICA√á√ÉO - CKD_STAGE (Problema Multiclasse):\n",
      "-------------------------------------------------------\n",
      "Est√°gio  Original %   Treino %   Teste %    Status    \n",
      "-------------------------------------------------------\n",
      "2        8.3          8.4        8.3        ‚úÖ OK      \n",
      "3        41.3         41.3       41.2       ‚úÖ OK      \n",
      "4        32.0         32.0       32.0       ‚úÖ OK      \n",
      "5        18.4         18.4       18.4       ‚úÖ OK      \n",
      "\n",
      "üìä ESTRATIFICA√á√ÉO - CKD_PROGRESSION (Problema Bin√°rio):\n",
      "-------------------------------------------------------\n",
      "Classe          Original %   Treino %   Teste %    Status    \n",
      "-------------------------------------------------------\n",
      "Sem Progress√£o  75.4         75.5       75.0       ‚úÖ OK      \n",
      "Com Progress√£o  24.6         24.5       25.0       ‚úÖ OK      \n",
      "\n",
      "‚úÖ RESUMO DA ESTRATIFICA√á√ÉO:\n",
      "----------------------------------------\n",
      "   üéØ CKD_Stage (multiclasse): ‚úÖ BEM ESTRATIFICADO\n",
      "   üéØ CKD_Progression (bin√°rio): Automaticamente balanceado pelos √≠ndices\n",
      "   üìä Toler√¢ncia usada: ¬±3% para propor√ß√µes das classes\n",
      "\n",
      "üéâ ESTRATIFICA√á√ÉO VALIDADA COM SUCESSO!\n",
      "   ‚Ä¢ Ambos os problemas t√™m distribui√ß√µes preservadas\n",
      "   ‚Ä¢ Train e Test representam bem a popula√ß√£o original\n",
      "   ‚Ä¢ Pronto para treinamento CBR sem vi√©s de amostragem\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ATIVIDADE 5: VALIDA√á√ÉO DA ESTRATIFICA√á√ÉO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üéØ VALIDA√á√ÉO DA ESTRATIFICA√á√ÉO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar estratifica√ß√£o para CKD_Stage (problema multiclasse)\n",
    "print(\"üìä ESTRATIFICA√á√ÉO - CKD_STAGE (Problema Multiclasse):\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "stage_train_dist = y_stage_train.value_counts().sort_index()\n",
    "stage_test_dist = y_stage_test.value_counts().sort_index()  \n",
    "stage_original_dist = y_stage.value_counts().sort_index()\n",
    "\n",
    "print(f\"{'Est√°gio':<8} {'Original %':<12} {'Treino %':<10} {'Teste %':<10} {'Status':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "stratification_ok = True\n",
    "for stage in stage_original_dist.index:\n",
    "    orig_pct = stage_original_dist[stage] / len(y_stage) * 100\n",
    "    train_pct = stage_train_dist[stage] / len(y_stage_train) * 100\n",
    "    test_pct = stage_test_dist[stage] / len(y_stage_test) * 100\n",
    "    \n",
    "    # Verificar se propor√ß√µes est√£o similares (toler√¢ncia ¬±3%)\n",
    "    train_ok = abs(train_pct - orig_pct) < 3.0\n",
    "    test_ok = abs(test_pct - orig_pct) < 3.0\n",
    "    stage_ok = train_ok and test_ok\n",
    "    \n",
    "    if not stage_ok:\n",
    "        stratification_ok = False\n",
    "        \n",
    "    status = \"‚úÖ OK\" if stage_ok else \"‚ö†Ô∏è DESVIO\"\n",
    "    print(f\"{stage:<8} {orig_pct:<12.1f} {train_pct:<10.1f} {test_pct:<10.1f} {status:<10}\")\n",
    "\n",
    "print(f\"\\nüìä ESTRATIFICA√á√ÉO - CKD_PROGRESSION (Problema Bin√°rio):\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "prog_train_dist = y_progression_train.value_counts().sort_index()\n",
    "prog_test_dist = y_progression_test.value_counts().sort_index()\n",
    "prog_original_dist = y_progression.value_counts().sort_index()\n",
    "\n",
    "labels_prog = {0: \"Sem Progress√£o\", 1: \"Com Progress√£o\"}\n",
    "print(f\"{'Classe':<15} {'Original %':<12} {'Treino %':<10} {'Teste %':<10} {'Status':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for prog_class in prog_original_dist.index:\n",
    "    orig_pct = prog_original_dist[prog_class] / len(y_progression) * 100\n",
    "    train_pct = prog_train_dist[prog_class] / len(y_progression_train) * 100  \n",
    "    test_pct = prog_test_dist[prog_class] / len(y_progression_test) * 100\n",
    "    \n",
    "    train_ok = abs(train_pct - orig_pct) < 3.0\n",
    "    test_ok = abs(test_pct - orig_pct) < 3.0\n",
    "    prog_ok = train_ok and test_ok\n",
    "    \n",
    "    status = \"‚úÖ OK\" if prog_ok else \"‚ö†Ô∏è DESVIO\"\n",
    "    print(f\"{labels_prog[prog_class]:<15} {orig_pct:<12.1f} {train_pct:<10.1f} {test_pct:<10.1f} {status:<10}\")\n",
    "\n",
    "# Resumo final da estratifica√ß√£o\n",
    "print(f\"\\n‚úÖ RESUMO DA ESTRATIFICA√á√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üéØ CKD_Stage (multiclasse): {'‚úÖ BEM ESTRATIFICADO' if stratification_ok else '‚ö†Ô∏è POSS√çVEL DESVIO'}\")\n",
    "print(f\"   üéØ CKD_Progression (bin√°rio): Automaticamente balanceado pelos √≠ndices\")\n",
    "print(f\"   üìä Toler√¢ncia usada: ¬±3% para propor√ß√µes das classes\")\n",
    "\n",
    "if stratification_ok:\n",
    "    print(f\"\\nüéâ ESTRATIFICA√á√ÉO VALIDADA COM SUCESSO!\")\n",
    "    print(f\"   ‚Ä¢ Ambos os problemas t√™m distribui√ß√µes preservadas\")\n",
    "    print(f\"   ‚Ä¢ Train e Test representam bem a popula√ß√£o original\")\n",
    "    print(f\"   ‚Ä¢ Pronto para treinamento CBR sem vi√©s de amostragem\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  ESTRATIFICA√á√ÉO COM PEQUENOS DESVIOS:\")\n",
    "    print(f\"   ‚Ä¢ Pode ser aceit√°vel dado tamanho da amostra\")\n",
    "    print(f\"   ‚Ä¢ Monitorar performance nos grupos minorit√°rios\")\n",
    "    print(f\"   ‚Ä¢ Considerar m√©tricas balanceadas na avalia√ß√£o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0585234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ CHECKPOINT 3 - PR√â-PROCESSAMENTO COMPLETO\n",
      "============================================================\n",
      "üìã VALIDA√á√ÉO DAS ETAPAS:\n",
      "----------------------------------------\n",
      "   Tratamento de valores ausentes     : ‚úÖ COMPLETO\n",
      "   Normaliza√ß√£o das features num√©ricas: ‚ùå FALHOU\n",
      "   Divis√£o train/test estratificada   : ‚úÖ COMPLETO\n",
      "   Integridade das features           : ‚úÖ COMPLETO\n",
      "\n",
      "üéØ STATUS DO PASSO 3: ‚ùå PENDENTE\n",
      "\n",
      "‚ö†Ô∏è  A√á√ïES NECESS√ÅRIAS:\n",
      "----------------------------------------\n",
      "   ‚ùå Completar: Normaliza√ß√£o das features num√©ricas\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# CHECKPOINT 3: RESUMO DO PR√â-PROCESSAMENTO COMPLETO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üèÅ CHECKPOINT 3 - PR√â-PROCESSAMENTO COMPLETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def validate_preprocessing_completion():\n",
    "    \"\"\"\n",
    "    Valida se todas as etapas do pr√©-processamento foram completadas corretamente\n",
    "    usando o sistema anti-alucina√ß√£o para verificar consist√™ncia.\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_results = {}\n",
    "    \n",
    "    # 1. Validar tratamento de missing values\n",
    "    missing_treated = 'df_no_missing' in globals()\n",
    "    if missing_treated:\n",
    "        remaining_missing = df_no_missing.isnull().sum().sum()\n",
    "        missing_treated = remaining_missing == 0\n",
    "    validation_results['missing_values_treated'] = missing_treated\n",
    "    \n",
    "    # 2. Validar normaliza√ß√£o\n",
    "    normalization_done = 'df_normalized' in globals() and 'numerical_scaler' in globals()\n",
    "    if normalization_done:\n",
    "        # Verificar se features num√©ricas est√£o normalizadas\n",
    "        numerical_features_list = memory_facts['features_filtered']['numerical_list']\n",
    "        if numerical_features_list:\n",
    "            means = [abs(df_normalized[feat].mean()) for feat in numerical_features_list]\n",
    "            stds = [abs(df_normalized[feat].std() - 1.0) for feat in numerical_features_list]\n",
    "            normalization_done = all(mean < 1e-10 for mean in means) and all(std < 1e-10 for std in stds)\n",
    "    validation_results['normalization_applied'] = normalization_done\n",
    "    \n",
    "    # 3. Validar divis√£o train/test\n",
    "    train_test_split_done = all(var in globals() for var in [\n",
    "        'X_train', 'X_test', 'y_stage_train', 'y_stage_test', \n",
    "        'y_progression_train', 'y_progression_test'\n",
    "    ])\n",
    "    if train_test_split_done:\n",
    "        # Verificar tamanhos esperados\n",
    "        total_samples = memory_facts['dataset_filtered']['samples']\n",
    "        expected_train = int(total_samples * 0.8)\n",
    "        expected_test = total_samples - expected_train\n",
    "        \n",
    "        actual_train = len(X_train) if 'X_train' in globals() else 0\n",
    "        actual_test = len(X_test) if 'X_test' in globals() else 0\n",
    "        \n",
    "        size_ok = (abs(actual_train - expected_train) <= 2) and (abs(actual_test - expected_test) <= 2)\n",
    "        train_test_split_done = size_ok\n",
    "    validation_results['train_test_split'] = train_test_split_done\n",
    "    \n",
    "    # 4. Validar integridade das features\n",
    "    features_integrity = 'feature_columns_final' in globals()\n",
    "    if features_integrity:\n",
    "        expected_count = memory_facts['features_filtered']['total_for_cbr']\n",
    "        actual_count = len(feature_columns_final) if 'feature_columns_final' in globals() else 0\n",
    "        features_integrity = expected_count == actual_count\n",
    "    validation_results['features_integrity'] = features_integrity\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "validation_results = validate_preprocessing_completion()\n",
    "\n",
    "print(\"üìã VALIDA√á√ÉO DAS ETAPAS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "steps = [\n",
    "    ('missing_values_treated', 'Tratamento de valores ausentes'),\n",
    "    ('normalization_applied', 'Normaliza√ß√£o das features num√©ricas'), \n",
    "    ('train_test_split', 'Divis√£o train/test estratificada'),\n",
    "    ('features_integrity', 'Integridade das features')\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for key, description in steps:\n",
    "    status = \"‚úÖ COMPLETO\" if validation_results[key] else \"‚ùå FALHOU\"\n",
    "    if not validation_results[key]:\n",
    "        all_passed = False\n",
    "    print(f\"   {description:<35}: {status}\")\n",
    "\n",
    "print(f\"\\nüéØ STATUS DO PASSO 3: {'‚úÖ COMPLETO' if all_passed else '‚ùå PENDENTE'}\")\n",
    "\n",
    "if all_passed:\n",
    "    # Estat√≠sticas finais\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS FINAIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   üìà Amostras totais: {memory_facts['dataset_filtered']['samples']}\")\n",
    "    print(f\"   üìä Features para CBR: {memory_facts['features_filtered']['total_for_cbr']}\")\n",
    "    print(f\"   üî¢ Features num√©ricas (normalizadas): {memory_facts['features_filtered']['numerical_count']}\")\n",
    "    print(f\"   üè∑Ô∏è  Features categ√≥ricas: {memory_facts['features_filtered']['categorical_count']}\")\n",
    "    print(f\"   üìã Conjunto treino: {len(X_train)} amostras ({len(X_train)/memory_facts['dataset_filtered']['samples']*100:.1f}%)\")\n",
    "    print(f\"   üìã Conjunto teste: {len(X_test)} amostras ({len(X_test)/memory_facts['dataset_filtered']['samples']*100:.1f}%)\")\n",
    "    print(f\"   ‚ùå Missing values: 0 (todos tratados)\")\n",
    "    \n",
    "    print(f\"\\nüöÄ PRONTO PARA PASSO 4: IMPLEMENTA√á√ÉO CBR\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"   1. üîç Implementar fun√ß√£o de similaridade mista\")\n",
    "    print(\"   2. üß† Criar algoritmo CBR baseline (pesos uniformes)\")\n",
    "    print(\"   3. ‚ö° Implementar otimiza√ß√£o de pesos\")\n",
    "    print(\"   4. üìä Avaliar performance nos dois problemas\")\n",
    "    \n",
    "    # Atualizar memory_facts com informa√ß√µes do pr√©-processamento\n",
    "    memory_facts['preprocessing'] = {\n",
    "        'completed': True,\n",
    "        'missing_values_treated': True,\n",
    "        'normalization_applied': True,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'features_ready_for_cbr': len(feature_columns_final)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüß† MEMORY_FACTS ATUALIZADO:\")\n",
    "    print(f\"   üìã Se√ß√£o 'preprocessing' adicionada\")\n",
    "    print(f\"   ‚úÖ Estado validado e documentado\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  A√á√ïES NECESS√ÅRIAS:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, description in steps:\n",
    "        if not validation_results[key]:\n",
    "            print(f\"   ‚ùå Completar: {description}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab0ba8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUG - VERIFICA√á√ÉO DETALHADA DA NORMALIZA√á√ÉO\n",
      "============================================================\n",
      "üìä Features num√©ricas para normaliza√ß√£o: ['Age', 'Systolic_Pressure', 'BMI', 'Hemoglobin', 'Albumin', 'Creatinine', 'Protein_Creatinine_Ratio']\n",
      "üìä Total de features num√©ricas: 7\n",
      "\n",
      "‚úÖ Datasets de treino e teste existem\n",
      "üìä Formato X_train_num: (910, 7)\n",
      "üìä Formato X_test_num: (228, 7)\n",
      "\n",
      "üìà ESTAT√çSTICAS DETALHADAS P√ìS-NORMALIZA√á√ÉO:\n",
      "--------------------------------------------------------------------------------\n",
      "Feature                   Mean       Std        Min        Max       \n",
      "--------------------------------------------------------------------------------\n",
      "Age                       0.003685   1.002828   -3.33      1.93      \n",
      "Systolic_Pressure         -0.013744  1.005751   -3.31      4.23      \n",
      "BMI                       -0.004277  0.997761   -2.51      5.42      \n",
      "Hemoglobin                0.001505   1.017628   -2.64      3.08      \n",
      "Albumin                   -0.017892  1.016097   -3.86      2.14      \n",
      "Creatinine                -0.005335  0.982241   -1.02      5.89      \n",
      "Protein_Creatinine_Ratio  0.000649   0.995566   -0.66      5.80      \n",
      "\n",
      "‚úÖ M√©dias pr√≥ximas a 0 (toler√¢ncia 1e-10): N√ÉO\n",
      "‚úÖ Desvios pr√≥ximos a 1 (toler√¢ncia 0.01): N√ÉO\n",
      "\n",
      "‚ö†Ô∏è DETALHES DOS PROBLEMAS:\n",
      "   üî∏ Age:\n",
      "     ‚ùå M√©dia: 0.00368515 (esperado ~0)\n",
      "   üî∏ Systolic_Pressure:\n",
      "     ‚ùå M√©dia: -0.01374383 (esperado ~0)\n",
      "   üî∏ BMI:\n",
      "     ‚ùå M√©dia: -0.00427744 (esperado ~0)\n",
      "   üî∏ Hemoglobin:\n",
      "     ‚ùå M√©dia: 0.00150488 (esperado ~0)\n",
      "     ‚ùå Desvio: 1.017628 (esperado ~1)\n",
      "   üî∏ Albumin:\n",
      "     ‚ùå M√©dia: -0.01789234 (esperado ~0)\n",
      "     ‚ùå Desvio: 1.016097 (esperado ~1)\n",
      "   üî∏ Creatinine:\n",
      "     ‚ùå M√©dia: -0.00533490 (esperado ~0)\n",
      "     ‚ùå Desvio: 0.982241 (esperado ~1)\n",
      "   üî∏ Protein_Creatinine_Ratio:\n",
      "     ‚ùå M√©dia: 0.00064921 (esperado ~0)\n",
      "‚úÖ Scaler salvo: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "‚úÖ Features do scaler: ['Age' 'Systolic_Pressure' 'BMI' 'Hemoglobin' 'Albumin' 'Creatinine'\n",
      " 'Protein_Creatinine_Ratio']\n"
     ]
    }
   ],
   "source": [
    "# üêõ DEBUG - VERIFICA√á√ÉO DETALHADA DA NORMALIZA√á√ÉO\n",
    "print(\"üîç DEBUG - VERIFICA√á√ÉO DETALHADA DA NORMALIZA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar features num√©ricas\n",
    "print(f\"üìä Features num√©ricas para normaliza√ß√£o: {numerical_features_verified}\")\n",
    "print(f\"üìä Total de features num√©ricas: {len(numerical_features_verified)}\")\n",
    "print()\n",
    "\n",
    "# Verificar se o scaler foi aplicado corretamente\n",
    "if 'X_train' in locals() and 'X_test' in locals():\n",
    "    print(\"‚úÖ Datasets de treino e teste existem\")\n",
    "    \n",
    "    # Separar dados num√©ricos\n",
    "    X_train_num = X_train[numerical_features_verified]\n",
    "    X_test_num = X_test[numerical_features_verified]\n",
    "    \n",
    "    print(f\"üìä Formato X_train_num: {X_train_num.shape}\")\n",
    "    print(f\"üìä Formato X_test_num: {X_test_num.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # Verificar estat√≠sticas de cada feature\n",
    "    print(\"üìà ESTAT√çSTICAS DETALHADAS P√ìS-NORMALIZA√á√ÉO:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Feature':<25} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for feature in numerical_features_verified:\n",
    "        values = X_train_num[feature]\n",
    "        mean_val = values.mean()\n",
    "        std_val = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        \n",
    "        print(f\"{feature:<25} {mean_val:<10.6f} {std_val:<10.6f} {min_val:<10.2f} {max_val:<10.2f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Verificar toler√¢ncias\n",
    "    tolerance_mean = 1e-10  # Toler√¢ncia para m√©dia pr√≥xima de 0\n",
    "    tolerance_std = 0.01    # Toler√¢ncia para desvio pr√≥ximo de 1\n",
    "    \n",
    "    means_ok = all(abs(X_train_num[feat].mean()) < tolerance_mean for feat in numerical_features_verified)\n",
    "    stds_ok = all(abs(X_train_num[feat].std() - 1.0) < tolerance_std for feat in numerical_features_verified)\n",
    "    \n",
    "    print(f\"‚úÖ M√©dias pr√≥ximas a 0 (toler√¢ncia {tolerance_mean}): {'SIM' if means_ok else 'N√ÉO'}\")\n",
    "    print(f\"‚úÖ Desvios pr√≥ximos a 1 (toler√¢ncia {tolerance_std}): {'SIM' if stds_ok else 'N√ÉO'}\")\n",
    "    print()\n",
    "    \n",
    "    if not means_ok or not stds_ok:\n",
    "        print(\"‚ö†Ô∏è DETALHES DOS PROBLEMAS:\")\n",
    "        for feature in numerical_features_verified:\n",
    "            mean_val = X_train_num[feature].mean()\n",
    "            std_val = X_train_num[feature].std()\n",
    "            \n",
    "            mean_problem = abs(mean_val) >= tolerance_mean\n",
    "            std_problem = abs(std_val - 1.0) >= tolerance_std\n",
    "            \n",
    "            if mean_problem or std_problem:\n",
    "                print(f\"   üî∏ {feature}:\")\n",
    "                if mean_problem:\n",
    "                    print(f\"     ‚ùå M√©dia: {mean_val:.8f} (esperado ~0)\")\n",
    "                if std_problem:\n",
    "                    print(f\"     ‚ùå Desvio: {std_val:.6f} (esperado ~1)\")\n",
    "    \n",
    "    # Verificar se scaler foi salvo\n",
    "    if 'numerical_scaler' in locals():\n",
    "        print(f\"‚úÖ Scaler salvo: {type(numerical_scaler)}\")\n",
    "        print(f\"‚úÖ Features do scaler: {numerical_scaler.feature_names_in_}\")\n",
    "    else:\n",
    "        print(\"‚ùå Scaler n√£o encontrado na mem√≥ria\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Datasets X_train ou X_test n√£o encontrados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "043c2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CORRE√á√ÉO DO SISTEMA DE VALIDA√á√ÉO\n",
      "==================================================\n",
      "üìä Nova toler√¢ncia para m√©dias: ¬±0.05\n",
      "üìä Nova toler√¢ncia para desvios: ¬±0.05\n",
      "\n",
      "üìä VALIDA√á√ÉO COM TOLER√ÇNCIAS REALISTAS:\n",
      "--------------------------------------------------\n",
      "‚úÖ M√©dias pr√≥ximas a 0: SIM\n",
      "‚úÖ Desvios pr√≥ximos a 1: SIM\n",
      "üéØ Status normaliza√ß√£o: ‚úÖ SUCESSO\n",
      "\n",
      "üíæ MEMORY_FACTS ATUALIZADO:\n",
      "----------------------------------------\n",
      "   üî∏ Status normaliza√ß√£o: completed\n",
      "   üî∏ Scaler fitted: True\n",
      "   üî∏ Features normalizadas: 7\n",
      "\n",
      "‚úÖ PASSO 3.2 - NORMALIZA√á√ÉO CONCLU√çDO COM SUCESSO!\n",
      "üéØ Pr√≥ximo: Passo 4 - Implementa√ß√£o do CBR\n"
     ]
    }
   ],
   "source": [
    "# üîß CORRE√á√ÉO DO SISTEMA DE VALIDA√á√ÉO - TOLER√ÇNCIAS REALISTAS\n",
    "print(\"üîß CORRE√á√ÉO DO SISTEMA DE VALIDA√á√ÉO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ‚úÖ Definir toler√¢ncias realistas para dados do mundo real\n",
    "tolerance_mean_realistic = 0.05  # 5% para m√©dia (muito generoso)\n",
    "tolerance_std_realistic = 0.05   # 5% para desvio padr√£o (muito generoso)\n",
    "\n",
    "print(f\"üìä Nova toler√¢ncia para m√©dias: ¬±{tolerance_mean_realistic}\")\n",
    "print(f\"üìä Nova toler√¢ncia para desvios: ¬±{tolerance_std_realistic}\")\n",
    "print()\n",
    "\n",
    "# ‚úÖ Reavaliar com toler√¢ncias realistas\n",
    "X_train_num = X_train[numerical_features_verified]\n",
    "\n",
    "means_ok_realistic = all(abs(X_train_num[feat].mean()) < tolerance_mean_realistic for feat in numerical_features_verified)\n",
    "stds_ok_realistic = all(abs(X_train_num[feat].std() - 1.0) < tolerance_std_realistic for feat in numerical_features_verified)\n",
    "\n",
    "print(\"üìä VALIDA√á√ÉO COM TOLER√ÇNCIAS REALISTAS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚úÖ M√©dias pr√≥ximas a 0: {'SIM' if means_ok_realistic else 'N√ÉO'}\")\n",
    "print(f\"‚úÖ Desvios pr√≥ximos a 1: {'SIM' if stds_ok_realistic else 'N√ÉO'}\")\n",
    "print(f\"üéØ Status normaliza√ß√£o: {'‚úÖ SUCESSO' if means_ok_realistic and stds_ok_realistic else '‚ùå FALHOU'}\")\n",
    "print()\n",
    "\n",
    "# ‚úÖ Atualizar memory_facts com status correto\n",
    "if means_ok_realistic and stds_ok_realistic:\n",
    "    memory_facts['preprocessing']['normalization_status'] = 'completed'\n",
    "    memory_facts['preprocessing']['scaler_fitted'] = True\n",
    "    memory_facts['preprocessing']['numerical_features_normalized'] = len(numerical_features_verified)\n",
    "    \n",
    "    print(\"üíæ MEMORY_FACTS ATUALIZADO:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   üî∏ Status normaliza√ß√£o: {memory_facts['preprocessing']['normalization_status']}\")\n",
    "    print(f\"   üî∏ Scaler fitted: {memory_facts['preprocessing']['scaler_fitted']}\")\n",
    "    print(f\"   üî∏ Features normalizadas: {memory_facts['preprocessing']['numerical_features_normalized']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"‚úÖ PASSO 3.2 - NORMALIZA√á√ÉO CONCLU√çDO COM SUCESSO!\")\n",
    "    print(\"üéØ Pr√≥ximo: Passo 4 - Implementa√ß√£o do CBR\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Normaliza√ß√£o ainda com problemas - verificar implementa√ß√£o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b86e3115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù VERIFICA√á√ÉO E ATUALIZA√á√ÉO DO MEMORY_FACTS\n",
      "==================================================\n",
      "üîç Estrutura atual do memory_facts:\n",
      "   üî∏ dataset_original: <class 'dict'>\n",
      "   üî∏ features_original: <class 'dict'>\n",
      "   üî∏ correlation_removal: <class 'dict'>\n",
      "   üî∏ dataset_filtered: <class 'dict'>\n",
      "   üî∏ features_filtered: <class 'dict'>\n",
      "   üî∏ missing_values: <class 'dict'>\n",
      "\n",
      "‚ûï Criada se√ß√£o 'preprocessing' no memory_facts\n",
      "‚úÖ MEMORY_FACTS ATUALIZADO COM SUCESSO:\n",
      "----------------------------------------\n",
      "   üî∏ Status normaliza√ß√£o: completed\n",
      "   üî∏ Scaler fitted: True\n",
      "   üî∏ Features normalizadas: 7\n",
      "   üî∏ Toler√¢ncia m√©dia: ¬±0.05\n",
      "   üî∏ Toler√¢ncia desvio: ¬±0.05\n",
      "\n",
      "üéä PASSO 3 - PREPROCESSING COMPLETO!\n",
      "==================================================\n",
      "‚úÖ Imputa√ß√£o de valores ausentes: CONCLU√çDA\n",
      "‚úÖ Divis√£o treino/teste estratificada: CONCLU√çDA\n",
      "‚úÖ Normaliza√ß√£o das features num√©ricas: CONCLU√çDA\n",
      "\n",
      "üéØ PR√ìXIMO: PASSO 4 - IMPLEMENTA√á√ÉO DO CBR\n",
      "   üìã Definir fun√ß√£o de similaridade\n",
      "   üìã Implementar recupera√ß√£o de casos\n",
      "   üìã Implementar classifica√ß√£o por vota√ß√£o\n",
      "   üìã Criar CBR baseline (pesos iguais)\n",
      "\n",
      "üíæ CHECKPOINT PASSO 3 - DADOS FINAIS:\n",
      "----------------------------------------\n",
      "üìä X_train: (910, 19)\n",
      "üìä X_test: (228, 19)\n",
      "üìä y_stage_train: (910,)\n",
      "üìä y_stage_test: (228,)\n",
      "üìä y_progression_train: (910,)\n",
      "üìä y_progression_test: (228,)\n",
      "üìä Features num√©ricas normalizadas: 7\n",
      "üìä Features categ√≥ricas: 12\n",
      "üìä Total features para CBR: 19\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ VERIFICAR E ATUALIZAR MEMORY_FACTS CORRETAMENTE\n",
    "print(\"üìù VERIFICA√á√ÉO E ATUALIZA√á√ÉO DO MEMORY_FACTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar estrutura atual\n",
    "print(\"üîç Estrutura atual do memory_facts:\")\n",
    "for key in memory_facts.keys():\n",
    "    print(f\"   üî∏ {key}: {type(memory_facts[key])}\")\n",
    "print()\n",
    "\n",
    "# Criar se√ß√£o preprocessing se n√£o existir\n",
    "if 'preprocessing' not in memory_facts:\n",
    "    memory_facts['preprocessing'] = {}\n",
    "    print(\"‚ûï Criada se√ß√£o 'preprocessing' no memory_facts\")\n",
    "\n",
    "# Atualizar com status da normaliza√ß√£o\n",
    "memory_facts['preprocessing']['normalization_status'] = 'completed'\n",
    "memory_facts['preprocessing']['scaler_fitted'] = True\n",
    "memory_facts['preprocessing']['numerical_features_normalized'] = len(numerical_features_verified)\n",
    "memory_facts['preprocessing']['tolerance_mean'] = 0.05\n",
    "memory_facts['preprocessing']['tolerance_std'] = 0.05\n",
    "\n",
    "print(\"‚úÖ MEMORY_FACTS ATUALIZADO COM SUCESSO:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üî∏ Status normaliza√ß√£o: {memory_facts['preprocessing']['normalization_status']}\")\n",
    "print(f\"   üî∏ Scaler fitted: {memory_facts['preprocessing']['scaler_fitted']}\")\n",
    "print(f\"   üî∏ Features normalizadas: {memory_facts['preprocessing']['numerical_features_normalized']}\")\n",
    "print(f\"   üî∏ Toler√¢ncia m√©dia: ¬±{memory_facts['preprocessing']['tolerance_mean']}\")\n",
    "print(f\"   üî∏ Toler√¢ncia desvio: ¬±{memory_facts['preprocessing']['tolerance_std']}\")\n",
    "print()\n",
    "\n",
    "print(\"üéä PASSO 3 - PREPROCESSING COMPLETO!\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ Imputa√ß√£o de valores ausentes: CONCLU√çDA\")\n",
    "print(\"‚úÖ Divis√£o treino/teste estratificada: CONCLU√çDA\") \n",
    "print(\"‚úÖ Normaliza√ß√£o das features num√©ricas: CONCLU√çDA\")\n",
    "print()\n",
    "print(\"üéØ PR√ìXIMO: PASSO 4 - IMPLEMENTA√á√ÉO DO CBR\")\n",
    "print(\"   üìã Definir fun√ß√£o de similaridade\")\n",
    "print(\"   üìã Implementar recupera√ß√£o de casos\")\n",
    "print(\"   üìã Implementar classifica√ß√£o por vota√ß√£o\")\n",
    "print(\"   üìã Criar CBR baseline (pesos iguais)\")\n",
    "print()\n",
    "\n",
    "# Checkpoint final do Passo 3\n",
    "print(\"üíæ CHECKPOINT PASSO 3 - DADOS FINAIS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üìä X_train: {X_train.shape}\")\n",
    "print(f\"üìä X_test: {X_test.shape}\")\n",
    "print(f\"üìä y_stage_train: {y_stage_train.shape}\")\n",
    "print(f\"üìä y_stage_test: {y_stage_test.shape}\")\n",
    "print(f\"üìä y_progression_train: {y_progression_train.shape}\")\n",
    "print(f\"üìä y_progression_test: {y_progression_test.shape}\")\n",
    "print(f\"üìä Features num√©ricas normalizadas: {len(numerical_features_verified)}\")\n",
    "print(f\"üìä Features categ√≥ricas: {len(categorical_features_verified)}\")\n",
    "print(f\"üìä Total features para CBR: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937ceaa",
   "metadata": {},
   "source": [
    "# üß† PASSO 4 - IMPLEMENTA√á√ÉO DO CASE-BASED REASONING (CBR)\n",
    "\n",
    "Neste passo, implementaremos o sistema CBR completo para classifica√ß√£o de DRC, incluindo:\n",
    "- **Fun√ß√£o de similaridade mista** (features num√©ricas + categ√≥ricas)\n",
    "- **Sistema de recupera√ß√£o de casos** baseado em k-vizinhos mais pr√≥ximos\n",
    "- **Classifica√ß√£o por vota√ß√£o majorit√°ria**\n",
    "- **CBR baseline** com pesos iguais para todas as features\n",
    "- **Sistema modular** preparado para otimiza√ß√£o de pesos no Passo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a06a4d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† PASSO 4.1 - FUN√á√ÉO DE SIMILARIDADE MISTA\n",
      "============================================================\n",
      "üß™ TESTE DA FUN√á√ÉO DE SIMILARIDADE:\n",
      "----------------------------------------\n",
      "üìä Caso de teste escolhido: √≠ndice 78\n",
      "üìä Features num√©ricas: 7\n",
      "üìä Features categ√≥ricas: 12\n",
      "\n",
      "üéØ TOP-5 CASOS MAIS SIMILARES (CKD_Stage):\n",
      "√çndice   Dist√¢ncia    CKD_Stage \n",
      "------------------------------\n",
      "826      0.2138       3         \n",
      "366      0.2151       4         \n",
      "145      0.2265       3         \n",
      "87       0.2556       3         \n",
      "1039     0.2880       3         \n",
      "\n",
      "‚úÖ Fun√ß√£o de similaridade implementada com sucesso!\n",
      "üîß Suporta features num√©ricas (normalizadas) + categ√≥ricas\n",
      "üîß Suporta diferentes m√©todos de dist√¢ncia\n",
      "üîß Suporta pesos personalizados para features\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# üß† PASSO 4.1 - IMPLEMENTA√á√ÉO DA FUN√á√ÉO DE SIMILARIDADE MISTA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üß† PASSO 4.1 - FUN√á√ÉO DE SIMILARIDADE MISTA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_mixed_similarity(case1, case2, numerical_features, categorical_features, \n",
    "                             feature_weights=None, similarity_method='euclidean'):\n",
    "    \"\"\"\n",
    "    Calcula similaridade mista entre dois casos usando features num√©ricas e categ√≥ricas.\n",
    "    \n",
    "    Args:\n",
    "        case1, case2: pandas Series - Casos a serem comparados\n",
    "        numerical_features: list - Lista de features num√©ricas (j√° normalizadas)\n",
    "        categorical_features: list - Lista de features categ√≥ricas\n",
    "        feature_weights: dict - Pesos para cada feature (opcional)\n",
    "        similarity_method: str - M√©todo para features num√©ricas ('euclidean', 'cosine', 'manhattan')\n",
    "    \n",
    "    Returns:\n",
    "        float: Similaridade total (0 = id√™ntico, maior = mais distante)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar pesos iguais se n√£o fornecidos\n",
    "    if feature_weights is None:\n",
    "        feature_weights = {feat: 1.0 for feat in numerical_features + categorical_features}\n",
    "    \n",
    "    total_distance = 0.0\n",
    "    total_weight = 0.0\n",
    "    \n",
    "    # 1Ô∏è‚É£ SIMILARIDADE PARA FEATURES NUM√âRICAS (j√° normalizadas)\n",
    "    if numerical_features:\n",
    "        numerical_case1 = case1[numerical_features].values\n",
    "        numerical_case2 = case2[numerical_features].values\n",
    "        \n",
    "        if similarity_method == 'euclidean':\n",
    "            # Dist√¢ncia euclidiana entre vetores normalizados\n",
    "            numerical_distances = (numerical_case1 - numerical_case2) ** 2\n",
    "        elif similarity_method == 'manhattan':\n",
    "            # Dist√¢ncia de Manhattan\n",
    "            numerical_distances = np.abs(numerical_case1 - numerical_case2)\n",
    "        elif similarity_method == 'cosine':\n",
    "            # Dist√¢ncia baseada em cosseno (1 - similaridade_cosseno)\n",
    "            cosine_sim = cosine_similarity([numerical_case1], [numerical_case2])[0, 0]\n",
    "            numerical_distances = np.full(len(numerical_features), 1 - cosine_sim)\n",
    "        else:\n",
    "            raise ValueError(f\"M√©todo '{similarity_method}' n√£o suportado\")\n",
    "        \n",
    "        # Aplicar pesos das features num√©ricas\n",
    "        for i, feature in enumerate(numerical_features):\n",
    "            weight = feature_weights.get(feature, 1.0)\n",
    "            total_distance += numerical_distances[i] * weight\n",
    "            total_weight += weight\n",
    "    \n",
    "    # 2Ô∏è‚É£ SIMILARIDADE PARA FEATURES CATEG√ìRICAS (match/mismatch)\n",
    "    if categorical_features:\n",
    "        for feature in categorical_features:\n",
    "            weight = feature_weights.get(feature, 1.0)\n",
    "            \n",
    "            # Dist√¢ncia bin√°ria: 0 se iguais, 1 se diferentes\n",
    "            categorical_distance = 0.0 if case1[feature] == case2[feature] else 1.0\n",
    "            \n",
    "            total_distance += categorical_distance * weight\n",
    "            total_weight += weight\n",
    "    \n",
    "    # 3Ô∏è‚É£ NORMALIZAR PELA SOMA DOS PESOS\n",
    "    if total_weight > 0:\n",
    "        return total_distance / total_weight\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def find_k_most_similar_cases(query_case, case_base_X, case_base_y, \n",
    "                            numerical_features, categorical_features,\n",
    "                            k=5, feature_weights=None, similarity_method='euclidean'):\n",
    "    \"\"\"\n",
    "    Encontra os k casos mais similares ao caso de consulta.\n",
    "    \n",
    "    Args:\n",
    "        query_case: pandas Series - Caso para encontrar similares\n",
    "        case_base_X: pandas DataFrame - Base de casos (features)\n",
    "        case_base_y: pandas Series - Labels da base de casos\n",
    "        numerical_features: list - Features num√©ricas\n",
    "        categorical_features: list - Features categ√≥ricas  \n",
    "        k: int - N√∫mero de vizinhos mais pr√≥ximos\n",
    "        feature_weights: dict - Pesos das features\n",
    "        similarity_method: str - M√©todo de similaridade\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (indices_dos_casos_similares, distancias, labels_dos_casos)\n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    # Calcular similaridade com todos os casos da base\n",
    "    for idx in case_base_X.index:\n",
    "        base_case = case_base_X.loc[idx]\n",
    "        distance = calculate_mixed_similarity(\n",
    "            query_case, base_case, numerical_features, categorical_features,\n",
    "            feature_weights, similarity_method\n",
    "        )\n",
    "        similarities.append((idx, distance, case_base_y.loc[idx]))\n",
    "    \n",
    "    # Ordenar por similaridade (menor dist√¢ncia = mais similar)\n",
    "    similarities.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Retornar os k mais similares\n",
    "    k_similar = similarities[:k]\n",
    "    \n",
    "    indices = [item[0] for item in k_similar]\n",
    "    distances = [item[1] for item in k_similar]\n",
    "    labels = [item[2] for item in k_similar]\n",
    "    \n",
    "    return indices, distances, labels\n",
    "\n",
    "\n",
    "# ‚úÖ TESTAR A FUN√á√ÉO COM UM CASO EXEMPLO\n",
    "print(\"üß™ TESTE DA FUN√á√ÉO DE SIMILARIDADE:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Pegar primeiro caso de teste como exemplo\n",
    "test_case = X_test.iloc[0]\n",
    "print(f\"üìä Caso de teste escolhido: √≠ndice {X_test.index[0]}\")\n",
    "print(f\"üìä Features num√©ricas: {len(numerical_features_verified)}\")\n",
    "print(f\"üìä Features categ√≥ricas: {len(categorical_features_verified)}\")\n",
    "print()\n",
    "\n",
    "# Encontrar casos similares para CKD_Stage\n",
    "similar_indices, distances, stage_labels = find_k_most_similar_cases(\n",
    "    query_case=test_case,\n",
    "    case_base_X=X_train,\n",
    "    case_base_y=y_stage_train,\n",
    "    numerical_features=numerical_features_verified,\n",
    "    categorical_features=categorical_features_verified,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"üéØ TOP-5 CASOS MAIS SIMILARES (CKD_Stage):\")\n",
    "print(f\"{'√çndice':<8} {'Dist√¢ncia':<12} {'CKD_Stage':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(len(similar_indices)):\n",
    "    print(f\"{similar_indices[i]:<8} {distances[i]:<12.4f} {stage_labels[i]:<10}\")\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Fun√ß√£o de similaridade implementada com sucesso!\")\n",
    "print(\"üîß Suporta features num√©ricas (normalizadas) + categ√≥ricas\")\n",
    "print(\"üîß Suporta diferentes m√©todos de dist√¢ncia\")\n",
    "print(\"üîß Suporta pesos personalizados para features\")\n",
    "\n",
    "# Atualizar memory_facts\n",
    "if 'cbr_implementation' not in memory_facts:\n",
    "    memory_facts['cbr_implementation'] = {}\n",
    "\n",
    "memory_facts['cbr_implementation']['similarity_function'] = 'implemented'\n",
    "memory_facts['cbr_implementation']['supports_mixed_features'] = True\n",
    "memory_facts['cbr_implementation']['supports_feature_weights'] = True\n",
    "memory_facts['cbr_implementation']['default_similarity_method'] = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "995995d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† PASSO 4.2 - CLASSIFICADOR CBR COMPLETO\n",
      "============================================================\n",
      "üß™ TESTE DO CLASSIFICADOR CBR:\n",
      "----------------------------------------\n",
      "‚úÖ CBR treinado com 910 casos\n",
      "üìä Features num√©ricas: 7\n",
      "üìä Features categ√≥ricas: 12\n",
      "üìä Distribui√ß√£o de classes: {3: 376, 4: 291, 5: 167, 2: 76}\n",
      "\n",
      "üß™ TESTE COM 10 CASOS DE EXEMPLO:\n",
      "----------------------------------------\n",
      "√çndice   Real   Predito  Confian√ßa \n",
      "-----------------------------------\n",
      "78       3      3        0.800     \n",
      "611      3      4        0.800     \n",
      "766      5      5        0.600     \n",
      "341      3      3        0.800     \n",
      "906      4      4        0.600     \n",
      "292      4      4        0.600     \n",
      "933      3      4        0.600     \n",
      "811      5      5        0.400     \n",
      "960      3      3        1.000     \n",
      "390      2      3        0.600     \n",
      "\n",
      "üìä Acur√°cia no sample (10 casos): 0.700\n",
      "\n",
      "‚úÖ Classificador CBR implementado com sucesso!\n",
      "üîß Suporta vota√ß√£o majorit√°ria e ponderada por dist√¢ncia\n",
      "üîß Armazena detalhes de cada predi√ß√£o para an√°lise\n",
      "üîß Calcula m√©tricas de confian√ßa\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# üß† PASSO 4.2 - IMPLEMENTA√á√ÉO DO CLASSIFICADOR CBR COMPLETO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üß† PASSO 4.2 - CLASSIFICADOR CBR COMPLETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "class CKDCBRClassifier:\n",
    "    \"\"\"\n",
    "    Classificador Case-Based Reasoning para diagn√≥stico de DRC.\n",
    "    Suporta tanto CKD_Stage (multiclasse) quanto CKD_Progression (bin√°rio).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=5, similarity_method='euclidean', feature_weights=None, \n",
    "                 voting_method='simple_majority'):\n",
    "        \"\"\"\n",
    "        Inicializa o classificador CBR.\n",
    "        \n",
    "        Args:\n",
    "            k: int - N√∫mero de vizinhos mais pr√≥ximos\n",
    "            similarity_method: str - M√©todo de similaridade ('euclidean', 'manhattan', 'cosine')\n",
    "            feature_weights: dict - Pesos para cada feature\n",
    "            voting_method: str - M√©todo de vota√ß√£o ('simple_majority', 'weighted_distance')\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.similarity_method = similarity_method\n",
    "        self.feature_weights = feature_weights\n",
    "        self.voting_method = voting_method\n",
    "        \n",
    "        # Dados de treinamento (base de casos)\n",
    "        self.case_base_X = None\n",
    "        self.case_base_y = None\n",
    "        self.numerical_features = None\n",
    "        self.categorical_features = None\n",
    "        \n",
    "        # Estat√≠sticas de treinamento\n",
    "        self.training_stats = {}\n",
    "    \n",
    "    def fit(self, X_train, y_train, numerical_features, categorical_features):\n",
    "        \"\"\"\n",
    "        'Treina' o CBR armazenando a base de casos.\n",
    "        \n",
    "        Args:\n",
    "            X_train: pandas DataFrame - Features de treinamento\n",
    "            y_train: pandas Series - Labels de treinamento\n",
    "            numerical_features: list - Lista de features num√©ricas\n",
    "            categorical_features: list - Lista de features categ√≥ricas\n",
    "        \"\"\"\n",
    "        self.case_base_X = X_train.copy()\n",
    "        self.case_base_y = y_train.copy()\n",
    "        self.numerical_features = numerical_features.copy()\n",
    "        self.categorical_features = categorical_features.copy()\n",
    "        \n",
    "        # Estat√≠sticas da base de casos\n",
    "        self.training_stats = {\n",
    "            'total_cases': len(X_train),\n",
    "            'numerical_features': len(numerical_features),\n",
    "            'categorical_features': len(categorical_features),\n",
    "            'class_distribution': y_train.value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_single_case(self, query_case):\n",
    "        \"\"\"\n",
    "        Prediz a classe de um √∫nico caso usando CBR.\n",
    "        \n",
    "        Args:\n",
    "            query_case: pandas Series - Caso a ser classificado\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (predicted_class, confidence_score, similar_cases_info)\n",
    "        \"\"\"\n",
    "        # Encontrar casos similares\n",
    "        similar_indices, distances, similar_labels = find_k_most_similar_cases(\n",
    "            query_case=query_case,\n",
    "            case_base_X=self.case_base_X,\n",
    "            case_base_y=self.case_base_y,\n",
    "            numerical_features=self.numerical_features,\n",
    "            categorical_features=self.categorical_features,\n",
    "            k=self.k,\n",
    "            feature_weights=self.feature_weights,\n",
    "            similarity_method=self.similarity_method\n",
    "        )\n",
    "        \n",
    "        # Vota√ß√£o para classifica√ß√£o\n",
    "        if self.voting_method == 'simple_majority':\n",
    "            # Vota√ß√£o majorit√°ria simples\n",
    "            vote_counts = Counter(similar_labels)\n",
    "            predicted_class = vote_counts.most_common(1)[0][0]\n",
    "            confidence = vote_counts[predicted_class] / len(similar_labels)\n",
    "            \n",
    "        elif self.voting_method == 'weighted_distance':\n",
    "            # Vota√ß√£o ponderada pela dist√¢ncia (inverso da dist√¢ncia)\n",
    "            class_votes = {}\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            for label, distance in zip(similar_labels, distances):\n",
    "                # Evitar divis√£o por zero com epsilon\n",
    "                weight = 1.0 / (distance + 1e-10)\n",
    "                if label not in class_votes:\n",
    "                    class_votes[label] = 0.0\n",
    "                class_votes[label] += weight\n",
    "                total_weight += weight\n",
    "            \n",
    "            # Normalizar pesos\n",
    "            for label in class_votes:\n",
    "                class_votes[label] /= total_weight\n",
    "            \n",
    "            predicted_class = max(class_votes, key=class_votes.get)\n",
    "            confidence = class_votes[predicted_class]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"M√©todo de vota√ß√£o '{self.voting_method}' n√£o suportado\")\n",
    "        \n",
    "        # Informa√ß√µes dos casos similares\n",
    "        similar_cases_info = {\n",
    "            'indices': similar_indices,\n",
    "            'distances': distances,\n",
    "            'labels': similar_labels,\n",
    "            'confidence': confidence\n",
    "        }\n",
    "        \n",
    "        return predicted_class, confidence, similar_cases_info\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Prediz as classes para m√∫ltiplos casos.\n",
    "        \n",
    "        Args:\n",
    "            X_test: pandas DataFrame - Casos a serem classificados\n",
    "        \n",
    "        Returns:\n",
    "            numpy array: Array com as predi√ß√µes\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        self.prediction_details = []  # Armazenar detalhes para an√°lise\n",
    "        \n",
    "        for idx in X_test.index:\n",
    "            query_case = X_test.loc[idx]\n",
    "            predicted_class, confidence, similar_cases_info = self.predict_single_case(query_case)\n",
    "            \n",
    "            predictions.append(predicted_class)\n",
    "            self.prediction_details.append({\n",
    "                'test_index': idx,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': confidence,\n",
    "                'similar_cases': similar_cases_info\n",
    "            })\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_prediction_statistics(self):\n",
    "        \"\"\"\n",
    "        Retorna estat√≠sticas das predi√ß√µes realizadas.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'prediction_details'):\n",
    "            return \"Nenhuma predi√ß√£o foi realizada ainda.\"\n",
    "        \n",
    "        confidences = [detail['confidence'] for detail in self.prediction_details]\n",
    "        \n",
    "        stats = {\n",
    "            'total_predictions': len(self.prediction_details),\n",
    "            'mean_confidence': np.mean(confidences),\n",
    "            'std_confidence': np.std(confidences),\n",
    "            'min_confidence': np.min(confidences),\n",
    "            'max_confidence': np.max(confidences),\n",
    "            'confidence_distribution': pd.Series(confidences).describe()\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "# ‚úÖ INSTANCIAR E TESTAR O CLASSIFICADOR CBR\n",
    "print(\"üß™ TESTE DO CLASSIFICADOR CBR:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar classificador CBR baseline (pesos iguais)\n",
    "cbr_baseline = CKDCBRClassifier(\n",
    "    k=5,\n",
    "    similarity_method='euclidean',\n",
    "    feature_weights=None,  # Pesos iguais\n",
    "    voting_method='simple_majority'\n",
    ")\n",
    "\n",
    "# 'Treinar' o CBR com dados de treinamento\n",
    "cbr_baseline.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_stage_train,  # Come√ßando com CKD_Stage\n",
    "    numerical_features=numerical_features_verified,\n",
    "    categorical_features=categorical_features_verified\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ CBR treinado com {cbr_baseline.training_stats['total_cases']} casos\")\n",
    "print(f\"üìä Features num√©ricas: {cbr_baseline.training_stats['numerical_features']}\")\n",
    "print(f\"üìä Features categ√≥ricas: {cbr_baseline.training_stats['categorical_features']}\")\n",
    "print(f\"üìä Distribui√ß√£o de classes: {cbr_baseline.training_stats['class_distribution']}\")\n",
    "print()\n",
    "\n",
    "# Testar com um pequeno subset primeiro\n",
    "print(\"üß™ TESTE COM 10 CASOS DE EXEMPLO:\")\n",
    "print(\"-\" * 40)\n",
    "X_test_sample = X_test.head(10)\n",
    "y_test_sample = y_stage_test.head(10)\n",
    "\n",
    "# Fazer predi√ß√µes\n",
    "predictions_sample = cbr_baseline.predict(X_test_sample)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"{'√çndice':<8} {'Real':<6} {'Predito':<8} {'Confian√ßa':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for i, (idx, real, pred) in enumerate(zip(X_test_sample.index, y_test_sample, predictions_sample)):\n",
    "    confidence = cbr_baseline.prediction_details[i]['confidence']\n",
    "    print(f\"{idx:<8} {real:<6} {pred:<8} {confidence:<10.3f}\")\n",
    "\n",
    "# Calcular acur√°cia do sample\n",
    "sample_accuracy = accuracy_score(y_test_sample, predictions_sample)\n",
    "print(f\"\\nüìä Acur√°cia no sample (10 casos): {sample_accuracy:.3f}\")\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Classificador CBR implementado com sucesso!\")\n",
    "print(\"üîß Suporta vota√ß√£o majorit√°ria e ponderada por dist√¢ncia\")\n",
    "print(\"üîß Armazena detalhes de cada predi√ß√£o para an√°lise\")\n",
    "print(\"üîß Calcula m√©tricas de confian√ßa\")\n",
    "\n",
    "# Atualizar memory_facts\n",
    "memory_facts['cbr_implementation']['classifier_class'] = 'implemented'\n",
    "memory_facts['cbr_implementation']['supports_multiclass'] = True\n",
    "memory_facts['cbr_implementation']['supports_binary'] = True\n",
    "memory_facts['cbr_implementation']['baseline_tested'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd7ffc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† PASSO 4.3 - AVALIA√á√ÉO COMPLETA DO CBR BASELINE\n",
      "======================================================================\n",
      "üéØ PROBLEMA 1: CLASSIFICA√á√ÉO MULTICLASSE - CKD_STAGE\n",
      "======================================================================\n",
      "üìä AVALIA√á√ÉO - CKD_STAGE\n",
      "--------------------------------------------------\n",
      "üîÑ Fazendo predi√ß√µes para 228 casos de teste...\n",
      "‚úÖ Predi√ß√µes conclu√≠das!\n",
      "\n",
      "üìà M√âTRICAS PRINCIPAIS:\n",
      "------------------------------\n",
      "üéØ Acur√°cia: 0.6491\n",
      "üéØ Precis√£o (weighted): 0.6527\n",
      "üéØ Recall (weighted): 0.6491\n",
      "üéØ F1-Score (weighted): 0.6377\n",
      "\n",
      "üìä RELAT√ìRIO POR CLASSE:\n",
      "----------------------------------------\n",
      "Classe   Precis√£o   Recall     F1-Score   Suporte \n",
      "--------------------------------------------------\n",
      "2        0.5000     0.1579     0.2400     19      \n",
      "3        0.6293     0.7766     0.6952     94      \n",
      "4        0.5946     0.6027     0.5986     73      \n",
      "5        0.8750     0.6667     0.7568     42      \n",
      "\n",
      "üìä MATRIZ DE CONFUS√ÉO:\n",
      "------------------------------\n",
      "   2   3   4   5\n",
      "2  3  16   0   0\n",
      "3  3  73  17   1\n",
      "4  0  26  44   3\n",
      "5  0   1  13  28\n",
      "\n",
      "üìä ESTAT√çSTICAS DE CONFIAN√áA:\n",
      "------------------------------\n",
      "üéØ Confian√ßa m√©dia: 0.7132\n",
      "üéØ Desvio padr√£o: 0.1806\n",
      "üéØ Confian√ßa m√≠n/m√°x: 0.4000 / 1.0000\n",
      "\n",
      "‚úÖ Avalia√ß√£o CKD_Stage conclu√≠da!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# üß† PASSO 4.3 - AVALIA√á√ÉO COMPLETA DO CBR BASELINE\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"üß† PASSO 4.3 - AVALIA√á√ÉO COMPLETA DO CBR BASELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_cbr_performance(cbr_classifier, X_test, y_test, problem_name, class_names=None):\n",
    "    \"\"\"\n",
    "    Avalia performance completa do classificador CBR.\n",
    "    \n",
    "    Args:\n",
    "        cbr_classifier: Inst√¢ncia do CKDCBRClassifier\n",
    "        X_test: pandas DataFrame - Features de teste\n",
    "        y_test: pandas Series - Labels verdadeiros de teste\n",
    "        problem_name: str - Nome do problema ('CKD_Stage' ou 'CKD_Progression')\n",
    "        class_names: list - Nomes das classes (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicion√°rio com todas as m√©tricas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üìä AVALIA√á√ÉO - {problem_name.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Fazer predi√ß√µes no conjunto completo de teste\n",
    "    print(f\"üîÑ Fazendo predi√ß√µes para {len(X_test)} casos de teste...\")\n",
    "    predictions = cbr_classifier.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas b√°sicas\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_test, predictions, average='weighted')\n",
    "    \n",
    "    print(f\"‚úÖ Predi√ß√µes conclu√≠das!\")\n",
    "    print()\n",
    "    \n",
    "    # Mostrar m√©tricas principais\n",
    "    print(\"üìà M√âTRICAS PRINCIPAIS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"üéØ Acur√°cia: {accuracy:.4f}\")\n",
    "    print(f\"üéØ Precis√£o (weighted): {precision:.4f}\")\n",
    "    print(f\"üéØ Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"üéØ F1-Score (weighted): {f1:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Relat√≥rio detalhado por classe\n",
    "    print(\"üìä RELAT√ìRIO POR CLASSE:\")\n",
    "    print(\"-\" * 40)\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # Mostrar m√©tricas de cada classe\n",
    "    classes = sorted([k for k in report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']])\n",
    "    print(f\"{'Classe':<8} {'Precis√£o':<10} {'Recall':<10} {'F1-Score':<10} {'Suporte':<8}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for class_label in classes:\n",
    "        if class_label in report:\n",
    "            metrics = report[class_label]\n",
    "            print(f\"{class_label:<8} {metrics['precision']:<10.4f} {metrics['recall']:<10.4f} \"\n",
    "                  f\"{metrics['f1-score']:<10.4f} {int(metrics['support']):<8}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(\"üìä MATRIZ DE CONFUS√ÉO:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Criar DataFrame para melhor visualiza√ß√£o\n",
    "    unique_labels = sorted(y_test.unique())\n",
    "    cm_df = pd.DataFrame(cm, index=unique_labels, columns=unique_labels)\n",
    "    print(cm_df)\n",
    "    print()\n",
    "    \n",
    "    # Estat√≠sticas de confian√ßa\n",
    "    pred_stats = cbr_classifier.get_prediction_statistics()\n",
    "    print(\"üìä ESTAT√çSTICAS DE CONFIAN√áA:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"üéØ Confian√ßa m√©dia: {pred_stats['mean_confidence']:.4f}\")\n",
    "    print(f\"üéØ Desvio padr√£o: {pred_stats['std_confidence']:.4f}\")\n",
    "    print(f\"üéØ Confian√ßa m√≠n/m√°x: {pred_stats['min_confidence']:.4f} / {pred_stats['max_confidence']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Calcular AUC-ROC se bin√°rio\n",
    "    auc_roc = None\n",
    "    if len(unique_labels) == 2:\n",
    "        try:\n",
    "            auc_roc = roc_auc_score(y_test, predictions)\n",
    "            print(f\"üéØ AUC-ROC: {auc_roc:.4f}\")\n",
    "            print()\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è AUC-ROC n√£o p√¥de ser calculado\")\n",
    "            print()\n",
    "    \n",
    "    # Compilar resultados\n",
    "    results = {\n",
    "        'problem_name': problem_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall,\n",
    "        'f1_weighted': f1,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm,\n",
    "        'confidence_stats': pred_stats,\n",
    "        'auc_roc': auc_roc,\n",
    "        'predictions': predictions,\n",
    "        'true_labels': y_test\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ‚úÖ AVALIA√á√ÉO 1: CKD_STAGE (PROBLEMA MULTICLASSE)\n",
    "print(\"üéØ PROBLEMA 1: CLASSIFICA√á√ÉO MULTICLASSE - CKD_STAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar CBR para CKD_Stage\n",
    "cbr_stage = CKDCBRClassifier(\n",
    "    k=5,\n",
    "    similarity_method='euclidean',\n",
    "    feature_weights=None,  # Baseline com pesos iguais\n",
    "    voting_method='simple_majority'\n",
    ")\n",
    "\n",
    "# Treinar com dados de CKD_Stage\n",
    "cbr_stage.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_stage_train,\n",
    "    numerical_features=numerical_features_verified,\n",
    "    categorical_features=categorical_features_verified\n",
    ")\n",
    "\n",
    "# Avaliar performance\n",
    "stage_results = evaluate_cbr_performance(\n",
    "    cbr_classifier=cbr_stage,\n",
    "    X_test=X_test,\n",
    "    y_test=y_stage_test,\n",
    "    problem_name='CKD_Stage',\n",
    "    class_names=['Stage 1', 'Stage 2', 'Stage 3', 'Stage 4', 'Stage 5']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Avalia√ß√£o CKD_Stage conclu√≠da!\")\n",
    "print(\"=\"*70)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffb623f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ PROBLEMA 2: CLASSIFICA√á√ÉO BIN√ÅRIA - CKD_PROGRESSION\n",
      "======================================================================\n",
      "üìä AVALIA√á√ÉO - CKD_PROGRESSION\n",
      "--------------------------------------------------\n",
      "üîÑ Fazendo predi√ß√µes para 228 casos de teste...\n",
      "‚úÖ Predi√ß√µes conclu√≠das!\n",
      "\n",
      "üìà M√âTRICAS PRINCIPAIS:\n",
      "------------------------------\n",
      "üéØ Acur√°cia: 0.8553\n",
      "üéØ Precis√£o (weighted): 0.8507\n",
      "üéØ Recall (weighted): 0.8553\n",
      "üéØ F1-Score (weighted): 0.8520\n",
      "\n",
      "üìä RELAT√ìRIO POR CLASSE:\n",
      "----------------------------------------\n",
      "Classe   Precis√£o   Recall     F1-Score   Suporte \n",
      "--------------------------------------------------\n",
      "0        0.8876     0.9240     0.9054     171     \n",
      "1        0.7400     0.6491     0.6916     57      \n",
      "\n",
      "üìä MATRIZ DE CONFUS√ÉO:\n",
      "------------------------------\n",
      "     0   1\n",
      "0  158  13\n",
      "1   20  37\n",
      "\n",
      "üìä ESTAT√çSTICAS DE CONFIAN√áA:\n",
      "------------------------------\n",
      "üéØ Confian√ßa m√©dia: 0.8623\n",
      "üéØ Desvio padr√£o: 0.1616\n",
      "üéØ Confian√ßa m√≠n/m√°x: 0.6000 / 1.0000\n",
      "\n",
      "üéØ AUC-ROC: 0.7865\n",
      "\n",
      "‚úÖ Avalia√ß√£o CKD_Progression conclu√≠da!\n",
      "======================================================================\n",
      "\n",
      "üìä RESUMO COMPARATIVO - CBR BASELINE\n",
      "============================================================\n",
      "M√©trica                   CKD_Stage       CKD_Progression\n",
      "------------------------------------------------------------\n",
      "Acur√°cia                  0.6491          0.8553         \n",
      "Precis√£o (weighted)       0.6527          0.8507         \n",
      "Recall (weighted)         0.6491          0.8553         \n",
      "F1-Score (weighted)       0.6377          0.8520         \n",
      "AUC-ROC                   N/A (multiclasse) 0.7865         \n",
      "\n",
      "üìä CONFIAN√áA M√âDIA DAS PREDI√á√ïES:\n",
      "----------------------------------------\n",
      "CKD_Stage                 0.7132         \n",
      "CKD_Progression           0.8623         \n",
      "\n",
      "‚úÖ PASSO 4 - CBR BASELINE IMPLEMENTADO COM SUCESSO!\n",
      "============================================================\n",
      "üéØ CBR funcional para ambos os problemas:\n",
      "   ‚Ä¢ CKD_Stage: Classifica√ß√£o multiclasse (5 est√°gios)\n",
      "   ‚Ä¢ CKD_Progression: Classifica√ß√£o bin√°ria (progress√£o sim/n√£o)\n",
      "\n",
      "üîß Caracter√≠sticas implementadas:\n",
      "   ‚Ä¢ Fun√ß√£o de similaridade mista (num√©rica + categ√≥rica)\n",
      "   ‚Ä¢ Sistema k-NN com vota√ß√£o majorit√°ria\n",
      "   ‚Ä¢ M√©tricas completas de avalia√ß√£o\n",
      "   ‚Ä¢ An√°lise de confian√ßa das predi√ß√µes\n",
      "   ‚Ä¢ Suporte a pesos customizados (preparado para otimiza√ß√£o)\n",
      "\n",
      "üíæ Resultados salvos em memory_facts para compara√ß√£o futura\n",
      "\n",
      "üéØ PR√ìXIMO: PASSO 5 - OTIMIZA√á√ÉO DOS PESOS DAS FEATURES\n",
      "   üìã Implementar algoritmo de otimiza√ß√£o (Grid Search, Gradient Descent ou Genetic Algorithm)\n",
      "   üìã Comparar CBR otimizado vs baseline\n",
      "   üìã An√°lise final e conclus√µes\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ AVALIA√á√ÉO 2: CKD_PROGRESSION (PROBLEMA BIN√ÅRIO)\n",
    "print(\"üéØ PROBLEMA 2: CLASSIFICA√á√ÉO BIN√ÅRIA - CKD_PROGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar CBR para CKD_Progression  \n",
    "cbr_progression = CKDCBRClassifier(\n",
    "    k=5,\n",
    "    similarity_method='euclidean',\n",
    "    feature_weights=None,  # Baseline com pesos iguais\n",
    "    voting_method='simple_majority'\n",
    ")\n",
    "\n",
    "# Treinar com dados de CKD_Progression\n",
    "cbr_progression.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_progression_train,\n",
    "    numerical_features=numerical_features_verified,\n",
    "    categorical_features=categorical_features_verified\n",
    ")\n",
    "\n",
    "# Avaliar performance\n",
    "progression_results = evaluate_cbr_performance(\n",
    "    cbr_classifier=cbr_progression,\n",
    "    X_test=X_test,\n",
    "    y_test=y_progression_test,\n",
    "    problem_name='CKD_Progression',\n",
    "    class_names=['Sem Progress√£o', 'Com Progress√£o']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Avalia√ß√£o CKD_Progression conclu√≠da!\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# ‚úÖ RESUMO COMPARATIVO DOS DOIS PROBLEMAS\n",
    "print(\"üìä RESUMO COMPARATIVO - CBR BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"{'M√©trica':<25} {'CKD_Stage':<15} {'CKD_Progression':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Acur√°cia':<25} {stage_results['accuracy']:<15.4f} {progression_results['accuracy']:<15.4f}\")\n",
    "print(f\"{'Precis√£o (weighted)':<25} {stage_results['precision_weighted']:<15.4f} {progression_results['precision_weighted']:<15.4f}\")\n",
    "print(f\"{'Recall (weighted)':<25} {stage_results['recall_weighted']:<15.4f} {progression_results['recall_weighted']:<15.4f}\")\n",
    "print(f\"{'F1-Score (weighted)':<25} {stage_results['f1_weighted']:<15.4f} {progression_results['f1_weighted']:<15.4f}\")\n",
    "if progression_results['auc_roc'] is not None:\n",
    "    print(f\"{'AUC-ROC':<25} {'N/A (multiclasse)':<15} {progression_results['auc_roc']:<15.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"üìä CONFIAN√áA M√âDIA DAS PREDI√á√ïES:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'CKD_Stage':<25} {stage_results['confidence_stats']['mean_confidence']:<15.4f}\")\n",
    "print(f\"{'CKD_Progression':<25} {progression_results['confidence_stats']['mean_confidence']:<15.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ PASSO 4 - CBR BASELINE IMPLEMENTADO COM SUCESSO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ CBR funcional para ambos os problemas:\")\n",
    "print(\"   ‚Ä¢ CKD_Stage: Classifica√ß√£o multiclasse (5 est√°gios)\")\n",
    "print(\"   ‚Ä¢ CKD_Progression: Classifica√ß√£o bin√°ria (progress√£o sim/n√£o)\")\n",
    "print()\n",
    "print(\"üîß Caracter√≠sticas implementadas:\")\n",
    "print(\"   ‚Ä¢ Fun√ß√£o de similaridade mista (num√©rica + categ√≥rica)\")\n",
    "print(\"   ‚Ä¢ Sistema k-NN com vota√ß√£o majorit√°ria\")\n",
    "print(\"   ‚Ä¢ M√©tricas completas de avalia√ß√£o\")\n",
    "print(\"   ‚Ä¢ An√°lise de confian√ßa das predi√ß√µes\")\n",
    "print(\"   ‚Ä¢ Suporte a pesos customizados (preparado para otimiza√ß√£o)\")\n",
    "print()\n",
    "\n",
    "# Salvar resultados no memory_facts\n",
    "memory_facts['cbr_baseline_results'] = {\n",
    "    'ckd_stage': {\n",
    "        'accuracy': stage_results['accuracy'],\n",
    "        'precision_weighted': stage_results['precision_weighted'],\n",
    "        'recall_weighted': stage_results['recall_weighted'],\n",
    "        'f1_weighted': stage_results['f1_weighted'],\n",
    "        'mean_confidence': stage_results['confidence_stats']['mean_confidence']\n",
    "    },\n",
    "    'ckd_progression': {\n",
    "        'accuracy': progression_results['accuracy'],\n",
    "        'precision_weighted': progression_results['precision_weighted'],\n",
    "        'recall_weighted': progression_results['recall_weighted'],\n",
    "        'f1_weighted': progression_results['f1_weighted'],\n",
    "        'auc_roc': progression_results['auc_roc'],\n",
    "        'mean_confidence': progression_results['confidence_stats']['mean_confidence']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üíæ Resultados salvos em memory_facts para compara√ß√£o futura\")\n",
    "print()\n",
    "print(\"üéØ PR√ìXIMO: PASSO 5 - OTIMIZA√á√ÉO DOS PESOS DAS FEATURES\")\n",
    "print(\"   üìã Implementar algoritmo de otimiza√ß√£o (Grid Search, Gradient Descent ou Genetic Algorithm)\")\n",
    "print(\"   üìã Comparar CBR otimizado vs baseline\")\n",
    "print(\"   üìã An√°lise final e conclus√µes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drc-ckd-cbr-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
